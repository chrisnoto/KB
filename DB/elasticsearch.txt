########## ES的重要概念
ES 的 shard 实质为一个 Lucene 的 index，其中包含多个 Lucene Segments。

Lucene ReOpen：当调用 Lucene Reopen 时，将使累积的数据可用于搜索。 尽管可以搜索最新数据，但这不能保证数据的持久性或未将其写入磁盘。 我们可以调用 n 次重新打开功能，并使最新数据可搜索，但不能确定磁盘上是否存在数据。

Lucene Flush：将堆内存的数据写入文件系统缓存，相当于 es 的 refresh。

Lucene Commits：Segment 数据合并写入磁盘。

ES Translog：

ES Refresh：Index Buffer Memory(堆内存) 中的数据复制到filesystem cache中新建的 Segment 中，然后数据可以查询。这个过程会产生 Lucene Flush 操作，生成一个新的 Segment 。堆内存数据清空，但是 Translog 不会清空。

ES Flush：filesystem cache的 Segments 写入写合并的 Segment 后落盘，清空 Translog。对应 Lucene Commit 操作。

translog 每个分片一个事务日志，文档写入 ES 时会同步写 Translog 和 Index Buffer Memory(堆内存)。当向elasticsearch发送创建document索引请求的时候，document数据会先进入到index buffer之后，与此同时会将操作记录在translog之中，
当发生refresh时（数据从index buffer中进入filesystem cache的过程）translog中的操作记录并不会被清除，而是当数据从filesystem cache中被写入磁盘之后才会将translog中清空。
而从filesystem cache写入磁盘的过程就是flush。

bucket（桶） 表示一个数据分组，类似 mysql 中的 group
metric  表示对一个数据分组执行的统计操作，比如说求平均值、求最大值、求最小值

使用如下 sql 来理解这两个概念
select count(*) from access_log group by user_id
    
bucket：group by user_id，那些 user_id 相同的数据，就会被划分到一个 bucket 中
metric：count(*)，对每个 user_id bucket 中所有的数据，计算一个数量

######### translog都有哪些操作
translog中定义了index，create，delete及deletebyquery四种操作它们都继承自Operation。这四种操作也是四种能够改变索引数据的操作。operation代码如下所示：

static interface Operation extends Streamable {

static enum Type {

CREATE((byte) 1),

SAVE((byte) 2),

DELETE((byte) 3),

DELETE_BY_QUERY((byte) 4);
###########  elasticsearch 7 新功能之 Visualize data from a log file ########
介绍
The File Data Visualizer helps you understand the fields and metrics in a log file. 
Upload your file, analyze its data, and then choose whether to import the data into an Elasticsearch index.
The File Data Visualizer supports these file formats:
Delimited text files, such as CSV and TSV
Newline-delimited JSON
Log files with a common format for the timestamp
You can upload files up to 100 MB.
可以用csv, tsv, ndjson,log with timestamp 等格式
log with timestamp格式不会解析log内容的
1 从postgresql :  select row_to_json(pglog) from pglog \g 111.json
编辑111.json去掉头和尾
2 在kibana中 home-> upload a file 



###########  elasticsearch 7 新功能之 remote cluster query ########
1 create a single node cluster
2 in kibana, add it as remote cluster    alias:myes
3 query with remote cluster
[root@stjes1 ~]# curl http://10.67.51.147:9200/myes:tutorial/_search?pretty
{
  "took" : 552,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "_clusters" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "myes:tutorial",
        "_type" : "helloworld",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "message" : "Hello World!"
        }
      },
      {
        "_index" : "myes:tutorial",
        "_type" : "helloworld",
        "_id" : "2",
        "_score" : 1.0,
        "_source" : {
          "message" : "Hello sans!"
        }
      }
    ]
  }
}

##########
测试jvm内存是否能用压缩对象指针
[root@xtjcesbges01 jvm.options.d]# java -Xmx32768m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops                         = false                               {lp64_product}
[root@xtjcesbges01 jvm.options.d]# java -Xmx31744m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops                        := true                                {lp64_product}

[root@stjes1 elasticsearch]# zcat es-prod-2021-12-14-2.log.gz |grep compressed
[2021-12-14T13:57:04,174][INFO ][o.e.e.NodeEnvironment    ] [stjes1] heap size [30.6gb], compressed ordinary object pointers [true]
[root@stjes1 elasticsearch]# ps auwx |grep elasticsearch |grep -v grep
elastic+ 185073  127 27.6 559346384 36417916 ?  SLsl  2021 44069:07 /bin/java -Xms31g -Xmx31g 

############# elasticsearch查询 ############
[naifa@repo-centos ~]$ curl -s -XGET http://10.67.51.150:9200/winlogbeat-6.8.1-2019.12.25/_search?_source=beat.hostname |jq '.hits|.hits|.[]|._source|.beat|.hostname'
"VSTJCAEVMI2DB02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"
"vSTJB2BBAK02"

######ELK Upgrade order#########
You should upgrade the core Elastic Stack products in the following order:

Elasticsearch: upgrade instructions
Kibana: upgrade instructions
Logstash: upgrade instructions
Beats: upgrade instructions
6.8的时候, ingest-geoip和ingest-user-agent已经不用单独安装了

#1  rolling upgrade elasticsearch repository-s3   6.4.0->6.8.1

# curl -X PUT "10.67.51.150:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.enable": "all"
  }
}
'
# systemctl stop elasticsearch
# rpm -Uvh elasticsearch-6.8.1.rpm
# systemctl daemon-reload
# /usr/share/elasticsearch/bin/elasticsearch-plugin remove repository-s3
# /usr/share/elasticsearch/bin/elasticsearch-plugin remove --purge ingest-geoip
# /usr/share/elasticsearch/bin/elasticsearch-plugin remove ingest-user-agent
# /usr/share/elasticsearch/bin/elasticsearch-plugin list
# /usr/share/elasticsearch/bin/elasticsearch-plugin install file:///root/repository-s3-6.8.1.zip
# systemctl start elasticsearch
# tail -f /var/log/elasticsearch/logging.log
# curl -X PUT "10.67.36.49:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.enable": "all"
  }
}
'

##########  elasticsearch高级操作 ##########
### reindex在不同集群之间迁移数据
curl -X POST "http://10.67.39.81:9200/_reindex" -H 'Content-Type: application/json' -d'
{
  "source": {
    "remote": {
      "host": "http://10.67.51.150:9200"
    },
    "index": "docker-2022.01.08",
    "query": {
      "match_all": {}
    }
  },
  "dest": {
    "index": "clm_2"
  }
}'

### split index

How splitting works
A split operation:

1 Creates a new target index with the same definition as the source index, but with a larger number of primary shards.
2 Hard-links segments from the source index into the target index. (If the file system doesn’t support hard-linking, 
then all segments are copied into the new index, which is a much more time consuming process.)
3 Hashes all documents again, after low level files are created, to delete documents that belong to a different shard.
4 Recovers the target index as though it were a closed index which had just been re-opened.

split操作前提
1 集群health状态为绿色
2 待split的index设为只读

1 set it read only
curl -X PUT "http://10.67.39.81:9200/clm_20220112/_settings" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "index.blocks.write": true
   }
}'
2 split it into new target index
curl -X POST "http://10.67.39.81:9200/clm_20220112/_split/clm_3" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "index.number_of_shards": 2
   }
}'

PUT filebeat-7.12.0-2022.08/_settings
{
  "blocks.write": true
}

POST filebeat-7.12.0-2022.08/_split/filebeat-7.12.0-202208
{
  "settings": {
    "index.number_of_shards": 2
  }
}

GET _cat/recovery/filebeat-7.12.0-202208

GET filebeat-7.12.0-2022.08/_count
GET filebeat-7.12.0-202208/_count
GET _cat/shards/filebeat-7.12.0-202208?v
index                  shard prirep state          docs  store ip           node
filebeat-7.12.0-202208 1     p      STARTED    76785201 84.6gb 10.66.12.214 xtjcesbges02
filebeat-7.12.0-202208 1     r      UNASSIGNED                              
filebeat-7.12.0-202208 0     p      STARTED    76776210 84.6gb 10.66.12.214 xtjcesbges02
filebeat-7.12.0-202208 0     r      UNASSIGNED

# 将多个index写到一个新的index
curl -X POST "http://10.67.51.150:9200/_reindex" -H 'Content-Type: application/json' -d'
{
  "source": {
    "index": "docker-2022.01.*"
  },
  "dest": {
    "index": "docker-2022.01"
  }
}'

curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic:vSTJ456 https://xtjcesbges01.cesbg.foxconn:9200/_reindex -H 'Content-Type: application/json' -d '
{
  "source": {
    "index": "filebeat-7.12.0-2022.03.*"
  },
  "dest": {
    "index": "filebeat-7.12.0-2022.03"
  }
}'

# 查看reindex的status
GET /_tasks?detailed=true&actions=*reindex&group_by=parents

############repository-s3 与minio ###############
minio 配置
[root@repo ~]# cat minio.sh
docker run -d \
    --name myminio \
    -p 9000:9000 \
    -p 9001:9001 \
    -e "MINIO_ACCESS_KEY=admin" \
    -e "MINIO_SECRET_KEY=vSTJ456789" \
    -v /mrepo/minio:/data \
    minio/minio server /data --console-address ":9001"

以下错误需要在jvm.options里添加 -Des.allow_insecure_settings=true，并重启ES
{
  "error": {
    "root_cause": [
      {
        "type": "illegal_argument_exception",
        "reason": "Setting [access_key] is insecure, but property [allow_insecure_settings] is not set"
      }
    ],
    "type": "illegal_argument_exception",
    "reason": "Setting [access_key] is insecure, but property [allow_insecure_settings] is not set"
  },
  "status": 400
}

repository-s3安装  每台机器都需要操作
/usr/share/elasticsearch/bin/elasticsearch-plugin install file:///root/repository-s3-6.8.1.zip
配置s3 endpoint, access key, secret key

[root@es elasticsearch]# tail -3 /etc/elasticsearch/elasticsearch.yml
s3.client.default.endpoint: "10.67.51.164:9000"
s3.client.default.protocol: http

/usr/share/elasticsearch/bin/elasticsearch-keystore add s3.client.default.access_key
/usr/share/elasticsearch/bin/elasticsearch-keystore add s3.client.default.secret_key

systemctl restart elasticsearch

############
创建repository
[root@es elasticsearch]# !1019
curl -X PUT 10.67.51.150:9200/_snapshot/myminio -H 'Content-Type: application/json' -d'
{
  "type": "s3",
  "settings": {
    "bucket": "myminio"
  }
}'
{"acknowledged":true}
查看repository
[root@stjes1 ~]# curl -s -XGET http://10.67.51.150:9200/_snapshot/myminio | jq .
{
  "myminio": {
    "type": "s3",
    "settings": {
      "bucket": "es-snapshot",
      "region": "TJ"
    }
  }
}


检查repos是否每个节点可用
[root@stjes1 ~]# curl -s -XPOST "10.67.51.150:9200/_snapshot/myminio/_verify" | jq .
{
  "nodes": {
    "BdLnYgiKSBuo-Kw4NvIj1g": {
      "name": "stjes2"
    },
    "KBPaq00ZSkqqF_Z5jnwvXQ": {
      "name": "stjes1"
    },
    "sLZDyxbqROywEOwLwWqHpw": {
      "name": "stjes3"
    }
  }
}


#########snapshot########
创建snapshot
[root@stjes1 ~]# curl -X PUT "10.67.51.150:9200/_snapshot/myminio/filebeat-2022.01.12.backup?wait_for_completion=true" -H 'Content-Type: application/json' -d'
{
  "indices": "filebeat-6.8.1-2022.01.12",
  "ignore_unavailable": true,
  "include_global_state": false,
  "metadata": {
    "taken_by": "admin",
    "taken_because": "daily backup"
  }
}'
{"snapshot":{"snapshot":"filebeat-2022.01.12.backup","uuid":"4NI1Ky4MSh22gQNb_VohMw","version_id":6080199,"version":"6.8.1","
indices":["filebeat-6.8.1-2022.01.12"],"include_global_state":false,"state":"SUCCESS",
"start_time":"2022-01-12T02:41:38.826Z","start_time_in_millis":1641955298826,"end_time":"2022-01-12T02:41:45.100Z","end_time_in_millis":1641955305100,"duration_in_millis":6274,
"failures":[],"shards":{"total":3,"failed":0,"successful":3}}}

查看snapshot
[root@stjes1 ~]# curl -XGET http://10.67.51.150:9200/_cat/snapshots/myminio?pretty=true
filebeat-2022.01.11.backup    SUCCESS 1641889874 08:31:14 1641889904 08:31:44 30.1s 1 3 0 3
filebeat-2022.01.11.inr.16:37 SUCCESS 1641890229 08:37:09 1641890232 08:37:12  2.4s 1 3 0 3
filebeat-2022.01.10.backup    SUCCESS 1641890628 08:43:48 1641890688 08:44:48    1m 1 3 0 3
filebeat-2022.01.12.backup    SUCCESS 1641955298 02:41:38 1641955305 02:41:45  6.2s 1 3 0 3

[root@stjes1 ~]# curl -s -XGET http://10.67.51.150:9200/_snapshot/myminio/filebeat-2022.01.11.backup?pretty=true | jq .
{
  "snapshots": [
    {
      "snapshot": "filebeat-2022.01.11.backup",
      "uuid": "owtaMv_-T4aLjSPfbSjHog",
      "version_id": 6080199,
      "version": "6.8.1",
      "indices": [
        "filebeat-6.8.1-2022.01.11"
      ],
      "include_global_state": true,
      "state": "SUCCESS",
      "start_time": "2022-01-11T08:31:14.345Z",
      "start_time_in_millis": 1641889874345,
      "end_time": "2022-01-11T08:31:44.489Z",
      "end_time_in_millis": 1641889904489,
      "duration_in_millis": 30144,
      "failures": [],
      "shards": {
        "total": 3,
        "failed": 0,
        "successful": 3
      }
    }
  ]
}
[root@stjes1 ~]# curl -s -XGET http://10.67.51.150:9200/_snapshot/myminio/filebeat-2022.01.11.inr.16:37?pretty=true | jq .
{
  "snapshots": [
    {
      "snapshot": "filebeat-2022.01.11.inr.16:37",
      "uuid": "JRPAM83QSfSq-3PEHPsN2A",
      "version_id": 6080199,
      "version": "6.8.1",
      "indices": [
        "filebeat-6.8.1-2022.01.11"
      ],
      "include_global_state": true,
      "state": "SUCCESS",
      "start_time": "2022-01-11T08:37:09.998Z",
      "start_time_in_millis": 1641890229998,
      "end_time": "2022-01-11T08:37:12.425Z",
      "end_time_in_millis": 1641890232425,
      "duration_in_millis": 2427,
      "failures": [],
      "shards": {
        "total": 3,
        "failed": 0,
        "successful": 3
      }
    }
  ]
}

[root@stjes1 curator]# curl -s -XGET http://10.67.51.150:9200/_snapshot/myminio/curator-20220114085641?pretty=true | jq .
{
  "snapshots": [
    {
      "snapshot": "curator-20220114085641",
      "uuid": "3QzR8rwlQ0O8oS4Ir24yJw",
      "version_id": 6080199,
      "version": "6.8.1",
      "indices": [
        "docker-2022.01.08",
        "docker-2022.01.04",
        "docker-2022.01",
        "docker-2022.01.03",
        "docker-2022.01.06",
        "docker-2022.01.07",
        "docker-2022.01.02",
        "docker-2022.01.01",
        "docker-2022.01.05"
      ],
      "include_global_state": true,
      "state": "SUCCESS",
      "start_time": "2022-01-14T08:56:41.447Z",
      "start_time_in_millis": 1642150601447,
      "end_time": "2022-01-14T08:56:50.664Z",
      "end_time_in_millis": 1642150610664,
      "duration_in_millis": 9217,
      "failures": [],
      "shards": {
        "total": 27,
        "failed": 0,
        "successful": 27
      }
    }
  ]
}

[root@repo es-snapshot]# cat index-2 |jq .
{
  "snapshots": [
    {
      "name": "filebeat-2022.01.11.inr.16:37",
      "uuid": "JRPAM83QSfSq-3PEHPsN2A",
      "state": 1
    },
    {
      "name": "filebeat-2022.01.11.backup",
      "uuid": "owtaMv_-T4aLjSPfbSjHog",
      "state": 1
    },
    {
      "name": "filebeat-2022.01.10.backup",
      "uuid": "vIrPYgdST7K8cmM5erDrsA",
      "state": 1
    }
  ],
  "indices": {
    "filebeat-6.8.1-2022.01.10": {
      "id": "TIFICiZaQxGtxBb_Ko62ZA",
      "snapshots": [
        "vIrPYgdST7K8cmM5erDrsA"
      ]
    },
    "filebeat-6.8.1-2022.01.11": {
      "id": "NlSuo-doRMSnLhOQippHsA",
      "snapshots": [
        "owtaMv_-T4aLjSPfbSjHog",             #增量
        "JRPAM83QSfSq-3PEHPsN2A"
      ]
    }
  }
}

[root@es elasticsearch]# curl -s -X GET 10.67.74.235:9200/_snapshot/backup/demo-2019.02.24-snapshot/_status |python -m json.tool |grep '"state"'
            "state": "SUCCESS",
还原snapshot
[root@es elasticsearch]# curl -X POST "10.67.74.235:9200/_snapshot/backup/demo-2019.02.23-snapshot/_restore"
{"accepted":true}[root@es elasticsearch]#
[root@es elasticsearch]# curl -X POST "10.67.74.235:9200/_snapshot/backup/demo-2019.02.24-snapshot/_restore"
{"accepted":true}[root@es elasticsearch]#

####查询elasticsearch所有模板######
[root@cobbler ~]# curl -s -XGET "http://10.67.51.150:9200/_template" |python -m json.tool | jq 'keys'
[
  ".ml-anomalies-",
  ".ml-meta",
  ".ml-notifications",
  ".ml-state",
  ".monitoring-alerts",
  ".monitoring-beats",
  ".monitoring-es",
  ".monitoring-kibana",
  ".monitoring-logstash",
  ".triggered_watches",
  ".watch-history-9",
  ".watches",
  "filebeat-6.4.0",
  "kibana_index_template:.kibana",
  "logstash",
  "logstash-index-template",
  "metricbeat-6.4.0",
  "security-index-template",
  "security_audit_log",
  "winlogbeat-6.4.0"
]

#############創建 syslog 模板###############
curl -X PUT "10.67.51.150:9200/_template/syslog?pretty" -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["syslog*"],
  "settings": {
    "refresh_interval": "30s",
    "number_of_shards": 1
  }
}
'

curl -X PUT "10.67.51.150:9200/_template/docker?pretty" -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["docker*"],
  "settings": {
    "refresh_interval": "30s",
    "number_of_shards": 3
  }
}
'

#####查各个index pattern的docs数(包含了replica)#########
[root@es1 ~]# /usr/bin/curator_cli --config /root/curator/curator.yml show_indices --verbose |grep -v '^\.[a-z]*' |awk '{t=length($1);print substr($1,0,t-10),$4}' |awk '{S[$1]+=$NF} END {for(a in S) print a, S[a]}'
swarm- 44086280
rke- 129671386
k8s- 57192234
filebeat-6.4.0- 141977796
fluentd- 1319124
winlogbeat-6.4.0- 1177064
查各个index pattern的docs数,并除以(replica+1)
[root@es1 ~]# /usr/bin/curator_cli --config /root/curator/curator.yml show_indices --verbose |grep -v '^\.[a-z]*' |awk '{t=length($1);print substr($1,0,t-10),$4/($6+1)}' |awk '{S[$1]+=$NF} END {for(a in S) print a, S[a]}'
swarm- 22043188
rke- 64836169
k8s- 19264321
filebeat-6.4.0- 70990681
fluentd- 659574
winlogbeat-6.4.0- 588537

### rollover
# rollover 使用api方式可以手动触发，使用ILM可以自动触发

POST /dc_location-000001/_alias/dc_location-rollover

POST /dc_location-rollover/_rollover   (未达到条件时，不触发，api返回的也都是false, 触发后api返回的是true)
{
  "conditions": {
    "max_docs": 100
  }
}
后续应该写到索引dc_location-rollover
如果继续往dc_location-000001写，则dc_location-000002不会新增数据
默认索引命名规则是 name-000001, rollover后的索引是name-000002
即使当前索引是 name-1, rollover后的索引仍然是name-000002
另外，api方式每次得手动触发，不会自动触发





6 chrome浏览器安装elasticsearch head插件


curl查询
cat系列
_cat系列提供了一系列查询elasticsearch集群状态的接口，可以通过执行
curl -XGET localhost:9200/_cat获取所有_cat系列的操作：
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
可以后面加一个v，让输出内容表格显示表头

常用查询
# 按shard大小給shard倒排序
GET _cat/shards?v=true&h=index,shard,pr,rep,state,sto,node,ur&s=sto:desc
index                               shard pr state       sto node                       ur
cloudmes-jobs-2023.03               0     r  STARTED 161.6gb xtjcesbges01               
cloudmes-jobs-2023.03               0     p  STARTED 161.5gb xtjcesbges03               
filebeat-7.12.0-2022.12-3           0     r  STARTED  62.2gb xtjcesbges07.cesbg.foxconn 
filebeat-7.12.0-2022.12-3           0     p  STARTED  62.1gb xtjcesbges06.cesbg.foxconn 
filebeat-7.12.0-202208              0     r  STARTED  53.6gb xtjcesbges06.cesbg.foxconn 

# 按主副本大小給index倒排序
get _cat/indices?v=true&h=index,health,pri,rep,pri.store.size&s=pri.store.size:desc
index                           health pri rep pri.store.size
cloudmes-jobs-2023.03           green    1   1        161.5gb
filebeat-7.12.0-202208          green    2   1        107.3gb
filebeat-7.12.0-2022.12-3       green    1   1         62.1gb
filebeat-7.12.0-2022.11-3       green    1   1         49.7gb
filebeat-7.12.0-2022.12-1       green    1   1         48.7gb

# 按index名稱給index倒排序
get _cat/indices?v=true&h=index,health,pri,rep,pri.store.size&s=index:desc
index                           health pri rep pri.store.size
winlogbeat-7.12.0-2023.03.31    green    1   1           10gb
winlogbeat-7.12.0-2023.03.30    green    1   1           24gb
winlogbeat-7.12.0-2023.03.29    green    1   1         25.6gb
winlogbeat-7.12.0-2023.03.28    green    1   1         25.5gb
winlogbeat-7.12.0-2023.03.27    green    1   1         28.3gb

# 按running time給task倒排序
GET _cat/tasks?v=true&h=action,type,running_time,node&s=running_time:desc
action                         type      running_time node
indices:data/write/reindex     transport 4.9h         xtjcesbges04.cesbg.foxconn
indices:data/write/bulk        transport 298ms        xtjcesbges04.cesbg.foxconn
indices:data/write/bulk[s]     transport 296.6ms      xtjcesbges04.cesbg.foxconn
indices:data/write/bulk[s]     transport 277ms        xtjcesbges06.cesbg.foxconn
indices:data/write/bulk[s][p]  direct    276.5ms      xtjcesbges06.cesbg.foxconn
--------------------- 
nodes系列
1、查询节点的状态
curl -XGET 'http://localhost:9200/_nodes/stats?pretty=true'
curl -XGET 'http://localhost:9200/_nodes/192.168.1.2/stats?pretty=true'
curl -XGET 'http://localhost:9200/_nodes/process'
curl -XGET 'http://localhost:9200/_nodes/_all/process'
curl -XGET 'http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/jvm,process'
curl -XGET 'http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/info/jvm,process'
curl -XGET 'http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/_all
curl -XGET 'http://localhost:9200/_nodes/hot_threads


--------------------- 
查看ES集群中磁盘使用情况
[root@es1 ~]# curl -XGET 'http://10.67.36.53:9200/_cat/allocation?v'
shards disk.indices disk.used disk.avail disk.total disk.percent host        ip          node
   368        5.8gb     6.9gb     92.9gb     99.9gb            6 10.67.36.53 10.67.36.53 es1
   368        6.3gb     7.5gb     92.4gb     99.9gb            7 10.67.36.52 10.67.36.52 es2
   368        1.9gb       2gb     97.9gb     99.9gb            2 10.67.36.51 10.67.36.51 es3
   
[root@es ~]# curl -XGET 'http://10.67.51.123:9200/_cat/allocation?v'
shards disk.indices disk.used disk.avail disk.total disk.percent host         ip           node
    39        5.9gb    16.8gb     58.6gb     75.4gb           22 10.67.51.123 10.67.51.123 es
    36                                                                                     UNASSIGNED

查看ES集群中所有节点信息，以及各个节点内存和CPU相关的指标
[root@cobbler ~]# curl -X GET 'http://10.67.36.53:9200/_cat/nodes?v'
ip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.67.36.51            4          70   0    0.00    0.02     0.05 di        -      es3
10.67.36.53            4          69   2    0.10    0.05     0.05 mdi       *      es1
10.67.36.52            3          70   0    0.07    0.05     0.05 mdi       -      es2
列出ES集群中所有的index信息
[root@cobbler ~]# curl -X GET 'http://10.67.36.53:9200/_cat/indices?v'
health status index          uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   abc-2018-10-19 EATkviyiTViCyAyM2Vc9Mw   5   1     341435            0    280.9mb        140.4mb
green  open   it-2018-10-21  1PqP-RK8RheQjEA17WVw6A   5   1      50320            0     44.8mb         22.3mb
green  open   abc-2018-10-18 sqRvriK1SpaOr30D_0JL8Q   5   1     218682            0    184.9mb         92.4mb
green  open   .kibana        W4nrDn4NQzuGU5w0CjUqtw   1   1          6            0     75.6kb         37.8kb
green  open   it-2018-10-22  vB3Bo9mAQVqdv5sSnNevMA   5   1      51781            0     46.7mb         23.4mb
green  open   new-2018-10-14 xipStdL7S3mqkUH_U8rhvQ   5   1      31233            0     22.3mb         11.2mb
green  open   new-2018-10-13 4w-Bxy72SfCud-7CjXYpjA   5   1      27311            0     22.7mb         11.3mb
green  open   new-2018-10-17 MRlDfdv9R6W1DVIoVpJrIA   5   1        533            0      1.6mb          827kb
green  open   new-2018-10-18 5AAnsa39RA25LazC2OTGuw   5   1     134330            0     96.6mb         48.3mb
green  open   it-2018-10-20  KCPG5BYsSjKbn5zWHefcNw   5   1      44859            0     39.5mb         19.7mb
green  open   new-2018-10-16 0HLQxPBDTFCDnUrH5DBAjg   5   1        534            0      1.9mb        991.5kb
green  open   new-2018-10-15 8KbTT7EOR1yVo1XRf0gWLA   5   1       4426            0      5.7mb          2.9mb
green  open   abc-2018-10-20 GVQJBgLgTrepLyHqXg8vYA   5   1     114318            0     89.3mb         44.6mb
green  open   it-2018-10-23  eVBWUpZqSNShBoUaee2y7Q   5   1      14988            0       14mb          7.1mb

列出ES集群中所有的field data信息
[root@vstjlogstash01 logstash]# curl -s 'http://10.67.51.150:9200/_cat/fielddata?v'
id                     host         ip           node   field                                                     size
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 beats_stats.metrics.beat.info.ephemeral_id               4.3kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 logstash_stats.pipelines.vertices.id                     1.9kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 apache2.access.user_agent.os_name                           0b
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 logstash_stats.pipelines.queue.type                      2.5kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 system.auth.ssh.event                                       0b
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 source_node.name                                         4.3kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 shard.index                                             17.6kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 logstash_stats.pipelines.id                              2.5kb
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 system.auth.hostname                                        0b
sLZDyxbqROywEOwLwWqHpw 10.67.51.149 10.67.51.149 stjes3 beats_stats.beat.type                                    1.7kb


[root@master1 ~]# curl -sH "Content-Type: application/json" -XGET "http://10.67.36.53:9200/new-2018-10-13/_search/" -d '{"query": {"bool": {"must": [{"term": {"kubernetes.namespace_name.keyword": "kube-system"}}],"must_not": [],"should": []}},"from": 0,"size": 10,"sort": [],"aggs": {}}' |python -m json.tool |jq '.'

{
  "_shards": {
    "failed": 0,
    "skipped": 0,
    "successful": 5,
    "total": 5
  },
  "hits": {
    "hits": [
      {
        "_id": "I58UbGYBLXittPaufLEA",
        "_index": "new-2018-10-13",
        "_score": 4.6962476,
        "_source": {
          "@timestamp": "2018-10-13T06:16:22.000000000+00:00",
          "docker": {
            "container_id": "394def5ecbc2cf175f25c9b8f37919748b9275169a496d2aa2d5e6257060f14e"
          },
          "kubernetes": {
            "container_image": "rancher/calico-node:v3.1.1",
            "container_image_id": "docker-pullable://rancher/calico-node@sha256:21d581d7356f2dba648f2905502a38fd4ae325fd079d377bcf94028bcfa577a3",
            "container_name": "calico-node",
            "host": "worker2",
            "labels": {
              "controller-revision-hash": "2111978372",
              "k8s-app": "canal",
              "pod-template-generation": "1"
            },
            "master_url": "https://10.43.0.1:443/api",
            "namespace_id": "29f5deaa-b0ba-11e8-895c-000c29fba296",
            "namespace_labels": {
              "field_cattle_io/projectId": "p-zbn8t"
            },
            "namespace_name": "kube-system",
            "pod_id": "805e9786-ceaf-11e8-89b6-000c29180c25",
            "pod_name": "canal-9dz94"
          },
          "log": "2018-10-13 06:16:22.182 [INFO][9] startup.go 251: Early log level set to info\n",
          "log_type": "k8s_normal_container",
          "stream": "stdout",
          "tag": "cluster.var.log.containers.canal-9dz94_kube-system_calico-node-394def5ecbc2cf175f25c9b8f37919748b9275169a496d2aa2d5e6257060f14e.log"
        },
        "_type": "container_log"
      },
#####node features usage######
[root@vstjlogstash01 logstash]# curl -XGET http://10.67.51.150:9200/_nodes/stjes2/usage | python -m json.tool
{
    "_nodes": {
        "failed": 0,
        "successful": 1,
        "total": 1
    },
    "cluster_name": "es-prod",
    "nodes": {
        "BdLnYgiKSBuo-Kw4NvIj1g": {
            "rest_actions": {
                "bulk_action": 5181109,
                "cluster_get_settings_action": 7,
                "cluster_health_action": 391125,
                "cluster_state_action": 4,
                "delete_index_action": 1,
                "delete_index_template_action": 1,
                "document_get_action": 66237,
                "document_index_action": 2,
                "document_update_action": 12,
                "force_merge_action": 34,
                "get_field_mapping_action": 2,
                "get_index_template_action": 31,
                "get_settings_action": 13,
                "indices_segments_action": 1,
                "indices_stats_action": 9,
                "main_action": 262256,
                "nodes_hot_threads_action": 2,
                "nodes_info_action": 516903,
                "nodes_stats_action": 9,
                "nodes_usage_action": 1,
                "put_index_template_action": 4,
                "search_action": 1847990,
                "update_settings_action": 3,
                "xpack_info_action": 220413,
                "xpack_monitoring_bulk_action": 1670918
            },
            "since": 1562663413037,
            "timestamp": 1563325520673
        }
    }
}
	  
# 去重查询beat.hostname
分别查询
filebeat-*-2021.02.*
winlogbeat-*-2021.02.*


curl -XPOST --cacert ~/mycert/certs/ca/ca.crt -u elastic https://xtjcesbges01.cesbg.foxconn:9200/winlogbeat-7.12.0-2022.02.*/_search -H 'Content-Type: application/json' -d'
 {"size":"500",
 "query":{
   "wildcard":{
     "agent.version":"7.*"
     }
   },
   "collapse":{
     "field":"host.hostname"
   }
 }
 ' | jq -r '.hits.hits[]._source.host.hostname'

[root@stjes1 ~]# curl -X POST "10.67.51.147:9200/filebeat-6.8.1-2022.07.*/_search" -H 'Content-Type: application/json' -d'
 {"size":"500",
 "query":{
   "wildcard":{
     "beat.version":"6.*"
     }
   },
   "collapse":{
     "field":"beat.hostname"
   }
 }
 ' | jq -r '.hits.hits[]._source.beat.hostname'
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  8497  100  8372  100   125   4315     64  0:00:01  0:00:01 --:--:--  4315
vSTJA2A01
node-3.domain.tld
node-1.domain.tld
node-2.domain.tld
stjes2
stjes3
node-10.domain.tld
stjes1
node-41.domain.tld
k8s-node1
[root@stjes1 ~]#


[root@stjes1 ~]# curl -XGET http://10.67.51.150:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason |grep UNA
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 27557  100 27557    0     0    99kwinlogbeat-6.8.1-2021.12.30       2 r UNASSIGNED NODE_LEFT
    winlogbeat-6.8.1-2021.12.30       0 r UNASSIGNED NODE_LEFT
  0filebeat-6.2.4-2021.12.30         0 r UNASSIGNED NODE_LEFT
 --docker-2021.12.23                 1 r UNASSIGNED NODE_LEFT
:--docker-2021.12.23                 0 r UNASSIGNED NODE_LEFT
:--docker-2022.01.01                 1 r UNASSIGNED NODE_LEFT
 --docker-2022.01.01                 0 r UNASSIGNED NODE_LEFT
:--docker-2021.12.31                 2 r UNASSIGNED NODE_LEFT
:--docker-2021.12.31                 0 r UNASSIGNED NODE_LEFT
 --syslog-2022.01.09                 0 r UNASSIGNED NODE_LEFT

######## elasticsearch-sql-cli
curl -X PUT "http://10.67.51.150:9200/library/book/_bulk?refresh&pretty" -H 'Content-Type: application/json' -d'
{"index":{"_id": "Leviathan Wakes"}}
{"name": "Leviathan Wakes", "author": "James S.A. Corey", "release_date": "2011-06-02", "page_count": 561}
{"index":{"_id": "Hyperion"}}
{"name": "Hyperion", "author": "Dan Simmons", "release_date": "1989-05-26", "page_count": 482}
{"index":{"_id": "Dune"}}
{"name": "Dune", "author": "Frank Herbert", "release_date": "1965-06-01", "page_count": 604}
'

[root@stjes1 ~]# /usr/share/elasticsearch/bin/elasticsearch-sql-cli http://10.67.51.147:9200

sql> select * from library;
     author     |     name      |  page_count   |      release_date
----------------+---------------+---------------+------------------------
Dan Simmons     |Hyperion       |482            |1989-05-26T00:00:00.000Z
James S.A. Corey|Leviathan Wakes|561            |2011-06-02T00:00:00.000Z
Frank Herbert   |Dune           |604            |1965-06-01T00:00:00.000Z 

sql> show tables "filebeat-*";
          name           |     type
-------------------------+---------------
filebeat-6.2.3-2022.01.07|BASE TABLE
filebeat-6.2.4-2021.12.29|BASE TABLE
filebeat-6.2.4-2021.12.30|BASE TABLE
filebeat-6.2.4-2021.12.31|BASE TABLE
filebeat-6.2.4-2022.01.01|BASE TABLE
filebeat-6.2.4-2022.01.02|BASE TABLE



sql> select '@timestamp',host,message from "syslog-2022.01.18" limit 5;
 '@timestamp'  |     host      |                                                                                         message
---------------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
@timestamp     |10.67.51.18    |<167>2022-01-18T01:00:43.064Z A21VSAN18 Vpxa: verbose vpxa[6D8CB70] [Originator@6876 sub=VpxaHalCnxHostagent opID=WFU-1124d8de] Received WaitForUpdatesDone callback

@timestamp     |10.67.51.18    |<167>2022-01-18T01:00:43.064Z A21VSAN18 Vpxa: verbose vpxa[6D8CB70] [Originator@6876 sub=VpxaHalCnxHostagent opID=WFU-1124d8de] Completed WaitForUpdatesDone callback

@timestamp     |10.67.51.18    |<167>2022-01-18T01:00:43.094Z A21VSAN18 Vpxa: verbose vpxa[6AFFB70] [Originator@6876 sub=VpxaHalCnxHostagent opID=WFU-28a7c199] Applying updates from 28475812 to 28475813 (at 28475812)

@timestamp     |10.67.51.18    |<167>2022-01-18T01:00:43.064Z A21VSAN18 Vpxa: verbose vpxa[6D8CB70] [Originator@6876 sub=VpxaHalCnxHostagent opID=WFU-1124d8de] Starting next WaitForUpdates() call to hostd

@timestamp     |10.67.51.18    |<167>2022-01-18T01:00:43.072Z A21VSAN18 Vpxa: verbose vpxa[6D6BB70] [Originator@6876 sub=VpxaHalCnxHostagent opID=WFU-a19df9d] Received WaitForUpdatesDone callback


POST /_sql?format=txt
{
    "query" : "select \"@timestamp\",responsetime/1000/1000,url from \"tomcat-access-plm-2023.04\" where domain.keyword = 'cesbgpdm.efoxconn.com' order by responsetime desc"
}
       @timestamp       |responsetime/1000/1000|                                                                             url                                                                             
------------------------+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------
2023-04-10T06:00:00.523Z|1514.2126             |/Windchill/ptc1/foxconn/action/bom/pcbabom/PCBABOMReleaseAction/createOrUpdateBOM                                                                            
2023-04-10T06:12:38.002Z|1494.759              |/Windchill/ptc1/comp/folderbrowser_table                                                                                                                     
2023-04-10T06:08:37.713Z|1460.2518             |/Windchill/ptc1/comp/folderbrowser_table                                                                                                                     
2023-04-10T06:08:37.713Z|1449.283              |/Windchill/ptc1/comp/netmarkets.product.list                                                                                                                 
2023-04-10T06:08:15.678Z|1442.6688             |/Windchill/servlet/ActionsMenu                                                                                                                               

# 天津ES正式环境查询
1 term查询
 curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_search -H 'Content-Type: application/json' -d '
{
     "query": {
        "term": {
          "domain.keyword": {
             "value": "ehs.cesbg.efoxconn.com"
            }
        }
    }
}'

count查询条数
 curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_count -H 'Content-Type: application/json' -d '
{
     "query": {
        "term": {
          "domain.keyword": {
             "value": "ehs.cesbg.efoxconn.com"
            }
        }
    }
}'

[root@xtjcesbges01 ~]# curl -s -XGET --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_count?q=domain.keyword:ehs.cesbg.efoxconn.com | jq .
Enter host password for user 'elastic':
{
  "count": 2657,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  }
}




regexp查询条数
{
     "query": {
        "regexp": {
          "domain.keyword": {
             "value": ".*"
            }
        }
    }
}'


GET /tomcat-access-hr*/_search?q=domain:(mongodb.flownet.efoxconn.com or flownet.efoxconn.com) AND @timestamp:[2023-04-09 TO 2023-04-10]

查询client_ip.keyword总记录数，去重记录数
curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_search?size=0 -H 'Content-Type: application/json' -d '
{
  "aggs": {
    "Value_Count": {
      "value_count": {
        "field": "client_ip.keyword"
      }
    },
    "Cardinality_Default": {
      "cardinality": {
        "field": "client_ip.keyword"
      }
    },
    "Cardinality_40K": {
      "cardinality": {
        "field": "client_ip.keyword",
        "precision_threshold": 40000
      }
    }
  }
}'
结果
{
  "took": 81,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 10000,
      "relation": "gte"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "Value_Count": {
      "value": 542690
    },
    "Cardinality_Default": {
      "value": 8
    },
    "Cardinality_40K": {
      "value": 8
    }
  }
}

 curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_search -H 'Content-Type: application/json' -d '
{
     "query": {
        "term": {
          "domain.keyword": {
             "value": "hr.cesbg.efoxconn.com"
            }
        }
    },
	  "aggs": {
    "Value_Count": {
      "value_count": {
        "field": "client_ip.keyword"
      }
    },
    "Cardinality_Default": {
      "cardinality": {
        "field": "client_ip.keyword"
      }
    },
    "Cardinality_40K": {
      "cardinality": {
        "field": "client_ip.keyword",
        "precision_threshold": 400000
      }
    }
  }
}'

# count 并且group by domain.keyword
post /tomcat-access-hr*/_search?size=0
{
  "aggs": {
    "genres": {
      "terms": {
        "field": "domain.keyword",
        "order": { "_count": "desc"}
      }
    }
  }
}
"aggregations" : {
    "genres" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 328538,
      "buckets" : [
        {
          "key" : "sso.cesbg.efoxconn.com",
          "doc_count" : 46981599
        },
        {
          "key" : "hr.cesbg.efoxconn.com",
          "doc_count" : 12722132
        },
        {
          "key" : "flownet.efoxconn.com",
          "doc_count" : 7682784
        },
        {
          "key" : "amp.cesbg.efoxconn.com",
          "doc_count" : 5812613
        },
        {
          "key" : "hredu.cesbg.efoxconn.com",
          "doc_count" : 2150857
        },
        {
          "key" : "ssoqa.cesbg.efoxconn.com",
          "doc_count" : 966118
        },
        {
          "key" : "hrreport.cesbg.efoxconn.com",
          "doc_count" : 884088
        },
        {
          "key" : "flowable.flownet.efoxconn.com",
          "doc_count" : 669064
        },
        {
          "key" : "ehs.cesbg.efoxconn.com",
          "doc_count" : 618110
        },
        {
          "key" : "Api.flownet.efoxconn.com",
          "doc_count" : 156227
        }
      ]
    }
  }


curl -XPOST --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-2023.01.04/_search?size=0 -H 'Content-Type: application/json' -d '
{
  "aggs": {
    "Cardinality_Default": {
      "cardinality": {
        "field": "domain.keyword"
      }
    }
  }
}'

curl -XPUT --cacert /etc/elasticsearch/certs/ca.crt  -u elastic https://xtjcesbges01.cesbg.foxconn:9200/library/book/_bulk?refresh&pretty" -H 'Content-Type: application/json' -d'
{"index":{"_id": "Leviathan Wakes"}}
{"name": "Leviathan Wakes", "author": "James S.A. Corey", "release_date": "2011-06-02", "page_count": 561}
{"index":{"_id": "Hyperion"}}
{"name": "Hyperion", "author": "Dan Simmons", "release_date": "1989-05-26", "page_count": 482}
{"index":{"_id": "Dune"}}
{"name": "Dune", "author": "Frank Herbert", "release_date": "1965-06-01", "page_count": 604}
'

get /cloudmes-wms-ims-2023.03/_search
{
  "query": { 
    "bool": { 
      "must": [
        { "match": { "agent.hostname":"XTJCloudMES-SaaS01"        }}
            ],
      "filter": [ 
                { "range": { "@timestamp": { "gte": "2023-03-01" }}}
      ]
    }
  },
  "sort": [
    {"@timestamp":"desc"}
    ],
  "_source": [
  "@timestamp",
  "container.labels.io_kubernetes_container_name",
  "message"
  ]
}

get /filebeat-7.12.0-2023.03*/_search
{
  "query": { 
    "bool": { 
      "must": [
        { "match": { "agent.hostname":"xtjbasecache01"        }}
            ],
      "filter": [ 
                { "term":  { "event.dataset": "redis.slowlog" }},
                { "range": { "@timestamp": { "gte": "2023-03-01" }}}
      ]
    }
  },
  "sort": [
    {"@timestamp":"desc"}
    ],
  "_source": [
  "@timestamp",
  "redis.slowlog.cmd",
  "redis.slowlog.key",
  "redis.slowlog.duration.us"
  ]
}

agent.hostname:"xtjbasecacheap*"

filter {
  ruby {
    code => "
      wanted_fields = ['agent.hostname', 'event.dataset','redis.slowlog.cmd','redis.slowlog.key','redis.slowlog.duration.us']
      event.to_hash.keys.each { |k|
        event.remove(k) unless wanted_fields.include? k
      }
    "
  }
}

{"find":"terms","field":"event.dataset","query":"redis.slowlog"}        event.dataset:"redis.slowlog"


# filter
curl -q --noproxy '*' -XPOST -k -u "logstash_writer:vSTJ456" https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-plm-2023.04/_search -H 'Content-Type: application/json' -d \
'{
     "query": {
        "bool": {
          "filter": [
          {"term": {"url.keyword":"/Windchill/servlet/RPC"}}
          ]
         }
    },
     "size":500,
     "_source": [
         "domain",
         "url",
         "status"
      ]

}' | jq .hits.hits

# query_string (lucene query)
curl -q --noproxy '*' -XGET -k -u "logstash_writer:vSTJ456" https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-plm-2023.04/_search?pretty -H 'Content-Type: application/json' -d \
'{
     "query": {
        "query_string": {
          "query": "(url.keyword: \\/Windchill\\/servlet\\/RPC)"
         }
    },
     "size":500,
     "_source": [
         "domain",
         "url",
         "status"
      ]

}' | jq .hits.hits


#  query 
curl -q --noproxy '*' -XPOST -k -u "logstash_writer:vSTJ456" https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-plm-2023.04/_search -H 'Content-Type: application/json' -d \
'{
     "query": {
        "term": {
          "url.keyword": {
             "value": "/Windchill/servlet/RPC"
            }
        }
    },
     "size":500,
     "_source": [
         "domain",
         "url",
         "status"
      ]

}' | jq .hits.hits

# uri中用lucene query
curl --noproxy '*' -XGET -k -u "logstash_writer:vSTJ456" "https://xtjcesbges01.cesbg.foxconn:9200/tomcat-access-plm-2023.04/_search?q=url.keyword:\\/Windchill\\/servlet\\/RPC&_source=domain,url" | jq .hits.hits




# 龙华 ES
[root@xlhcesbges01 ~]# curl -XGET -k -u elastic:vSTJ456 https://xlhcesbges01.cesbg.foxconn:9200/_cat/nodes
10.134.241.75 52 74 0 0.01 0.03 0.05 ilr         - xlhcesbges02
10.134.241.95 22 95 0 0.26 0.29 0.31 cdfhilmrstw - xlhcesbges05
10.134.241.90 48 92 0 0.39 0.43 0.50 cdfhilmrstw * xlhcesbges04
10.134.241.86 24 98 0 1.06 0.98 0.72 cdfhilmrstw - xlhcesbges03
10.134.241.70 32 74 0 0.10 0.09 0.06 ilr         - xlhcesbges01

# 查看docs.deleted
get _cat/indices?v=true&h=index,health,pri,rep,pri.store.size,docs.count,docs.deleted&s=index:desc
winlogbeat-7.12.0-2023.06.15                            green    1   1         26.6gb   39177248     16657706
winlogbeat-7.12.0-2023.06.14                            green    1   1           24gb   51522228      1994624
winlogbeat-7.12.0-2023.06.13                            green    1   1         22.9gb   49239994      1886164
winlogbeat-7.12.0-2023.06.12                            green    1   1           22gb   48108944      1930224
winlogbeat-7.12.0-2023.06.11                            green    1   1         17.8gb   43065519      2628022
winlogbeat-7.12.0-2023.06.10                            green    1   1         21.9gb   50581158      2005738
winlogbeat-7.12.0-2023.06.09                            green    1   1         22.7gb   50398392      2182926
winlogbeat-7.12.0-2023.06.08                            green    1   1         20.9gb   45179953      2533172
winlogbeat-7.12.0-2023.06.07                            green    1   1          7.5gb   15203896      2753887
winlogbeat-7.12.0-2023.06.06                            green    1   1          9.9gb   20277319      2287820
winlogbeat-7.12.0-2023.06.05                            green    1   1         22.8gb   51864321      1829834
winlogbeat-7.12.0-2023.06.04                            green    1   1           18gb   42761280      4407292
winlogbeat-7.12.0-2023.06.03                            green    1   1         22.2gb   50121309      2975845
winlogbeat-7.12.0-2023.06.02                            green    1   1         23.9gb   47658617     11758094
winlogbeat-7.12.0-2023.06.01                            green    1   1         25.2gb   47360457     17174131
winlogbeat-7.12.0-2023.05.31                            green    1   1         23.4gb   51364945      3000142
winlogbeat-7.12.0-2023.05.30                            green    1   1         22.3gb   48670263      3080294
winlogbeat-7.12.0-2023.05.29                            green    1   1         22.4gb   49151590      2971724
winlogbeat-7.12.0-2023.05.28                            green    1   1         17.7gb   43537224      3603010
winlogbeat-7.12.0-2023.05.27                            green    1   1         20.1gb   47844601      3100448
winlogbeat-7.12.0-2023.05.26                            green    1   1           22gb   49268745      3017946
winlogbeat-7.12.0-2023.05.25                            green    1   1         25.9gb   56788565      2766916
winlogbeat-7.12.0-2023.05.24                            green    1   1         23.7gb   50116372      2753916
winlogbeat-7.12.0-2023.05.23                            green    1   1         22.9gb   49344869      2428838
winlogbeat-7.12.0-2023.05.22                            green    1   1         22.7gb   49478309      2779936
winlogbeat-7.12.0-2023.05.21                            green    1   1         17.5gb   42526588      3329988
winlogbeat-7.12.0-2023.05.20                            green    1   1         22.6gb   56145150      2114856
winlogbeat-7.12.0-2023.05.19                            green    1   1         26.1gb   63922215      1161776
winlogbeat-7.12.0-2023.05.18                            green    1   1         24.8gb   52745714      2580880
winlogbeat-7.12.0-2023.05.17                            green    1   1         23.7gb   55100399      2687440
winlogbeat-7.12.0-2023.05.16                            green    1   1         27.1gb   65428125      2259578
winlogbeat-7.12.0-2023.05.15                            green    1   1         24.4gb   52523444      2527360
winlogbeat-7.12.0-2023.05.14                            green    1   1         18.2gb   43987600      3772552
winlogbeat-7.12.0-2023.05.13                            green    1   1         22.3gb   51754467      2859844
winlogbeat-7.12.0-2023.05.12                            green    1   1         23.6gb   52084182      2480404
winlogbeat-7.12.0-2023.05.11                            green    1   1         23.8gb   51705737      2547924
winlogbeat-7.12.0-2023.05.10                            green    1   1           25gb   55801443      2691832
winlogbeat-7.12.0-2023.05.09                            green    1   1         24.2gb   55455263      2764248
winlogbeat-7.12.0-2023.05.08                            green    1   1         23.1gb   50212000      2777868
winlogbeat-7.12.0-2023.05.07                            green    1   1         18.4gb   44824811      1828331
winlogbeat-7.12.0-2023.05.06                            green    1   1         22.9gb   52982617      2955750
winlogbeat-7.12.0-2023.05.05                            green    1   1         24.9gb   54708784      2583342
winlogbeat-7.12.0-2023.05.04                            green    1   1         26.4gb   64621066      2923422
winlogbeat-7.12.0-2023.05.03                            green    1   1         23.3gb   63885318      1271182
winlogbeat-7.12.0-2023.05.02                            green    1   1         18.3gb   45652792      3605096
winlogbeat-7.12.0-2023.05.01                            green    1   1         16.1gb   40362380      3695662

# delete by query
POST winlogbeat-7.12.0-2023.03.*/_delete_by_query?wait_for_completion=false&scroll_size=10000
{
  "query": {
    "term": {
	  "agent.hostname": "vSTJEPDIWeb"
    }
  }
}

GET _cat/tasks?v

GET _tasks?detailed=true&actions=*/delete/byquery

GET /_tasks/jZf1uR1mQN2JQdNs5kTFng:4457949


POST _tasks/task_id:3801434/_cancel 