Redis (Remote dictionary server) 

1 redis上线及升级
2 redis用户权限管理
3 redis监控及巡检
4 redis集群及弹性伸缩
5 redis故障排错、持续性能优化
6 redis数据导入、导出、迁移、备份和还原

### 远程连接
redis-cli -u redis://10.67.50.41:6379
redis-cli -h 10.67.50.41 -p 6379

### redis 密码认证
方式一
root@redis001 ~# export REDISCLI_AUTH=120hzPpmK616xYMYLwxXPyxV+FQvsGdJrDpZEDMelScN1ayzLXkLs3vlZvM+g7wa8LFTqSc60uW2cxaQPJ2WSlh1DlYOPROGnOUY4BRHD7yHWClEi0xMxRAb
root@redis001 ~# redis-cli ping
PONG
方式二  交互模式
root@redis001 ~# redis-cli
127.0.0.1:6379> AUTH 120hzPpmK616xYMYLwxXPyxV+FQvsGdJrDpZEDMelScN1ayzLXkLs3vlZvM+g7wa8LFTqSc60uW2cxaQPJ2WSlh1DlYOPROGnOUY4BRHD7yHWClEi0xMxRAb
OK
方式三  输入密码
root@redis001 ~# redis-cli -a 120hzPpmK616xYMYLwxXPyxV+FQvsGdJrDpZEDMelScN1ayzLXkLs3vlZvM+g7wa8LFTqSc60uW2cxaQPJ2WSlh1DlYOPROGnOUY4BRHD7yHWClEi0xMxRAb

# 客户端登录option   默认是 version 3
[root@rancher ~]# redis-cli -h 10.67.50.41
10.67.50.41:6379> hello 3 auth default Foxconn123 setname senchen

[root@rancher ~]# redis-cli -h 10.67.50.41
10.67.50.41:6379> hello 2 auth default Foxconn123 setname senchen
###########redis aof文件重写############
Redis将生成一个新的AOF文件， 这个文件包含重建当前数据集所需的最少命令



#####  redis 基本用法 ######
连接本地unix socket
redis-cli -s /var/run/redis/redis.sock

#### 数据类型
1 string
keys '*'  查询所有健
set mongo "it's document DB"
get mongo  查询mongo这个健的健值
127.0.0.1:6379> mget mongo mysql
1) "This is mongo cookbook"
2) "I like mysql"

127.0.0.1:6379> keys *
1) "test07"
2) "test02"
3) "test01"
4) "test06"
5) "test05"
6) "test04"
7) "test03"
8) "test"
9) "test08"
127.0.0.1:6379> scan 0 match test* count 2
1) "10"
2) 1) "test05"
   2) "test02"
127.0.0.1:6379> scan 5 match test* count 2
1) "3"
2) 1) "test01"
   2) "test04"
   3) "test03"
   4) "test"
127.0.0.1:6379> scan 3 match test* count 2
1) "0"
2) 1) "test08"


2 hash
set键为record1的hash表
127.0.0.1:6379> hset record1 name "chensen"
(integer) 1
127.0.0.1:6379> hset record1 age 40
(integer) 1F0xc0nn!23

127.0.0.1:6379> hkeys record1        获取record1的hash field
1) "name"
2) "age"
127.0.0.1:6379> hmget record1 name age  获取record1的hash field的值
1) "chensen"
2) "40"
127.0.0.1:6379> hvals record1         获取record1哈希表里所有的值
1) "chensen"
2) "40"

127.0.0.1:6379> hscan test05 0
1) "0"
2)  1) "uid"
    2) "['test05']"
    3) "objectClass"
    4) "['top', 'person', 'organizationalPerson', 'inetorgperson']"
    5) "userPassword"
    6) "['{MD5}VI5MNrhB+cDSTa1w/A5x0g==']"
    7) "sn"
    8) "['test05']"
    9) "givenName"
   10) "['test05']"
   11) "cn"
   12) "['test05']"
127.0.0.1:6379> hscan test05 0 match "*n"
1) "0"
2) 1) "sn"
   2) "['test05']"
   3) "cn"
   4) "['test05']"


3 集合
127.0.0.1:6379> sadd os CentOS Windows Debian Ubuntu AIX HPUX Solaris
(integer) 7
127.0.0.1:6379> scard os
(integer) 7
127.0.0.1:6379> smembers os
1) "CentOS"
2) "Windows"
3) "Debian"
4) "Ubuntu"
5) "AIX"
6) "Solaris"
7) "HPUX"

4 列表
127.0.0.1:6379> lpush dept sa oa gscm b2b hr sap
(integer) 6

127.0.0.1:6379> lrange dept 0 5
1) "sap"
2) "hr"
3) "b2b"
4) "gscm"
5) "oa"
6) "sa"
127.0.0.1:6379> llen dept
(integer) 6
127.0.0.1:6379> lindex dept 4
"oa"
127.0.0.1:6379> lset dept 4 OA        改
OK
127.0.0.1:6379> lindex dept 4
"OA"

5 有序集合
127.0.0.1:6379> zadd db 1 redis
(integer) 1
127.0.0.1:6379> zadd db 2 mongo
(integer) 1
127.0.0.1:6379> zadd db 3 elasticsearch
(integer) 1
127.0.0.1:6379> zadd db 3 clickhouse
(integer) 1
127.0.0.1:6379> zadd db 9 Oracle
(integer) 1
127.0.0.1:6379> zadd db 8 Postgres
(integer) 1

127.0.0.1:6379> zrange db 0 5 withscores
 1) "redis"
 2) "1"
 3) "mongo"
 4) "2"
 5) "clickhouse"
 6) "3"
 7) "elasticsearch"
 8) "3"
 9) "Postgres"
10) "8"
11) "Oracle"
12) "9"
127.0.0.1:6379> zrevrange db 0 5 withscores
 1) "Oracle"
 2) "9"
 3) "Postgres"
 4) "8"
 5) "elasticsearch"
 6) "3"
 7) "clickhouse"
 8) "3"
 9) "mongo"
10) "2"
11) "redis"
12) "1"

6 stream
Redis Stream 是 Redis 5.0 版本新增加的数据结构。
Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。
简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。
而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。

每个 Stream 都有唯一的名称，它就是 Redis 的 key

同一个group的消费者不能重复读消息
last_delivered_id ：游标，每个消费组会有个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。

6.1 首先xadd建立stream

6.2 接着建立stream的consumer group      消费组从第一条消息开始消费，如果从最后开始消费，则用$
>> xgroup create sensor group2 0
"OK"

6.3 消费者cs从group2消费消息  每次消费2条
xreadgroup group group2 cs count 2 streams sensor >

1) 1) "sensor"
   2) 1) 1) "1675842547425-0"
         2) 1) "f1"
            2) "v1"
            3) "f2"
            4) "v2"
            5) "f3"
            6) "v3"
      2) 1) "1675842584792-0"
         2) 1) "f1"
            2) "v11"
            3) "f2"
            4) "v21"
            5) "f3"
            6) "v31"
>> xreadgroup group group2 cs count 2 streams sensor >

1) 1) "sensor"
   2) 1) 1) "1675842926111-0"
         2) 1) "f1"
            2) "v13"
            3) "f2"
            4) "v23"
            5) "f3"
            6) "v33"
      2) 1) "1675843746295-0"
         2) 1) "f1"
            2) "v14"
            3) "f2"
            4) "v24"
            5) "f3"
            6) "v34"
>> xreadgroup group group2 cs count 2 streams sensor >

1) 1) "sensor"
   2) 1) 1) "1675843788224-0"
         2) 1) "f1"
            2) "v15"
            3) "f2"
            4) "v25"
            5) "f3"
            6) "v35"

>> xreadgroup group group2 csm count 2 streams sensor >

(nil)			

# Pending Entries List
从stream角度看
10.67.50.41:6379> xinfo groups sensor
1) 1# "name" => "cg-1"
   2# "consumers" => (integer) 1
   3# "pending" => (integer) 0
   4# "last-delivered-id" => "0-0"
   5# "entries-read" => (nil)
   6# "lag" => (integer) 5
2) 1# "name" => "group1"
   2# "consumers" => (integer) 1
   3# "pending" => (integer) 2
   4# "last-delivered-id" => "1675843788224-0"
   5# "entries-read" => (integer) 5
   6# "lag" => (integer) 0
3) 1# "name" => "group2"
   2# "consumers" => (integer) 1
   3# "pending" => (integer) 4
   4# "last-delivered-id" => "1675843788224-0"
   5# "entries-read" => (integer) 5
   6# "lag" => (integer) 0
4) 1# "name" => "mygroup"
   2# "consumers" => (integer) 1
   3# "pending" => (integer) 0
   4# "last-delivered-id" => "0-0"
   5# "entries-read" => (nil)
   6# "lag" => (integer) 5
 
从消费组的角度看 
10.67.50.41:6379> xinfo consumers sensor group2
1) 1# "name" => "cs"
   2# "pending" => (integer) 4
   3# "idle" => (integer) 1832214
10.67.50.41:6379> xpending sensor group2
1) (integer) 5
2) "1675842547425-0"
3) "1675843788224-0"
4) 1) 1) "cs"
      2) "5"   
确认一条消息
10.67.50.41:6379> xack sensor group2 1675843788224-0
(integer) 1
10.67.50.41:6379> xinfo consumers sensor group2
1) 1# "name" => "cs"
   2# "pending" => (integer) 3
   3# "idle" => (integer) 2162663
10.67.50.41:6379> xpending sensor group2
1) (integer) 3
2) "1675842584792-0"   头
3) "1675843746295-0"   尾
4) 1) 1) "cs"
      2) "3"
   


   
# 查看redis版本
LOLWUT
hello

# 客户端登录option
[root@rancher ~]# redis-cli -h 10.67.50.41
10.67.50.41:6379> hello 3 auth default Foxconn123 setname senchen
1# "server" => "redis"
2# "version" => "7.0.5"
3# "proto" => (integer) 3
4# "id" => (integer) 250911
5# "mode" => "standalone"
6# "role" => "master"
7# "modules" => (empty array)
10.67.50.41:6379>
10.67.50.41:6379>
10.67.50.41:6379>
10.67.50.41:6379>
10.67.50.41:6379> client info
id=250911 addr=10.67.36.58:50090 laddr=172.18.0.9:6379 fd=11 name=senchen age=30 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=26 qbuf-free=20448 argv-mem=10 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22298 events=r cmd=client|info user=default redir=-1 resp=3

[root@rancher ~]# redis-cli -h 10.67.50.41
10.67.50.41:6379> hello 2 auth default Foxconn123 setname senchen
 1) "server"
 2) "redis"
 3) "version"
 4) "7.0.5"
 5) "proto"
 6) (integer) 2
 7) "id"
 8) (integer) 250918
 9) "mode"
10) "standalone"
11) "role"
12) "master"
13) "modules"
14) (empty array)

# client tracking on 通知key失效信息  
1 key过期了
2 key的值更新了
10.67.50.41:6379> client tracking on bcast prefix dns
OK

10.67.50.41:6379> get dns11
"1.11"
10.67.50.41:6379> get dns11
-> invalidate: 'dns10'
"1.11"
10.67.50.41:6379> get dns11
"1.11"
10.67.50.41:6379> get dns11
-> invalidate: 'dns11'
(nil)
10.67.50.41:6379> get dns11
(nil)
10.67.50.41:6379> get dns11
-> invalidate: 'dns12'
(nil)
10.67.50.41:6379> get dns11
(nil)
10.67.50.41:6379> get dns11
(nil)
10.67.50.41:6379> get dns11
-> invalidate: 'dns13'
(nil)

#实验数据  大批key,每秒很多过期
10.67.50.41:6379> get user:1:name
-> invalidate: 'user:177895:name'
-> invalidate: 'user:654696:name', 'user:871205:name'
-> invalidate: 'user:596536:name'
-> invalidate: 'user:682011:name'
-> invalidate: 'user:444096:name', 'user:559951:name'
-> invalidate: 'user:298408:name', 'user:350012:name'
-> invalidate: 'user:447868:name', 'user:694866:name', 'user:858568:name'
-> invalidate: 'user:259858:name'
-> invalidate: 'user:521533:name'
-> invalidate: 'user:55161:name'
-> invalidate: 'user:671212:name'
-> invalidate: 'user:238150:name', 'user:951223:name'
-> invalidate: 'user:909353:name'
-> invalidate: 'user:903835:name'
-> invalidate: 'user:743293:name'
-> invalidate: 'user:728264:name'
-> invalidate: 'user:161534:name'
-> invalidate: 'user:475947:name'
-> invalidate: 'user:185845:name'
-> invalidate: 'user:133876:name'
-> invalidate: 'user:887408:name'
-> invalidate: 'user:187153:name'


普通模式
当tracking开启时， Redis会「记住」每个客户端请求的 key，当 key的值发现变化时会发送失效信息给客户端 (invalidation message)。
失效信息可以通过 RESP3协议发送给请求的客户端，或者转发给一个不同的连接 (支持 RESP2 + Pub/Sub) 的客户端。
Server 端将 Client 访问的 key以及该 key 对应的客户端 ID 列表信息存储在全局唯一的表(TrackingTable)，当表满了，回移除最老的记录，同时触发该记录已过期的通知给客户端。
每个 Redis 客户端又有一个唯一的数字 ID，TrackingTable 存储着每一个 Client ID，当连接断开后，清除该 ID 对应的记录。
TrackingTable 表中记录的 Key 信息不考虑是哪个 database 的，虽然访问的是 db1 的 key，db2 同名 key 修改时会客户端收到过期提示，但这样做会减少系统的复杂性，以及表的存储数据量。

广播模式(BCAST)
当广播模式 (broadcasting) 开启时，服务器不会记住给定客户端访问了哪些键，因此这种模式在服务器端根本不消耗任何内存。
在这个模式下，服务端会给客户端广播所有 key 的失效情况，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。
所以，在实际应用中，我们设置让客户端注册只跟踪指定前缀的 key，当注册跟踪的 key 前缀匹配被修改，服务端就会把失效消息广播给所有关注这个 key前缀的客户端。

client tracking on bcast prefix user
1.
这种监测带有前缀的 key 的广播模式，和我们对 key 的命名规范非常匹配。我们在实际应用时，会给同一业务下的 key 设置相同的业务名前缀，所以，我们就可以非常方便地使用广播模式。Redis 6.0 新特性篇：Client Side Cache 是嘛玩意？-开源基础软件社区
广播模式与普通模式类似，Redis 使用 PrefixTable 存储广播模式下的客户端数据，它存储**前缀字符串指针和(需要通知的 key 和客户端 ID)**的映射关系。

转发模式
普通模式与广播模式，需要客户端使用 RESP 3 协议，他是 Redis 6.0 新启用的协议。
对于使用 RESP 2 协议的客户端来说，实现客户端缓存则需要另一种模式：重定向模式(redirect)。
RESP 2 无法直接 PUSH 失效消息，所以 需要另一个支持 RESP 3 协议的客户端 告诉 Server 将失效消息通过 Pus/Sub 通知给 RESP 2 客户端。
在重定向模式下，想要获得失效消息通知的客户端，就需要执行订阅命令 SUBSCRIBE，专门订阅用于发送失效消息的频道 _redis_:invalidate。

同时，再使用另外一个客户端，执行 CLIENT TRACKING 命令，设置服务端将失效消息转发给使用 RESP 2 协议的客户端。
假设客户端 B 想要获取失效消息，但是客户端 B 只支持 RESP 2 协议，客户端 A 支持 RESP 3 协议。我们可以分别在
客户端 B 和 A 上执行 SUBSCRIBE 和 CLIENT TRACKING，如下所示：
//客户端B执行，客户端 B 的 ID 号是 606
SUBSCRIBE _redis_:invalidate

//客户端 A 执行
CLIENT TRACKING ON BCAST REDIRECT 606
1.
2.
3.
4.
5.
B 客户端就可以通过 _redis_:invalidate 频道获取失效消息了。

# 查看 channel
10.66.14.103:6379> pubsub channels
1) "__sentinel__:hello"
2) "__keyevent@4__:expired"
3) "__keyevent@1__:expired"
4) "__keyevent@4__:del"
5) "__keyevent@3__:del"
6) "__keyevent@1__:del"
7) "__keyevent@3__:expired"
查看 channel的客户端数量
10.66.14.103:6379> pubsub numsub __keyevent@4__:expired
1) "__keyevent@4__:expired"
2) (integer) 1
10.66.14.103:6379> pubsub numsub __keyevent@3__:expired
1) "__keyevent@3__:expired"
2) (integer) 3

# 查看bigkey
[root@xtjqaredis01 redis]# redis-cli -h 10.66.14.103 --bigkeys

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).

[00.00%] Biggest string found so far '"account:IGA1-03205"' with 64 bytes
[01.54%] Biggest hash   found so far '"register:60C19DF5-F398-4355-9343-EA86501D1A8E"' with 17 fields
[11.58%] Biggest set    found so far '"client_api_auth_list:6C4105B7-AC72-48EB-8992-042B41AAA193"' with 46 members
[47.96%] Biggest hash   found so far '"register:44421C46-9BD0-4158-A492-95C57AA5FB8B"' with 19 fields

-------- summary -------

Sampled 10891 keys in the keyspace!
Total key length in bytes is 176298 (avg len 16.19)

Biggest   hash found '"register:44421C46-9BD0-4158-A492-95C57AA5FB8B"' has 19 fields
Biggest string found '"account:IGA1-03205"' has 64 bytes
Biggest    set found '"client_api_auth_list:6C4105B7-AC72-48EB-8992-042B41AAA193"' has 46 members

0 lists with 0 items (00.00% of keys, avg size 0.00)
112 hashs with 1788 fields (01.03% of keys, avg size 15.96)
10776 strings with 689100 bytes (98.94% of keys, avg size 63.95)
0 streams with 0 entries (00.00% of keys, avg size 0.00)
3 sets with 52 members (00.03% of keys, avg size 17.33)
0 zsets with 0 members (00.00% of keys, avg size 0.00)

# 查看命令统计
10.66.14.103:6379> info commandstats
# Commandstats
cmdstat_sync:calls=2,usec=1729,usec_per_call=864.50,rejected_calls=0,failed_calls=0
cmdstat_psync:calls=2,usec=1538,usec_per_call=769.00,rejected_calls=0,failed_calls=0
cmdstat_select:calls=56367,usec=123258,usec_per_call=2.19,rejected_calls=0,failed_calls=78
cmdstat_hset:calls=16829,usec=101992,usec_per_call=6.06,rejected_calls=0,failed_calls=0
cmdstat_renamenx:calls=1,usec=26,usec_per_call=26.00,rejected_calls=0,failed_calls=0
cmdstat_slowlog:calls=26627,usec=122887,usec_per_call=4.62,rejected_calls=0,failed_calls=0
cmdstat_command:calls=7,usec=5523,usec_per_call=789.00,rejected_calls=0,failed_calls=0
cmdstat_scard:calls=25,usec=112,usec_per_call=4.48,rejected_calls=0,failed_calls=0
cmdstat_pubsub:calls=7,usec=106,usec_per_call=15.14,rejected_calls=0,failed_calls=0
cmdstat_replconf:calls=32356063,usec=88062829,usec_per_call=2.72,rejected_calls=0,failed_calls=0
cmdstat_hmset:calls=1890833,usec=15507059,usec_per_call=8.20,rejected_calls=0,failed_calls=0

# 查看cache命中率
命中率= keyspace_hits/(keyspace_hits + keyspace_misses)
[root@xtjqaredis01 redis]# redis-cli -h 10.66.14.103 info stats |grep keyspace
keyspace_hits:4625545
keyspace_misses:3306808

# 内存碎片
Memory RSS (Resident Set Size) is the number of bytes that the operating system has allocated to Redis. If the ratio of ‘memory_rss’ to ‘memory_used’ is greater than ~1.5, 
then it signifies memory fragmentation. The fragmented memory can be recovered by restarting the server.

# 查看健的内部编码方式
127.0.0.1:6379> object encoding db
"skiplist"
127.0.0.1:6379> object encoding filebeat
"quicklist"
https://web-tj-1.fixo.cloud   sen.chen@mail.foxconn.com

#### 查看中文
root@redis001 ~# redis-cli --raw
127.0.0.1:6379> get redisdba
1 redis上线及升级
2 redis用户权限管理
3 redis监控及巡检
4 redis集群及弹性伸缩
5 redis故障排错、持续性能优化
6 redis数据迁移、备份和还原

# grafana插件redis-datasource
先export http_proxy
再grafana-cli plugins install redis-datasource

########导入数据
方法一    pipe   批量
root@redis001 ~# cat 22
SET H7104398    邓智勇
SET H7113074    孙佳伟
SET H7114524    程路峰
SET H7101057    邵玉雪

#cat 22 | redis-cli --pipe

方法2   shell 
root@redis001 ~# head -2 3
XTJ-B2B-IS-D1   10.66.12.56
XTJ-ESB-IS-D1   10.66.12.40
root@redis001 ~# while read name ip;do echo -en $ip | redis-cli -x set $name;done< <(cat 3 |awk '{print $1,$2}')
OK
OK


################ lua 脚本 ############
127.0.0.1:6379> eval "redis.call('SET',KEYS[1],ARGV[1])" 1 server2 10.67.9.200
(nil)
127.0.0.1:6379> get server2
"10.67.9.200"

############### python ###########
----------------------------------mysql -> redis
root@redis001 ~# cat mysql.py
#!/usr/bin/python
import MySQLdb
import redis

r = redis.Redis(host='10.67.50.131',port=6379,password='120hzPpmK616xYMYLwxXPyxV+FQvsGdJrDpZEDMelScN1ayzLXkLs3vlZvM+g7wa8LFTqSc60uW2cxaQPJ2WSlh1DlYOPROGnOUY4BRHD7yHWClEi0xMxRAb')
pipe = r.pipeline()

db = MySQLdb.connect("10.67.51.162","root","vSTJ456","zabbix",charset='utf8')
cursor = db.cursor()
cursor.execute("select username,name from users")
results = cursor.fetchall()

for row in results:
  key = row[0]
  value = row[1]
  pipe.set(key,value)

db.close()
pipe.execute()

---------------------------------ldap -> redis
[root@repo ~]# cat lsearch.py
#!/usr/bin/python
import ldap
import redis

r = redis.Redis(host='10.67.50.131',port=6379,password='120hzPpmK616xYMYLwxXPyxV+FQvsGdJrDpZEDMelScN1ayzLXkLs3vlZvM+g7wa8LFTqSc60uW2cxaQPJ2WSlh1DlYOPROGnOUY4BRHD7yHWClEi0xMxRAb')

pipe = r.pipeline()

conn = ldap.initialize("ldap://xygjsldap01.cesbg.fii")
conn.set_option(ldap.OPT_X_TLS_REQUIRE_CERT,ldap.OPT_X_TLS_NEVER)
conn.start_tls_s()
conn.simple_bind_s("cn=Directory Manager","Foxconn123321")

searchScope = ldap.SCOPE_SUBTREE
base_dn = 'dc=cesbg,dc=fii'
result = conn.search_s(base_dn,searchScope,"uid=test*",None)

for dn,entry in result:
  pipe.set(entry['givenName'][0],dn)

pipe.execute()

######### redis 原理 ############
### 1 输入缓冲区：qbuf、qbuf-free
Redis为每个客户端分配了输入缓冲区，作用是将客户端发送的命令临时保存，同时会从输入缓冲区读取命令并执行，它为Redis服务器提供了缓冲功能。
Redis无法配置输入缓冲区的大小，输入缓冲区会根据输入内容大小的不同动态调整，但是总体大小不能超过1G。

输入缓存区使用不当产生的问题：
客户端的输入缓冲区超过1G，客户端将会被强制关闭。
输入缓冲区不受maxmemory控制，如果redis实例的maxmemory设置了1G，已经存储800M数据， 如果此时输入缓冲区使用了500M，将总内存将超过maxmemory，可能会产生数据丢失、键值淘汰、OOM等情况
产生的原因：
redis处理速度跟不上输入缓冲区的输入速度，例如存在bigkey，慢查询等原因导致命令执行的时间变长。
写入命令量非常大，但此时redis服务器在执行持久化导致阻塞无法处理命令，导致命令大量积压在输入缓存区中。
解决方案：
client list 查看qbuf、qbuf-free来定位存在问题的客户端，分析原因加以处理。
info clients定期监控client_biggest_input_buf，设置预警阀值超过时发送报警邮件或短信 。

### 2 输出缓冲区：obl、oll、omem
Redis为每个客户端分配了输出缓冲区，作用是保存命令执行的结果返回给客户端为Redi与客户端交互返回结果提供了缓冲功能。
输出缓冲区的容量可以通过参数client-output-buffer-limit来进行设置。输出缓冲区不受maxmemory控制，如果redis使用内存总量+输出缓冲区的容量>maxmemory时，会产生数据丢失、键值淘汰、OOM等情况。
配置:
client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
<class>：客户端类型，分为三种。a）normal：普通客户端；b）slave：slave客户端，用于复制；c）pubsub：发布订阅客户端。
<hard limit>：如果客户端使用的输出缓冲区大于<hard limit>，客户端会被立即关闭。
<soft limit>和<soft seconds>：如果客户端使用的输出缓冲区超过了<soft limit>并且持续了<soft limit>秒，客户端会被立即关闭。
输出缓冲区按客户端的不同分为三种：普通客户端、发布订阅客户端、slave客户端：

** 输出缓冲区有两部分组成：固定缓冲区（16KB）和动态缓冲区：**
固定缓冲区用于保存那些长度比较小的回复，比如OK、简短的字符串值、整数值、错误回复等。
可变大小的缓冲区用于保存那些长度比较大的回复，比如一个非常长的字符串值，一个有很多元素组成的集合或列表。
client对象的结构：

固定缓冲区使用的是字节数组，动态缓冲区使用的是链表。当固定缓冲区存满后会将Redis新的返回结果存放在动态缓冲区的队列中，队列中的每个对象就是每个返回结果。

解决方案：
通过定期执行client list命令，收集obl、oll、omem找到异常的连接记录并分析，最终找到可能出问题的客户端。
info clients定期监控client_longest_output_list代表输出缓冲区列表最大对象数，设置预警阀值超过时发送报警邮件或短信 。
合理配置普通客户端输出缓冲区的大小。
如果master节点写入较大，适当增大slave的输出缓冲区的，slave客户端的输出缓冲区可能会比较大，一旦slave客户端连接因为输出缓冲区溢出被kill，会造成复制重连。
限制容易让输出缓冲区增大的命令，例如，高并发下的monitor命令就是一个危险的命令。
及时监控内存，一旦发现内存抖动频繁，可能就是输出缓冲区过大。
客户端的存活状态
client list中的age和idle分别代表当前客户端已经连接的时间和最近一次的空闲时间。当age等于idle时，说明连接一直处于空闲状态。
客户端的限制maxclients和timeout
maxclients参数来限制最大客户端连接数，一旦连接数超过maxclients，新的连接将被拒绝。maxclients默认值是10000，可以通过info clients来查询当前Redis的连接数。
某些情况由于业务方使用不当（例如没有主动关闭连接）可能存在大量idle连接，因此Redis提供了timeout（单位为秒）参数来限制连接的最大空闲时间合理使用有限的资源，一旦客户端连接的idle时间超过了timeout，连接将会被关闭。
Redis的默认配置给出的timeout=0,客户端不会因超时而关闭。
客户端类型




RDB运行后，开启AOF的正确方式
1.在线修改配置
config set appendonly=1
2.检查appendonly.aof
3.修改配置文件

注意：如果配置文件开启AOF，默认从AOF启动，里面并没有任何数据
######redis-stat监控#######
docker run --name redis-stat -p 63790:63790 -e 'TZ=Asia/Shanghai' -d insready/redis-stat --server 10.67.51.164 10.42.6.13 10.42.4.19 10.42.5.27
kubernetes环境里,单独启动的docker可以利用指定dns来解析kubernetes service
docker run --name redis-stat -p 63790:63790 --dns=10.43.0.10 -e 'TZ=Asia/Shanghai' -d insready/redis-stat --server redis-ha-announce-0.default.svc.cluster.local redis-ha-announce-1.default.svc.cluster.local redis-ha-announce-2.default.svc.cluster.local
docker run --name redis-stat -p 63790:63790 --dns=10.43.0.10 --dns-search=default.svc.cluster.local -e 'TZ=Asia/Shanghai' -d insready/redis-stat --server redis-ha-announce-0 redis-ha-announce-1 redis-ha-announce-2
######redis-commander Redis操作UI ###
docker run --name redis-commander -d --env REDIS_HOSTS=redis1:10.42.6.13:6379:1,redis2:10.42.4.19:6379:1,redis3:10.42.5.27:6379:1 -p 8081 rediscommander/redis-commander:latest
docker run --name redis-commander -d --dns=10.43.0.10 --dns-search=default.svc.cluster.local \
  --env REDIS_HOSTS=redis1:redis-ha-announce-0:6379:1,redis2:redis-ha-announce-1:6379:1,redis3:redis-ha-announce-2:6379:1 \
  -p 8081 rediscommander/redis-commander:latest
  
docker run -d --name haproxy-wi -v haproxy-wi:/var/www/haproxy-wi/app \
-p 8080:80 aidaho/haproxy-wi 
####### redis管理工具##########
redis insight
docker run -d -v redisinsight:/db -p 8001:8001 redislabs/redisinsight:latest

并非所有的业务场景都适合用缓存，读多写少、不要求一致性、时效要求越低、访问频率越高、对最终一致性和数据丢失有一定程度的容忍的场景
才适合使用缓存，缓存并不能解决所有的性能问题，倘若滥用缓存会带来额外的维护成本，使得系统架构更复杂更难以维护。
缓存与数据库一致性策略
1. Cache Aside模式：先写DB再删Cache
2. Read/Write Through模式在上面的Cache Aside中，应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。
所以，应用程序代码比较复杂。而Read/Write Through是把更新数据库（Repository）的操作由缓存服务自己代理，对于应用层来说，就简单很多了。
可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。
3. Write Behind Caching模式Write Behind也叫 Write Back。其实Linux文件系统的Page Cache算法用的也是这个，所以说底层的东西很多时候是相通。
Write Behind的思想是：在更新数据时，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
3.1 Redisson includes functionality for write-through and write-behind caching in Redis by using the RMap interface.
3.2 RGSync:  https://github.com/RedisGears/rgsync
Python-based recipe
Programmable

3.3 rghibernate:  https://github.com/RedisGears/rghibernate
Java-based recipe
Uses the Hibernate framework
Configurable rather than programmable

# redis各版本新增特性
Stream 是 Redis 5.0 引入的一种专门为消息队列设计的数据类型
Redis 6.0推出了Access Control List (ACL)特性
Redis 6.0支持了基于Transport Layer Security (TLS)的通信加密
RedisGears 要求最低 Redis 5.0 的支持
Redis v7.0 introduces Redis Functions

RedisMod簡介
首先介紹下RedisMod這個東西，它是一系列Redis的增強模塊。有了RedisMod的支持，Redis的功能將變得非常強大。目前RedisMod中包含了如下增強模塊：

RediSearch：一個功能齊全的搜尋引擎；
RedisJSON：對JSON類型的原生支持；
RedisTimeSeries：時序資料庫支持；
RedisGraph：圖資料庫支持；
RedisBloom：概率性數據的原生支持；
RedisGears：可編程的數據處理；
RedisAI：機器學習的實時模型管理和部署。

In addition to all of the features of Redis OSS, Redis Stack supports:

Probabilistic data structures
Queryable JSON documents
Querying across hashes and JSON documents
Time series data support (ingestion & querying)
Graph data models with the Cypher query language

# lua script  被认为是application的一部分，而不是redis的一部分，所以不被redis server长期管理
By design, Redis only caches the loaded scripts. That means that the script cache can become lost at any time, such as after calling SCRIPT FLUSH,
 after restarting the server, or when failing over to a replica. The application is responsible for reloading scripts during runtime if any are 
 missing. The underlying assumption is that scripts are a part of the application and not maintained by the Redis server.

# hotkeys  需要开启 lfu 策略
redis-cli  -h 10.67.50.225 --hotkeys
-------- summary -------
Sampled 8280 keys in the keyspace!
hot key found with counter: 7   keyname: "filebeat"
hot key found with counter: 2   keyname: "\xe7\x9f\xb3\xe6\xaf\x85"
hot key found with counter: 2   keyname: "\xe6\x9f\xb4\xe6\xa3\xae"

# 运维关注的重要指标
sync_full:11          累计Master full sync的次数;如果值比较大，说明常常出现全量复制，就得分析原因，或调整repl-backlog-size
                      repl_backlog的长度(repl-backlog-size)，网络环境不稳定的，建议调整大些。(主从之间如何网络延时过大可以调整此参数，避免重复的触发全量同步)
evicted_keys:0        因内存used_memory达到maxmemory后，每秒被驱逐的key个数

客户端相关
connected_clients：代表当前Redis节点的客户端连接数，需要重点监控，一旦超过maxclients，新的客户端连接将被拒绝。
client_longest_output_list：当前所有输出缓冲区中队列对象个数的最大值。
client_biggest_input_buf：当前所有输入缓冲区中占用的最大容量。
blocked_clients：正在执行阻塞命令（例如blpop、brpop、brpoplpush）的客户端个数。
total_connections_received(info stats)：Redis自启动以来处理的客户端连接数总数。
rejected_connections：Redis自启动以来拒绝的客户端连接数，需要重点监控。

# 有用的命令
查看主从同步什么数据
[root@389dsbak ~]# redis-cli -h 10.67.50.41 -a Foxconn123 --slave     
