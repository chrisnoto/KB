######## Mongo ########
连接db
[root@c8-cilent1 ~]# mongosh mongodb://root:example@10.67.36.58/test  需要在test数据库中添加root用户并赋权限
admin> use test
switched to db test
test> db.createUser({user:"root",pwd:"example",roles:["readWrite"]})
{ ok: 1 }
test> db.auth("root","example")
{ ok: 1 }

db.createUser({user:"mongodb_exporter",pwd:"password",roles:[{role:"clusterMonitor",db:"admin"},{role:"read",db:"test"}]})
db.createUser({user:"root",pwd:"example",roles:["readWrite"]})

Current Mongosh Log ID: 61273589b813596cfbd3a5ae
Connecting to:          mongodb://<credentials>@10.67.36.58/test?directConnection=true
Using MongoDB:          5.0.2
Using Mongosh Beta:     0.12.1


root@f5429e1c496e:/# mongosh "mongodb://root:example@127.0.0.1:27017/admin"
Current Mongosh Log ID: 6113643d26d56d29f6a36161
Connecting to:          mongodb://<credentials>@127.0.0.1:27017/admin?directConnection=true&serverSelectionTimeoutMS=2000
Using MongoDB:          5.0.2
Using Mongosh:          1.0.4

root@f5429e1c496e:/# mongoimport --host 127.0.0.1:27017 --db test --collection example --authenticationDatabase admin --username root --password example --file /facts.json
2021-08-12T06:29:00.431+0000    connected to: mongodb://127.0.0.1:27017/
2021-08-12T06:29:00.431+0000    dropping: test.example
2021-08-12T06:29:00.456+0000    1 document(s) imported successfully. 0 document(s) failed to import.

test> db.example.find({ansible_architecture:"x86_64"},{"ansible_all_ipv4_addresses":1,"ansible_nodename":1,"ansible_distribution":1,"ansible_distribution_version":1,"ansible_kernel":1,"ansible_product_name":1,
"ansible_processor_vcpus":1,"ansible_memtotal_mb":1})
[
  {
    _id: ObjectId("6114ccc7dfaa80771ed8efc0"),
    ansible_all_ipv4_addresses: [ '192.168.122.1', '10.67.36.15' ],
    ansible_distribution: 'CentOS',
    ansible_distribution_version: '8.0',
    ansible_kernel: '4.18.0-80.11.2.el8_0.x86_64',
    ansible_memtotal_mb: 3780,
    ansible_nodename: 'c8-cilent1.xq.foxconn',
    ansible_processor_vcpus: 2,
    ansible_product_name: 'KVM'
  },
  {
    _id: ObjectId("6114ccde4626e9983f6593a3"),
    ansible_all_ipv4_addresses: [ '172.17.0.1', '10.67.51.164' ],
    ansible_distribution: 'CentOS',
    ansible_distribution_version: '7.5',
    ansible_kernel: '3.10.0-957.27.2.el7.x86_64',
    ansible_memtotal_mb: 7931,
    ansible_nodename: 'repo-centos',
    ansible_processor_vcpus: 4,
    ansible_product_name: 'VMware Virtual Platform'
  }
]

mongoimport --host 127.0.0.1:27017 --db test --collection staff --authenticationDatabase admin --username root --password example --drop --file /2.json

查询  where, sort
test> db.staff.find({"details.weight":{$gt:270},"details.age":{$gt:26}}).sort({"details.age":-1})
[
  {
    _id: ObjectId("61372182aeb931801cbe0a1d"),
    name: 'Frank Thomas',
    team: ' TOR',
    position: ' Designated Hitter',
    details: { height: 77, weight: 275, age: 38.76 }
  },
  {
    _id: ObjectId("61372182aeb931801cbe090c"),
    name: 'C.C. Sabathia',
    team: ' CLE',
    position: ' Starting Pitcher',
    details: { height: 79, weight: 290, age: 26.61 }
  }
]

创建索引
test> db.staff.createIndex({"details.age":1})
details.age_1
test> db.staff.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  { v: 2, key: { 'details.age': 1 }, name: 'details.age_1' }
]
test>

分组
各team的人数
test> db.staff.aggregate([{$group : {_id : "$team", num_tutorial : {$sum : 1}}}])
[
  { _id: ' PIT', num_tutorial: 35 },
  { _id: ' OAK', num_tutorial: 37 },
  { _id: ' ARZ', num_tutorial: 30 },
  { _id: ' LA', num_tutorial: 33 },
  { _id: ' BAL', num_tutorial: 35 },
  { _id: ' ATL', num_tutorial: 38 },
  { _id: ' MLW', num_tutorial: 35 },
  { _id: ' NYM', num_tutorial: 38 },
各team的平均年纪
test> db.staff.aggregate([{$group : {_id : "$team", avg_age : {$avg : "$details.age"}}}])
[
  { _id: ' PIT', avg_age: 27.194857142857146 },
  { _id: ' OAK', avg_age: 28.716486486486485 },
  { _id: ' ARZ', avg_age: 27.60033333333333 },
  { _id: ' LA', avg_age: 29.778181818181817 },
  { _id: ' BAL', avg_age: 29.062285714285718 },
  { _id: ' ATL', avg_age: 28.262894736842107 },
  { _id: ' MLW', avg_age: 29.04057142857143 },
  { _id: ' NYM', avg_age: 30.525000000000002 },
  { _id: ' CWS', avg_age: 28.270909090909093 },
  { _id: ' TB', avg_age: 26.797272727272727 },
  { _id: ' DET', avg_age: 29.149459459459457 },
  { _id: ' SEA', avg_age: 27.681818181818183 },
  { _id: ' BOS', avg_age: 29.78388888888889 },
  { _id: ' MIN', avg_age: 28.241818181818182 },
各team的最大年纪
test> db.staff.aggregate([{$group : {_id : "$team", avg_age : {$max : "$details.age"}}}])
[
  { _id: ' PIT', avg_age: 34.97 },
  { _id: ' OAK', avg_age: 38.49 },
  { _id: ' ARZ', avg_age: 43.47 },
  { _id: ' LA', avg_age: 39.49 },
  { _id: ' BAL', avg_age: 36.33 },
  { _id: ' ATL', avg_age: 39.79 },
  { _id: ' MLW', avg_age: 38.43 },
  { _id: ' NYM', avg_age: 48.52 },
  { _id: ' CWS', avg_age: 36.51 },
  { _id: ' TB', avg_age: 36.47 },
  { _id: ' DET', avg_age: 42.3 },
  { _id: ' SEA', avg_age: 36.03 },
  { _id: ' BOS', avg_age: 40.97 },
  { _id: ' MIN', avg_age: 37.43 },
  
  
备份db
mongodump 是 MongoDB 官方提供的逻辑备份工具，它可以从 MongoDB 数据库读取数据，并生成 BSON 文件，mongodump 适合用于备份和恢复数据量较小的 MongoDB 数据库，不适用于大数据量备份。
mongorestore恢复工具
root@5a83f9cbb735:/# mongodump --host 127.0.0.1 --port 27017 -u root -p example -d test
2021-09-07T09:07:30.801+0000    writing test.staff to dump/test/staff.bson
2021-09-07T09:07:30.804+0000    done dumping test.staff (1035 documents)

查看bson二进制文件
root@5a83f9cbb735:/dump/test# bsondump staff.bson | head -10
{"_id":{"$oid":"61372182aeb931801cbe086c"},"name":"Brian Roberts","team":" BAL","position":" Second Baseman","details":{"height":{"$numberInt":"69"},"weight":{"$numberInt":"176"},"age":{"$numberDouble":"29.39"}}}
{"_id":{"$oid":"61372182aeb931801cbe086d"},"name":"Paul Bako","team":" BAL","position":" Catcher","details":{"height":{"$numberInt":"74"},"weight":{"$numberInt":"215"},"age":{"$numberDouble":"34.69"}}}
{"_id":{"$oid":"61372182aeb931801cbe086e"},"name":"Adam Donachie","team":" BAL","position":" Catcher","details":{"height":{"$numberInt":"74"},"weight":{"$numberInt":"180"},"age":{"$numberDouble":"22.99"}}}
{"_id":{"$oid":"61372182aeb931801cbe086f"},"name":"Miguel Tejada","team":" BAL","position":" Shortstop","details":{"height":{"$numberInt":"69"},"weight":{"$numberInt":"209"},"age":{"$numberDouble":"30.77"}}}
{"_id":{"$oid":"61372182aeb931801cbe0870"},"name":"Melvin Mora","team":" BAL","position":" Third Baseman","details":{"height":{"$numberInt":"71"},"weight":{"$numberInt":"200"},"age":{"$numberDouble":"35.07"}}}

db.staff.mapReduce(
function() {emit(this.name,1);},
function(key,values) {return Array.avg(values)},
{
query:{"details.age":{$gt:26}},
out:"average"
}
)

# 限定输出字段
ansible> db.cache.find({"data.ansible_system":'Linux'},{"data.ansible_system":1});
[
  { _id: 'ansible_factslocalhost', data: { ansible_system: 'Linux' } },
  {
    _id: 'ansible_facts10.67.51.164',
    data: { ansible_system: 'Linux' }
  }
]
ansible> db.cache.find({"data.ansible_system":"Linux"},{"data.ansible_distribution":1,"data.ansible_distribution_version":1,"data.ansible_hostname":1,"data.ansible_default_ipv4.address":1});
[
  {
    _id: 'ansible_factslocalhost',
    data: {
      ansible_distribution: 'AlmaLinux',
      ansible_distribution_version: '9.0',
      ansible_hostname: '389dsbak',
      ansible_default_ipv4: { address: '10.67.50.225' }
    }
  },
  {
    _id: 'ansible_facts10.67.51.164',
    data: {
      ansible_distribution_version: '7.5',
      ansible_default_ipv4: { address: '10.67.51.164' },
      ansible_distribution: 'CentOS',
      ansible_hostname: 'repo'
    }
  }
]

[root@repo ~]# mongosh --quiet mongodb://10.67.51.164:27017/ansible --eval 'db.cache.find({"data.ansible_system":"Linux"},{"data.ansible_distribution":1,"data.ansible_distribution_version":1,"data.ansible_hostname":1,"data.ansible_default_ipv4.address":1})'
[
  {
    _id: 'ansible_factslocalhost',
    data: {
      ansible_distribution: 'AlmaLinux',
      ansible_distribution_version: '9.0',
      ansible_hostname: '389dsbak',
      ansible_default_ipv4: { address: '10.67.50.225' }
    }
  },
  {
    _id: 'ansible_facts10.67.51.164',
    data: {
      ansible_distribution_version: '7.5',
      ansible_default_ipv4: { address: '10.67.51.164' },
      ansible_distribution: 'CentOS',
      ansible_hostname: 'repo'
    }
  }
]

[root@repo ~]# mongosh --quiet mongodb://10.67.51.164:27017/ansible <demo.js
ansible> use ansible
already on db ansible
ansible> show collections
cache
ansible> [root@repo ~]# cat demo.js
use ansible
show collections

# 查看索引
ansible> db.cache.getIndexes();
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  { v: 2, key: { date: 1 }, name: 'ttl', expireAfterSeconds: 8640000 }
]


# mongo客户端命令
root@35d51112cc40:/# mongo -u "root" -p "openIM123" --authenticationDatabase "admin"
MongoDB shell version v4.0.28
connecting to: mongodb://127.0.0.1:27017/?authSource=admin&gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("82f45096-7f3d-4fcb-99b9-3c3a3cb0b153") }
MongoDB server version: 4.0.28


1. 创建Sharding复制集 rs0

# mkdir /data/log
# mkdir /data/db1
# nohup mongod --port 27020 --dbpath=/data/db1 --logpath=/data/log/rs0-1.log --logappend --fork --shardsvr --replSet=rs0 &

# mkdir /data/db2
# nohup mongod --port 27021 --dbpath=/data/db2 --logpath=/data/log/rs0-2.log --logappend --fork --shardsvr --replSet=rs0 &
1.1 复制集rs0配置

# mongo localhost:27020 > rs.initiate({_id: 'rs0', members: [{_id: 0, host: 'localhost:27020'}, {_id: 1, host: 'localhost:27021'}]}) > rs.isMaster() #查看主从关系
2. 创建Sharding复制集 rs1

# mkdir /data/db3
# nohup mongod --port 27030 --dbpath=/data/db3 --logpath=/data/log/rs1-1.log --logappend --fork --shardsvr --replSet=rs1 &
# mkdir /data/db4
# nohup mongod --port 27031 --dbpath=/data/db4 --logpath=/data/log/rs1-2.log --logappend --fork --shardsvr --replSet=rs1 &
2.1 复制集rs1配置

# mongo localhost:27030
> rs.initiate({_id: 'rs1', members: [{_id: 0, host: 'localhost:27030'}, {_id: 1, host: 'localhost:27031'}]})
> rs.isMaster() #查看主从关系
3. 创建Config复制集 conf

# mkdir /data/conf1
# nohup mongod --port 27100 --dbpath=/data/conf1 --logpath=/data/log/conf-1.log --logappend --fork --configsvr --replSet=conf &
# mkdir /data/conf2
# nohup mongod --port 27101 --dbpath=/data/conf2 --logpath=/data/log/conf-2.log --logappend --fork --configsvr --replSet=conf &
3.1 复制集conf配置

# mongo localhost:27100
> rs.initiate({_id: 'conf', members: [{_id: 0, host: 'localhost:27100'}, {_id: 1, host: 'localhost:27101'}]})
> rs.isMaster() #查看主从关系
4. 创建Route

# nohup mongos --port 40000 --configdb conf/localhost:27100,localhost:27101 --fork --logpath=/data/log/route.log --logappend & 
4.1 设置分片

# mongo localhost:40000
> use admin
> db.runCommand({ addshard: 'rs0/localhost:27020,localhost:27021'})
> db.runCommand({ addshard: 'rs1/localhost:27030,localhost:27031'})
> db.runCommand({ enablesharding: 'test'})
> db.runCommand({ shardcollection: 'test.user', key: {name: 1}})


# 10.67.51.164  mongo
/etc/mongod.conf增加下面两行后，重启mongodb
replication:
  replSetName: rs0

[root@repo ~]# mongosh mongodb://10.67.51.164:27017  
test> rs.initiate({ _id : "rs0",members: [{ _id: 0, host: "10.67.51.164:27017" }]})
{ ok: 1 }
rs0 [direct: other] test> rs.isMaster()
{
  topologyVersion: {
    processId: ObjectId("643752baa09515e8b89dd2d5"),
    counter: Long("6")
  },
  hosts: [ '10.67.51.164:27017' ],
  setName: 'rs0',
  setVersion: 1,
  ismaster: true,
  secondary: false,
  primary: '10.67.51.164:27017',
  me: '10.67.51.164:27017',
  electionId: ObjectId("7fffffff0000000000000001"),
  lastWrite: {
    opTime: { ts: Timestamp({ t: 1681347351, i: 1 }), t: Long("1") },
    lastWriteDate: ISODate("2023-04-13T00:55:51.000Z"),
    majorityOpTime: { ts: Timestamp({ t: 1681347351, i: 1 }), t: Long("1") },
    majorityWriteDate: ISODate("2023-04-13T00:55:51.000Z")
  },
  maxBsonObjectSize: 16777216,
  maxMessageSizeBytes: 48000000,
  maxWriteBatchSize: 100000,
  localTime: ISODate("2023-04-13T00:55:51.481Z"),
  logicalSessionTimeoutMinutes: 30,
  connectionId: 2,
  minWireVersion: 0,
  maxWireVersion: 17,
  readOnly: false,
  ok: 1,
  '$clusterTime': {
    clusterTime: Timestamp({ t: 1681347351, i: 1 }),
    signature: {
      hash: Binary(Buffer.from("0000000000000000000000000000000000000000", "hex"), 0),
      keyId: Long("0")
    }
  },
  operationTime: Timestamp({ t: 1681347351, i: 1 }),
  isWritablePrimary: true
}

rs0 [direct: primary] cmdb> rs.isMaster()
{
  topologyVersion: {
    processId: ObjectId("643752baa09515e8b89dd2d5"),
    counter: Long("6")
  },
  hosts: [ '10.67.51.164:27017' ],
  setName: 'rs0',
  setVersion: 1,
  ismaster: true,
  secondary: false,
  primary: '10.67.51.164:27017',
  me: '10.67.51.164:27017',
  electionId: ObjectId("7fffffff0000000000000001"),
  lastWrite: {
    opTime: { ts: Timestamp({ t: 1681347421, i: 1 }), t: Long("1") },
    lastWriteDate: ISODate("2023-04-13T00:57:01.000Z"),
    majorityOpTime: { ts: Timestamp({ t: 1681347421, i: 1 }), t: Long("1") },
    majorityWriteDate: ISODate("2023-04-13T00:57:01.000Z")
  },
  maxBsonObjectSize: 16777216,
  maxMessageSizeBytes: 48000000,
  maxWriteBatchSize: 100000,
  localTime: ISODate("2023-04-13T00:57:04.164Z"),
  logicalSessionTimeoutMinutes: 30,
  connectionId: 12,
  minWireVersion: 0,
  maxWireVersion: 17,
  readOnly: false,
  ok: 1,
  '$clusterTime': {
    clusterTime: Timestamp({ t: 1681347421, i: 1 }),
    signature: {
      hash: Binary(Buffer.from("0000000000000000000000000000000000000000", "hex"), 0),
      keyId: Long("0")
    }
  },
  operationTime: Timestamp({ t: 1681347421, i: 1 }),
  isWritablePrimary: true
}

rs0 [direct: primary] monstache> rs.printReplicationInfo();
actual oplog size
'3906.177978515625 MB'
---
configured oplog size
'3906.177978515625 MB'
---
log length start to end
'440 secs (0.12 hrs)'
---
oplog first event time
'Thu Apr 13 2023 08:55:31 GMT+0800 (China Standard Time)'
---
oplog last event time
'Thu Apr 13 2023 09:02:51 GMT+0800 (China Standard Time)'
---
now
'Thu Apr 13 2023 09:02:56 GMT+0800 (China Standard Time)'
rs0 [direct: primary] monstache> db.getReplicationInfo();
{
  configuredLogSizeMB: 3906.177978515625,
  logSizeMB: 3906.177978515625,
  usedMB: 0.01,
  timeDiff: 470,
  timeDiffHours: 0.13,
  tFirst: 'Thu Apr 13 2023 08:55:31 GMT+0800 (China Standard Time)',
  tLast: 'Thu Apr 13 2023 09:03:21 GMT+0800 (China Standard Time)',
  now: 'Thu Apr 13 2023 09:03:23 GMT+0800 (China Standard Time)'
