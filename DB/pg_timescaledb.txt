###########  zabbix 5.4 + timescaledb-2 安装和配置

安装timescaledb-2插件
# yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-$(rpm -E %{rhel})-x86_64/pgdg-redhat-repo-latest.noarch.rpm
# yum install timescaledb-2-postgresql-13
$ timescaledb-tune --pg-config=/usr/pgsql-13/bin/pg_config
# systemctl restart postgresql-13
$ createuser --pwprompt zabbix
$ createdb -O zabbix -E Unicode -T template0 zabbix
$ pg_restore -d zabbix /tmp/zabbix.dump


#使用timescaledb脚本，创建hyphertable
-bash-4.2$ zcat /tmp/timescaledb.sql.gz | psql zabbix
NOTICE:  PostgreSQL version 13.4 is valid
NOTICE:  TimescaleDB extension is detected
NOTICE:  TimescaleDB version 2.5.0 is valid
NOTICE:  migrating data to chunks
DETAIL:  Migration might take a while depending on the amount of data.
NOTICE:  migrating data to chunks
DETAIL:  Migration might take a while depending on the amount of data.
NOTICE:  migrating data to chunks
DETAIL:  Migration might take a while depending on the amount of data.
NOTICE:  migrating data to chunks
DETAIL:  Migration might take a while depending on the amount of data.
NOTICE:  TimescaleDB is configured successfully
********************SQL中创建hypertable的语句
        PERFORM create_hypertable('history', 'clock', chunk_time_interval => 86400, migrate_data => true);       # 一个chunk为一天数据
        PERFORM create_hypertable('history_uint', 'clock', chunk_time_interval => 86400, migrate_data => true);
        PERFORM create_hypertable('history_log', 'clock', chunk_time_interval => 86400, migrate_data => true);
        PERFORM create_hypertable('history_text', 'clock', chunk_time_interval => 86400, migrate_data => true);
        PERFORM create_hypertable('history_str', 'clock', chunk_time_interval => 86400, migrate_data => true);
        PERFORM create_hypertable('trends', 'clock', chunk_time_interval => 2592000, migrate_data => true);        # 一个chunk为一月数据
        PERFORM create_hypertable('trends_uint', 'clock', chunk_time_interval => 2592000, migrate_data => true);
        UPDATE config SET db_extension='timescaledb',hk_history_global=1,hk_trends_global=1;
        UPDATE config SET compression_status=1,compress_older='7d';
        RAISE NOTICE 'TimescaleDB is configured successfully';

********************
# 已经看到很多chunk了
-bash-4.2$ oid2name -d zabbix -i |grep chunk|grep hyper
     33035                                                 _hyper_1_1_chunk
     33036                                       _hyper_1_1_chunk_history_1
     31716                                                 _hyper_1_2_chunk
     31723                                       _hyper_1_2_chunk_history_1
     31724                                                 _hyper_1_3_chunk
     31731                                       _hyper_1_3_chunk_history_1
     31732                                                 _hyper_1_4_chunk
....

# 查看有哪些hypertable
zabbix=# SELECT * FROM timescaledb_information.hypertables;
 hypertable_schema | hypertable_name | owner  | num_dimensions | num_chunks | compression_enabled | is_distributed | replication_factor | data_nodes | tablespaces
-------------------+-----------------+--------+----------------+------------+---------------------+----------------+--------------------+------------+-------------
 public            | history         | zabbix |              1 |          8 | t                   | f              |                    |            |
 public            | history_uint    | zabbix |              1 |          8 | t                   | f              |                    |            |
 public            | history_log     | zabbix |              1 |          0 | t                   | f              |                    |            |
 public            | history_text    | zabbix |              1 |          1 | t                   | f              |                    |            |
 public            | history_str     | zabbix |              1 |          1 | t                   | f              |                    |            |
 public            | trends          | zabbix |              1 |          5 | t                   | f              |                    |            |
 public            | trends_uint     | zabbix |              1 |          5 | t                   | f              |                    |            |
(7 rows)

# 查看有哪些chunks
zabbix=# select * from timescaledb_information.chunks ;
 hypertable_schema | hypertable_name |     chunk_schema      |    chunk_name     | primary_dimension | primary_dimension_type | range_start | range_end | range_start_integer | range_end_integer | is_compressed | chunk_tablespace | data_nodes
-------------------+-----------------+-----------------------+-------------------+-------------------+------------------------+-------------+-----------+---------------------+-------------------+---------------+------------------+------------
 public            | history         | _timescaledb_internal | _hyper_1_1_chunk  | clock             | integer                |             |           |          1635206400 |        1635292800 | t             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_2_chunk  | clock             | integer                |             |           |          1635465600 |        1635552000 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_3_chunk  | clock             | integer                |             |           |          1635379200 |        1635465600 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_4_chunk  | clock             | integer                |             |           |          1634947200 |        1635033600 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_5_chunk  | clock             | integer                |             |           |          1635033600 |        1635120000 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_6_chunk  | clock             | integer                |             |           |          1635120000 |        1635206400 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_7_chunk  | clock             | integer                |             |           |          1635292800 |        1635379200 | f             |                  |


# 查看history表的chunks
zabbix=# select public.show_chunks('history');
              show_chunks
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_8_chunk
(8 rows)

查看history表的chuck细节
zabbix=# SELECT * FROM timescaledb_information.chunks WHERE hypertable_name = 'history';
 hypertable_schema | hypertable_name |     chunk_schema      |    chunk_name    | primary_dimension | primary_dimension_type | range_start | range_end | range_start_integer | range_end_integer | is_compressed | chunk_tablespace | data_nodes
-------------------+-----------------+-----------------------+------------------+-------------------+------------------------+-------------+-----------+---------------------+-------------------+---------------+------------------+------------
 public            | history         | _timescaledb_internal | _hyper_1_1_chunk | clock             | integer                |             |           |          1635206400 |        1635292800 | t             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_2_chunk | clock             | integer                |             |           |          1635465600 |        1635552000 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_3_chunk | clock             | integer                |             |           |          1635379200 |        1635465600 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_4_chunk | clock             | integer                |             |           |          1634947200 |        1635033600 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_5_chunk | clock             | integer                |             |           |          1635033600 |        1635120000 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_6_chunk | clock             | integer                |             |           |          1635120000 |        1635206400 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_7_chunk | clock             | integer                |             |           |          1635292800 |        1635379200 | f             |                  |
 public            | history         | _timescaledb_internal | _hyper_1_8_chunk | clock             | integer                |             |           |          1635552000 |        1635638400 | f             |                  |
(8 rows)

zabbix db里的clock字段存储的是秒数
可以秒数转日期，也可以日期转秒数
zabbix=# select to_timestamp(1635293027);
      to_timestamp
------------------------
 2021-10-27 00:03:47+00
(1 row)

zabbix=# SELECT EXTRACT(EPOCH FROM TIMESTAMP '2021-10-31 06:00:00');
 date_part
------------
 1635660000
(1 row)

使用newer和older来查询chunks
zabbix=# select show_chunks('history',newer_than => 1635293027);
              show_chunks
----------------------------------------
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_8_chunk
(3 rows)


zabbix=# select show_chunks('history',older_than => 1635293027);
              show_chunks
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
(4 rows)

查看chuck表大小
zabbix=# select * from chunks_detailed_size('history');
     chunk_schema      |    chunk_name    | table_bytes | index_bytes | toast_bytes | total_bytes | node_name
-----------------------+------------------+-------------+-------------+-------------+-------------+-----------
 _timescaledb_internal | _hyper_1_2_chunk |     3416064 |     2662400 |           0 |     6078464 |
 _timescaledb_internal | _hyper_1_3_chunk |     3416064 |     2588672 |           0 |     6004736 |
 _timescaledb_internal | _hyper_1_4_chunk |     3301376 |     2555904 |           0 |     5857280 |
 _timescaledb_internal | _hyper_1_5_chunk |     3416064 |     2531328 |           0 |     5947392 |
 _timescaledb_internal | _hyper_1_6_chunk |     3416064 |     2514944 |           0 |     5931008 |
 _timescaledb_internal | _hyper_1_7_chunk |     3416064 |     2400256 |           0 |     5816320 |
 _timescaledb_internal | _hyper_1_8_chunk |      778240 |      507904 |           0 |     1286144 |
 _timescaledb_internal | _hyper_1_1_chunk |       65536 |       24576 |      425984 |      516096 |
(8 rows)
查看history超表的大小
zabbix=# select pg_size_pretty(table_bytes) as table_size,pg_size_pretty(index_bytes) as index_size,pg_size_pretty(toast_bytes) as toast_size,pg_size_pretty(total_bytes) as total_size from hypertable_detailed_size('history');
 table_size | index_size | toast_size | total_size
------------+------------+------------+------------
 21 MB      | 16 MB      | 416 kB     | 37 MB


压缩chunk
zabbix=# select compress_chunk('_timescaledb_internal._hyper_1_1_chunk');
             compress_chunk
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)
.......
-[ RECORD 8 ]------------------+----------------------
chunk_schema                   | _timescaledb_internal
chunk_name                     | _hyper_1_1_chunk
compression_status             | Compressed
before_compression_table_bytes | 3416064
before_compression_index_bytes | 2777088
before_compression_toast_bytes | 0
before_compression_total_bytes | 6193152
after_compression_table_bytes  | 65536
after_compression_index_bytes  | 16384
after_compression_toast_bytes  | 425984
after_compression_total_bytes  | 507904
node_name                      |



压缩后原 _hyper_1_1_chunk 大小为0
zabbix=# select pg_relation_size('_timescaledb_internal._hyper_1_1_chunk');
 pg_relation_size
------------------
                0
(1 row)
zabbix=# set search_path to _timescaledb_internal;
SET
zabbix=# \d
                           List of relations
        Schema         |            Name             | Type  |  Owner
-----------------------+-----------------------------+-------+----------
.......
 _timescaledb_internal | _hyper_1_1_chunk            | table | zabbix
 _timescaledb_internal | _hyper_1_2_chunk            | table | zabbix
 _timescaledb_internal | _hyper_1_3_chunk            | table | zabbix
.....
 _timescaledb_internal | compress_hyper_8_27_chunk   | table | zabbix
(40 rows)

通过explain可以看到 _hyper_1_1_chunk 压缩后 数据放到了 compress_hyper_8_27_chunk
zabbix=# explain select count(*) from history;
                                                   QUERY PLAN
-----------------------------------------------------------------------------------------------------------------
 Finalize Aggregate  (cost=6959.03..6959.04 rows=1 width=8)
   ->  Gather  (cost=6958.82..6959.03 rows=2 width=8)
         Workers Planned: 2
         ->  Partial Aggregate  (cost=5958.82..5958.83 rows=1 width=8)
               ->  Parallel Append  (cost=0.00..5514.00 rows=177927 width=0)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk  (cost=0.12..5.46 rows=46000 width=0)
                           ->  Parallel Seq Scan on compress_hyper_8_27_chunk  (cost=0.00..5.46 rows=46 width=4)    # 这里
                     ->  Parallel Seq Scan on _hyper_1_2_chunk  (cost=0.00..743.35 rows=33035 width=0)
                     ->  Parallel Seq Scan on _hyper_1_3_chunk  (cost=0.00..743.35 rows=33035 width=0)
                     ->  Parallel Seq Scan on _hyper_1_5_chunk  (cost=0.00..743.35 rows=33035 width=0)
                     ->  Parallel Seq Scan on _hyper_1_6_chunk  (cost=0.00..743.35 rows=33035 width=0)
                     ->  Parallel Seq Scan on _hyper_1_7_chunk  (cost=0.00..743.35 rows=33035 width=0)
                     ->  Parallel Seq Scan on _hyper_1_4_chunk  (cost=0.00..718.11 rows=31911 width=0)
                     ->  Parallel Seq Scan on _hyper_1_8_chunk  (cost=0.00..184.03 rows=8103 width=0)
(14 rows)

压缩后大小为40kB
zabbix=# select pg_size_pretty(pg_relation_size('_timescaledb_internal.compress_hyper_8_27_chunk'));
 pg_size_pretty
----------------
 40 kB
(1 row)


查看压缩任务
zabbix=# SELECT * FROM timescaledb_information.jobs;
 job_id |     application_name      | schedule_interval | max_runtime | max_retries | retry_period |      proc_schema      |     proc_name      |  owner   | scheduled |                     config                     |          next_start           | hypertable_schema | h
ypertable_name
--------+---------------------------+-------------------+-------------+-------------+--------------+-----------------------+--------------------+----------+-----------+------------------------------------------------+-------------------------------+-------------------+--
---------------
      1 | Telemetry Reporter [1]    | 24:00:00          | 00:01:40    |          -1 | 01:00:00     | _timescaledb_internal | policy_telemetry   | postgres | t         |                                                | 2021-10-30 08:46:15.187675+00 |                   |
   1006 | Compression Policy [1006] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 7, "compress_after": 612000} | 2021-10-30 12:26:03.791419+00 | public            | t
rends_uint
   1000 | Compression Policy [1000] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 1, "compress_after": 612000} | 2021-10-30 12:26:03.807164+00 | public            | h
istory
   1001 | Compression Policy [1001] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 2, "compress_after": 612000} | 2021-10-30 12:26:03.8262+00   | public            | h
istory_uint
   1002 | Compression Policy [1002] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 5, "compress_after": 612000} | 2021-10-30 12:26:03.851741+00 | public            | h
istory_str
   1003 | Compression Policy [1003] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 4, "compress_after": 612000} | 2021-10-30 12:26:03.868407+00 | public            | h
istory_text
   1005 | Compression Policy [1005] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 6, "compress_after": 612000} | 2021-10-30 12:26:03.914944+00 | public            | t
rends
   1004 | Compression Policy [1004] | 1 day             | 00:00:00    |          -1 | 01:00:00     | _timescaledb_internal | policy_compression | zabbix   | t         | {"hypertable_id": 3, "compress_after": 612000} | 2021-10-30 12:26:03.933253+00 | public            | h
istory_log

# time_bucket函数
查看itemid=10073的监控指标每5分钟的平均值
zabbix=# select time_bucket('300',clock) as five_min,avg(value) from history where itemid=10073 group by five_min order by five_min limit 10;
  five_min  |        avg
------------+--------------------
 1634949900 | 0.6498569713761893
 1634950200 | 0.6498569025011809
 1634950500 | 0.6498579033543198
 1634950800 | 0.6498616420345298
 1634951100 | 0.6498640946037003
 1634951400 |  0.649850038873476
 1634951700 | 0.6520572575130209
 1634952000 |  0.649848264986644
 1634952300 | 0.6498570006136769
 1634952600 | 0.6498655667358046

# first函数
查看每个itemid最早的一笔记录 
zabbix=# select itemid,first(value,clock) from history group by itemid;
 itemid |         first
--------+-----------------------
  10073 |    0.6498569713761893
  10074 |                     0
  10075 |                     0
  10076 |   0.08331538591753834
  10077 |                     0
  10078 |   0.13330488936035287
  23252 |                     0
  23253 |   0.16917611233293858
  23255 |                     0
  23256 |   0.06889424733034792
  23257 |   0.18606224627875506
 
# ts-dump备份   这里超表没有备份，需要单独copy备份
-bash-4.2$ ts-dump --db-URI=postgres://postgres:postgres@10.67.39.58:5432/zabbix --dump-dir=tsdump/
2021/11/01 08:45:04 Jobs:  have stopped, continuing
 pg_dump version: pg_dump (PostgreSQL) 13.4

2021/11/01 08:45:06 pg_dump: warning: there are circular foreign-key constraints on this table:
2021/11/01 08:45:06 pg_dump:   hypertable
2021/11/01 08:45:06 pg_dump: You might not be able to restore the dump without using --disable-triggers or temporarily dropping the constraints.
2021/11/01 08:45:06 pg_dump: Consider using a full dump instead of a --data-only dump to avoid this problem.
2021/11/01 08:45:06 pg_dump: warning: there are circular foreign-key constraints on this table:
2021/11/01 08:45:06 pg_dump:   chunk
2021/11/01 08:45:06 pg_dump: You might not be able to restore the dump without using --disable-triggers or temporarily dropping the constraints.
2021/11/01 08:45:06 pg_dump: Consider using a full dump instead of a --data-only dump to avoid this problem.
2021/11/01 08:45:07 pg_dump: NOTICE:  hypertable data are in the chunks, no data will be copied
2021/11/01 08:45:07 DETAIL:  Data for hypertables are stored in the chunks of a hypertable so COPY TO of a hypertable will not copy any data.
2021/11/01 08:45:07 HINT:  Use "COPY (SELECT * FROM <hypertable>) TO ..." to copy all data in hypertable, or copy each chunk individually.
2021/11/01 08:45:07 pg_dump: NOTICE:  hypertable data are in the chunks, no data will be copied
......
# pg_basebackup  只能备份本机

####################  prometheus + promscale + timescaledb2 POC
容器快速搭建环境
docker network create --driver bridge pnet

docker run --name timescaledb -e POSTGRES_PASSWORD=secret -d -p 5432:5432 --network=pnet timescaledev/promscale-extension:latest-ts2-pg13 postgres -csynchronous_commit=off

docker run --name promscale -d -p 9201:9201 --network=pnet timescale/promscale:0.6 -db-password=secret -db-port=5432 -db-name=postgres -db-host=timescaledb -db-ssl-mode=allow
此步完成后，会自动在PG里建promscale extension

编辑prometheus.yml，加入
remote_write:
        - url: "http://10.67.36.58:9201/write"
remote_read:
    - url: "http://10.67.36.58:9201/read"

重启prometheus
root@u1804:/var/snap/prometheus/current# systemctl restart snap.prometheus.prometheus.service

postgres=# SELECT count(*) FROM timescaledb_information.hypertables;
 count
-------
   767
(1 row) 

####################### prometheus + promscale + 多节点timescaledb2   ####################
容器快速搭建环境
1 分别运行3个timescaledb容器
docker run --name timescaledb -e POSTGRES_PASSWORD=secret -d -p 5432:5432 timescaledev/promscale-extension:latest-ts2-pg13 postgres -csynchronous_commit=off

2 每个节点做根据下面要求修改postgresql.conf，并stop/start container
max_prepared_transactions must be set to a non-zero value on all data nodes (if not already set, 150 is recommended).
enable_partitionwise_aggregate should be set to on on the access node for good query performance. Otherwise, queries will not be pushed down to the data nodes.
jit should be set to off on the access node as JIT currently doesn't work well with distributed queries. JIT can still be enabled on the data nodes

docker run -i -t timescale/timescaledb:latest-pg10 postgres -cmax_wal_size=2GB  # 可以直接在run的时候加上参数，不过在改参数的时候也有弊端

3 依次将dns,dns2节点加入为data_node，这里dns是写错的节点名称 -_-!!

postgres=# select add_data_node('dns',host=>'10.67.36.59');
NOTICE:  database "postgres" already exists on data node, skipping
NOTICE:  extension "timescaledb" already exists on data node, skipping
DETAIL:  TimescaleDB extension version on 10.67.36.59:5432 was 2.3.1.
             add_data_node
---------------------------------------
 (dns,10.67.36.59,5432,postgres,t,f,f)
(1 row)

postgres=# select add_data_node('dns2',host=>'10.67.36.57');
NOTICE:  database "postgres" already exists on data node, skipping
NOTICE:  extension "timescaledb" already exists on data node, skipping
DETAIL:  TimescaleDB extension version on 10.67.36.57:5432 was 2.3.1.
             add_data_node
----------------------------------------
 (dns2,10.67.36.57,5432,postgres,t,f,f)
(1 row)

postgres=# select * from timescaledb_information.data_nodes;
 node_name |  owner   |                   options
-----------+----------+----------------------------------------------
 dns       | postgres | {host=10.67.36.59,port=5432,dbname=postgres}
 dns2      | postgres | {host=10.67.36.57,port=5432,dbname=postgres}
(2 rows)

底层在查询是应该是借助了FDW
postgres=# \des+
                                                             List of foreign servers
 Name |  Owner   | Foreign-data wrapper | Access privileges | Type | Version |                     FDW options                      | Description
------+----------+----------------------+-------------------+------+---------+------------------------------------------------------+-------------
 dns  | postgres | timescaledb_fdw      |                   |      |         | (host '10.67.36.59', port '5432', dbname 'postgres') |
 dns2 | postgres | timescaledb_fdw      |                   |      |         | (host '10.67.36.57', port '5432', dbname 'postgres') |
(2 rows)

4 运行promscale容器
docker run --name promscale_3ts -d -p 9201:9201 timescale/promscale:0.6 -db-password=secret -db-port=5432 -db-name=postgres -db-host=10.67.36.60 -db-ssl-mode=allow

5 在access node上测试分布式hypertable
postgres=# CREATE TABLE conditions (
postgres(#   time        TIMESTAMPTZ       NOT NULL,
postgres(#   location    TEXT              NOT NULL,
postgres(#   temperature DOUBLE PRECISION  NULL,
postgres(#   humidity    DOUBLE PRECISION  NULL
postgres(# );
CREATE TABLE

postgres=# SELECT create_distributed_hypertable('conditions', 'time', 'location');  #单副本
 create_distributed_hypertable
-------------------------------
 (1,public,conditions,t)
(1 row)

postgres=# SELECT * FROM timescaledb_information.hypertables;
 hypertable_schema | hypertable_name |  owner   | num_dimensions | num_chunks | compression_enabled | is_distributed | replication_factor | data_nodes | tablespaces
-------------------+-----------------+----------+----------------+------------+---------------------+----------------+--------------------+------------+-------------
 public            | conditions      | postgres |              2 |          2 | f                   | t              |                  1 | {dns,dns2} |
(1 row)

插入数据后查询
postgres=# SELECT chunk_name, data_nodes
postgres-# FROM timescaledb_information.chunks
postgres-# WHERE hypertable_name = 'conditions';
      chunk_name       | data_nodes
-----------------------+------------
 _dist_hyper_1_1_chunk | {dns}
 _dist_hyper_1_2_chunk | {dns2}
(2 rows)

通过执行计划看到查询下推到两个data node
postgres=# explain (verbose) select * from conditions;
                                                                              QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)  (cost=100.00..1873158.09 rows=41839260 width=56)
   Output: conditions."time", conditions.location, conditions.temperature, conditions.humidity
   ->  Append  (cost=100.00..1873158.09 rows=41839260 width=56)
         ->  Custom Scan (DataNodeScan) on public.conditions conditions_1  (cost=100.00..831980.90 rows=20919630 width=56)
               Output: conditions_1."time", conditions_1.location, conditions_1.temperature, conditions_1.humidity
               Data node: dns
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", location, temperature, humidity FROM public.conditions WHERE _timescaledb_internal.chunks_in(public.conditions.*, ARRAY[1])
         ->  Custom Scan (DataNodeScan) on public.conditions conditions_2  (cost=100.00..831980.90 rows=20919630 width=56)
               Output: conditions_2."time", conditions_2.location, conditions_2.temperature, conditions_2.humidity
               Data node: dns2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", location, temperature, humidity FROM public.conditions WHERE _timescaledb_internal.chunks_in(public.conditions.*, ARRAY[1])

分别查看两个chunk
postgres=# \d+ _timescaledb_internal._dist_hyper_1_1_chunk
                                  Foreign table "_timescaledb_internal._dist_hyper_1_1_chunk"
   Column    |           Type           | Collation | Nullable | Default | FDW options | Storage  | Stats target | Description
-------------+--------------------------+-----------+----------+---------+-------------+----------+--------------+-------------
 time        | timestamp with time zone |           | not null |         |             | plain    |              |
 location    | text                     |           | not null |         |             | extended |              |
 temperature | double precision         |           |          |         |             | plain    |              |
 humidity    | double precision         |           |          |         |             | plain    |              |
Check constraints:
    "constraint_1" CHECK ("time" >= '2021-10-28 00:00:00+00'::timestamp with time zone AND "time" < '2021-11-04 00:00:00+00'::timestamp with time zone)
    "constraint_2" CHECK (_timescaledb_internal.get_partition_hash(location) < 1073741823)
Server: dns
Inherits: conditions

postgres=# \d+ _timescaledb_internal._dist_hyper_1_2_chunk
                                  Foreign table "_timescaledb_internal._dist_hyper_1_2_chunk"
   Column    |           Type           | Collation | Nullable | Default | FDW options | Storage  | Stats target | Description
-------------+--------------------------+-----------+----------+---------+-------------+----------+--------------+-------------
 time        | timestamp with time zone |           | not null |         |             | plain    |              |
 location    | text                     |           | not null |         |             | extended |              |
 temperature | double precision         |           |          |         |             | plain    |              |
 humidity    | double precision         |           |          |         |             | plain    |              |
Check constraints:
    "constraint_1" CHECK ("time" >= '2021-10-28 00:00:00+00'::timestamp with time zone AND "time" < '2021-11-04 00:00:00+00'::timestamp with time zone)
    "constraint_3" CHECK (_timescaledb_internal.get_partition_hash(location) >= 1073741823)
Server: dns2
Inherits: conditions

创建两副本的分布式超表
CREATE TABLE conditions_rep2 (
  time        TIMESTAMPTZ       NOT NULL,
  location    TEXT              NOT NULL,
  temperature DOUBLE PRECISION  NULL,
  humidity    DOUBLE PRECISION  NULL
);
postgres=# SELECT create_distributed_hypertable('conditions_rep2', 'time', 'location',
postgres(#     replication_factor => 2);
 create_distributed_hypertable
-------------------------------
 (2,public,conditions_rep2,t)
(1 row)

INSERT INTO conditions_rep2
  VALUES
    (NOW(), 'office', 70.0, 50.3),
    (NOW(), 'basement', 66.5, 61.0),
	(NOW(), 'office', 71.3, 50.0),
    (NOW(), 'garage', 66.5, 60.0),
	(NOW(), 'office', 70.0, 50.0),
    (NOW(), 'basement', 66.5, 60.0),
	(NOW(), 'office', 70.2, 50.0),
    (NOW(), 'basement', 66.5, 60.0),
	(NOW(), 'garage', 70.9, 50.0),
    (NOW(), 'basement', 66.5, 60.5),
	(NOW(), 'office', 70.0, 51.0),
    (NOW(), 'basement', 66.5, 60.0),
    (NOW(), 'garage', 77.6, 65.2);

#查看chunk分布	 单副本和两副本都能看到
postgres=# select hypertable_schema,hypertable_name,chunk_schema,chunk_name,is_compressed,data_nodes from timescaledb_information.chunks ;
 hypertable_schema | hypertable_name |     chunk_schema      |      chunk_name       | is_compressed | data_nodes
-------------------+-----------------+-----------------------+-----------------------+---------------+------------
 public            | conditions      | _timescaledb_internal | _dist_hyper_1_1_chunk | f             | {dns}
 public            | conditions      | _timescaledb_internal | _dist_hyper_1_2_chunk | f             | {dns2}
 public            | conditions_rep2 | _timescaledb_internal | _dist_hyper_2_3_chunk | f             | {dns,dns2}
 public            | conditions_rep2 | _timescaledb_internal | _dist_hyper_2_4_chunk | f             | {dns,dns2}
	
6 prometheus配置prom_scale
编辑prometheus.yml，加入
remote_write:
        - url: "http://10.67.36.62:9201/write"
remote_read:
    - url: "http://10.67.36.62:9201/read"

重启prometheus
root@u1804:/var/snap/prometheus/current# systemctl restart snap.prometheus.prometheus.service

查看所有的hypertable
select hypertable_schema,hypertable_name,chunk_schema,chunk_name,is_compressed,data_nodes from timescaledb_information.chunks ;
hypertable_schema |                        hypertable_name                         |  owner   | num_dimensions | num_chunks | compression_enabled | is_distributed | replication_factor | data_nodes | tablespaces
-------------------+----------------------------------------------------------------+----------+----------------+------------+---------------------+----------------+--------------------+------------+-------------
 public            | conditions                                                     | postgres |              2 |          2 | f                   | t              |                  1 | {dns,dns2} |
 public            | conditions_rep2                                                | postgres |              2 |          2 | f                   | t              |                  2 | {dns,dns2} |
 prom_data         | node_cpu_seconds_total                                         | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_next_gc_bytes                                      | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_heap_objects                                       | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_mspan_inuse_bytes                                  | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_lookups_total                                      | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_stack_sys_bytes                                    | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | node_boot_time_seconds                                         | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | node_context_switches_total                                    | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | node_cpu_guest_seconds_total                                   | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_sys_bytes                                          | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_mspan_sys_bytes                                    | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_alloc_bytes                                        | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_mcache_inuse_bytes                                 | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_mcache_sys_bytes                                   | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_buck_hash_sys_bytes                                | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | node_arp_entries                                               | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_memstats_frees_total                                        | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |
 prom_data         | go_threads                                                     | postgres |              1 |          1 | t                   | t              |                  1 | {dns,dns2} |

数据大部分都存在chuck上，可以从三个节点分别看到
access node
postgres=# \l+ postgres
                                                                List of databases
   Name   |  Owner   | Encoding |  Collate   |   Ctype    | Access privileges |  Size  | Tablespace |                Description
----------+----------+----------+------------+------------+-------------------+--------+------------+--------------------------------------------
 postgres | postgres | UTF8     | en_US.utf8 | en_US.utf8 |                   | 259 MB | pg_default | default administrative connection database
(1 row)

dn1
postgres=# \l+ postgres
                                                                List of databases
   Name   |  Owner   | Encoding |  Collate   |   Ctype    | Access privileges |  Size   | Tablespace |                Description
----------+----------+----------+------------+------------+-------------------+---------+------------+--------------------------------------------
 postgres | postgres | UTF8     | en_US.utf8 | en_US.utf8 |                   | 5521 MB | pg_default | default administrative connection database
(1 row)

dn2
postgres=# \l+ postgres
                                                                List of databases
   Name   |  Owner   | Encoding |  Collate   |   Ctype    | Access privileges |  Size   | Tablespace |                Description
----------+----------+----------+------------+------------+-------------------+---------+------------+--------------------------------------------
 postgres | postgres | UTF8     | en_US.utf8 | en_US.utf8 |                   | 5758 MB | pg_default | default administrative connection database
(1 row)

 
 
# 在原有集群的基础上新增节点
Expanding the cluster
When adding nodes to a TimescaleDB cluster that is already being written to by Promscale, you should run the add_prom_node(node_name) function after running the standard add_data_node() function. For example:

SELECT add_data_node('example_node_name', host => 'example_host_address')
SELECT add_prom_node('example_node_name');
Note: add_prom_node should be run by the same database user, as the one writing data from Promscale. 


#######################  执行计划分析  ##########
chunk其中一个索引为 "_hyper_1_51_chunk_history_clock_idx" btree (clock DESC)
zabbix=# \d+ _timescaledb_internal._hyper_1_51_chunk
                                 Table "_timescaledb_internal._hyper_1_51_chunk"
 Column |       Type       | Collation | Nullable |        Default        | Storage | Stats target | Description
--------+------------------+-----------+----------+-----------------------+---------+--------------+-------------
 itemid | bigint           |           | not null |                       | plain   |              |
 clock  | integer          |           | not null | 0                     | plain   |              |
 value  | double precision |           | not null | '0'::double precision | plain   |              |
 ns     | integer          |           | not null | 0                     | plain   |              |
Indexes:
    "_hyper_1_51_chunk_history_1" btree (itemid, clock)
    "_hyper_1_51_chunk_history_clock_idx" btree (clock DESC)
Check constraints:
    "constraint_50" CHECK (clock >= 1636070400 AND clock < 1636156800)
Inherits: history
Access method: heap

1 使用order by clock desc走索引  缓存里有11096个heap页，从磁盘读了470个heap页，I/O Timings: read=6.996
zabbix=# explain (analyze,verbose,buffers,costs) select * from history where clock > 1635919200 order by clock DESC;
                                                                                            QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ChunkAppend) on public.history  (cost=0.29..6698.00 rows=231575 width=24) (actual time=0.068..124.847 rows=232042 loops=1)
   Output: history.itemid, history.clock, history.value, history.ns
   Order: history.clock DESC
   Startup Exclusion: false
   Runtime Exclusion: false
   Buffers: shared hit=11096 read=470
   I/O Timings: read=6.996
   ->  Index Scan using _hyper_1_51_chunk_history_clock_idx on _timescaledb_internal._hyper_1_51_chunk  (cost=0.29..1084.29 rows=37501 width=24) (actual time=0.065..14.643 rows=38000 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock, _hyper_1_51_chunk.value, _hyper_1_51_chunk.ns
         Index Cond: (_hyper_1_51_chunk.clock > 1635919200)
         Buffers: shared hit=4012 read=74
         I/O Timings: read=1.236
   ->  Index Scan using _hyper_1_47_chunk_history_clock_idx on _timescaledb_internal._hyper_1_47_chunk  (cost=0.29..3216.21 rows=111078 width=24) (actual time=0.038..38.402 rows=110882 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock, _hyper_1_47_chunk.value, _hyper_1_47_chunk.ns
         Index Cond: (_hyper_1_47_chunk.clock > 1635919200)
         Buffers: shared hit=3812 read=396
         I/O Timings: read=5.760
   ->  Index Scan using _hyper_1_43_chunk_history_clock_idx on _timescaledb_internal._hyper_1_43_chunk  (cost=0.29..2397.50 rows=82996 width=24) (actual time=0.042..25.523 rows=83160 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock, _hyper_1_43_chunk.value, _hyper_1_43_chunk.ns
         Index Cond: (_hyper_1_43_chunk.clock > 1635919200)
         Buffers: shared hit=3272
 Planning:
   Buffers: shared hit=73
 Planning Time: 1.516 ms
 Execution Time: 147.930 ms
(25 rows)




3 全表扫描，缓存里有1960个heap页，没有从磁盘读，没有IO Timing
zabbix=# explain (analyze,verbose,buffers,costs) select * from history where clock > 1635919200;
                                                                      QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------------
 Append  (cost=0.00..6404.77 rows=234301 width=24) (actual time=2.442..93.491 rows=235586 loops=1)
   Buffers: shared hit=1960
   ->  Seq Scan on _timescaledb_internal._hyper_1_43_chunk  (cost=0.00..2199.94 rows=82755 width=24) (actual time=2.441..18.987 rows=83160 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock, _hyper_1_43_chunk.value, _hyper_1_43_chunk.ns
         Filter: (_hyper_1_43_chunk.clock > 1635919200)
         Rows Removed by Filter: 27722
         Buffers: shared hit=821
   ->  Seq Scan on _timescaledb_internal._hyper_1_47_chunk  (cost=0.00..2211.09 rows=110247 width=24) (actual time=0.017..21.549 rows=110882 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock, _hyper_1_47_chunk.value, _hyper_1_47_chunk.ns
         Filter: (_hyper_1_47_chunk.clock > 1635919200)
         Buffers: shared hit=833
   ->  Seq Scan on _timescaledb_internal._hyper_1_51_chunk  (cost=0.00..822.24 rows=41299 width=24) (actual time=0.020..8.364 rows=41544 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock, _hyper_1_51_chunk.value, _hyper_1_51_chunk.ns
         Filter: (_hyper_1_51_chunk.clock > 1635919200)
         Buffers: shared hit=306
 Planning:
   Buffers: shared hit=65
 Planning Time: 0.956 ms
 Execution Time: 116.730 ms
(19 rows)

2 index only    只扫描了28个索引页，回表了9个heap页
zabbix=# explain (analyze,verbose,buffers,costs) select itemid,clock from history where itemid=10073 and clock > 1635919200 order by clock DESC;
                                                                                           QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ChunkAppend) on public.history  (cost=0.29..82.86 rows=3042 width=12) (actual time=0.041..2.162 rows=3057 loops=1)
   Output: history.itemid, history.clock
   Order: history.clock DESC
   Startup Exclusion: false
   Runtime Exclusion: false
   Buffers: shared hit=28
   ->  Index Only Scan Backward using _hyper_1_51_chunk_history_1 on _timescaledb_internal._hyper_1_51_chunk  (cost=0.29..17.59 rows=535 width=12) (actual time=0.039..0.304 rows=537 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock
         Index Cond: ((_hyper_1_51_chunk.itemid = 10073) AND (_hyper_1_51_chunk.clock > 1635919200))
         Heap Fetches: 9
         Buffers: shared hit=10
   ->  Index Only Scan Backward using _hyper_1_47_chunk_history_1 on _timescaledb_internal._hyper_1_47_chunk  (cost=0.42..36.76 rows=1432 width=12) (actual time=0.027..0.553 rows=1440 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock
         Index Cond: ((_hyper_1_47_chunk.itemid = 10073) AND (_hyper_1_47_chunk.clock > 1635919200))
         Heap Fetches: 0
         Buffers: shared hit=10
   ->  Index Only Scan Backward using _hyper_1_43_chunk_history_1 on _timescaledb_internal._hyper_1_43_chunk  (cost=0.42..28.52 rows=1075 width=12) (actual time=0.031..0.396 rows=1080 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock
         Index Cond: ((_hyper_1_43_chunk.itemid = 10073) AND (_hyper_1_43_chunk.clock > 1635919200))
         Heap Fetches: 0
         Buffers: shared hit=8
 Planning:
   Buffers: shared hit=65
 Planning Time: 1.353 ms
 Execution Time: 2.733 ms
(25 rows)
#############
Bitmap Scan

是索引掃描和順序掃描的混合體。為了解決索引掃描的缺點並充分利用其優點。正如上面所說，對於索引資料結構中的資料，需要找到heap 頁中對應的資料。因此需要獲取一次索引頁，然後獲取 heap 頁，
從而造成大量隨機 IO 。 Bitmap 掃描方法平衡了不使用隨機 IO 的索引掃描優點。

Bitmap index scan ：首先獲取索引資料併為所有 TID 建立 bitmap 。為了理解方法，可以認為 bitmap 包含所有頁的雜湊（基於頁號），每個頁的 entry 包含頁內所有偏移的陣列。

Bitmap heap scan ：從頁的 bitmap 中讀取值，然後針對頁和偏移掃描資料。最後檢查可見性和條件並返回 tuple 。

下面查詢使用bitmap 掃描，因為他選擇的記錄很多（比如 too much for index scan ）但不是大量（ too little for sequential scan ）。
## index only有回表， heap fetches挺多，时间慢
zabbix=# explain (analyze,verbose,buffers,costs) select itemid,clock from history where itemid=10073 and clock < 1636092000;
                                                                                                          QUERY PLAN

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------
 Append  (cost=0.42..1566.38 rows=19371 width=12) (actual time=0.042..9.852 rows=18774 loops=1)
   Buffers: shared hit=1283
   ->  Index Only Scan using _hyper_1_43_chunk_history_1 on _timescaledb_internal._hyper_1_43_chunk  (cost=0.42..150.23 rows=1441 width=12) (actual time=0.041..0.609 rows=1440 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock
         Index Cond: ((_hyper_1_43_chunk.itemid = 10073) AND (_hyper_1_43_chunk.clock < 1636092000))
         Heap Fetches: 186
         Buffers: shared hit=143
   ->  Index Only Scan using _hyper_1_8_chunk_history_1 on _timescaledb_internal._hyper_1_8_chunk  (cost=0.42..168.69 rows=1360 width=12) (actual time=0.043..0.557 rows=1356 loops=1)
         Output: _hyper_1_8_chunk.itemid, _hyper_1_8_chunk.clock
         Index Cond: ((_hyper_1_8_chunk.itemid = 10073) AND (_hyper_1_8_chunk.clock < 1636092000))
         Heap Fetches: 222
         Buffers: shared hit=149
   ->  Index Only Scan using _hyper_1_36_chunk_history_1 on _timescaledb_internal._hyper_1_36_chunk  (cost=0.42..49.52 rows=1410 width=12) (actual time=0.029..0.406 rows=1440 loops=1)
         Output: _hyper_1_36_chunk.itemid, _hyper_1_36_chunk.clock
         Index Cond: ((_hyper_1_36_chunk.itemid = 10073) AND (_hyper_1_36_chunk.clock < 1636092000))
         Heap Fetches: 68
         Buffers: shared hit=59
   ->  Custom Scan (DecompressChunk) on _timescaledb_internal._hyper_1_1_chunk  (cost=1.43..2.86 rows=2000 width=12) (actual time=0.111..0.363 rows=1440 loops=1)
         Output: _hyper_1_1_chunk.itemid, _hyper_1_1_chunk.clock
         Filter: (_hyper_1_1_chunk.clock < 1636092000)
         Buffers: shared hit=31
         ->  Index Scan using compress_hyper_8_27_chunk__compressed_hypertable_8_itemid__ts_m on _timescaledb_internal.compress_hyper_8_27_chunk  (cost=0.14..2.86 rows=2 width=52) (actual time=0.015..0.0
18 rows=2 loops=1)
               Output: compress_hyper_8_27_chunk._ts_meta_count, compress_hyper_8_27_chunk.itemid, compress_hyper_8_27_chunk.clock
               Index Cond: (compress_hyper_8_27_chunk.itemid = 10073)
               Filter: (compress_hyper_8_27_chunk._ts_meta_min_1 < 1636092000)
               Buffers: shared hit=2
   ->  Index Only Scan using _hyper_1_4_chunk_history_1 on _timescaledb_internal._hyper_1_4_chunk  (cost=0.41..37.04 rows=1391 width=12) (actual time=0.042..0.319 rows=1391 loops=1)
         Output: _hyper_1_4_chunk.itemid, _hyper_1_4_chunk.clock
         Index Cond: ((_hyper_1_4_chunk.itemid = 10073) AND (_hyper_1_4_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=12
   ->  Index Only Scan using _hyper_1_39_chunk_history_1 on _timescaledb_internal._hyper_1_39_chunk  (cost=0.42..39.82 rows=1255 width=12) (actual time=0.028..0.330 rows=1267 loops=1)
         Output: _hyper_1_39_chunk.itemid, _hyper_1_39_chunk.clock
         Index Cond: ((_hyper_1_39_chunk.itemid = 10073) AND (_hyper_1_39_chunk.clock < 1636092000))
         Heap Fetches: 36
         Buffers: shared hit=37
   ->  Index Only Scan using _hyper_1_6_chunk_history_1 on _timescaledb_internal._hyper_1_6_chunk  (cost=0.41..38.02 rows=1440 width=12) (actual time=0.041..0.349 rows=1440 loops=1)
         Output: _hyper_1_6_chunk.itemid, _hyper_1_6_chunk.clock
         Index Cond: ((_hyper_1_6_chunk.itemid = 10073) AND (_hyper_1_6_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=10
   ->  Index Only Scan using _hyper_1_2_chunk_history_1 on _timescaledb_internal._hyper_1_2_chunk  (cost=0.41..39.12 rows=1440 width=12) (actual time=0.038..0.354 rows=1440 loops=1)
         Output: _hyper_1_2_chunk.itemid, _hyper_1_2_chunk.clock
         Index Cond: ((_hyper_1_2_chunk.itemid = 10073) AND (_hyper_1_2_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=12
   ->  Index Only Scan using _hyper_1_3_chunk_history_1 on _timescaledb_internal._hyper_1_3_chunk  (cost=0.41..39.12 rows=1440 width=12) (actual time=0.047..0.341 rows=1440 loops=1)
         Output: _hyper_1_3_chunk.itemid, _hyper_1_3_chunk.clock
         Index Cond: ((_hyper_1_3_chunk.itemid = 10073) AND (_hyper_1_3_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=10
   ->  Index Only Scan using _hyper_1_47_chunk_history_1 on _timescaledb_internal._hyper_1_47_chunk  (cost=0.42..625.40 rows=1442 width=12) (actual time=0.023..1.406 rows=1440 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock
         Index Cond: ((_hyper_1_47_chunk.itemid = 10073) AND (_hyper_1_47_chunk.clock < 1636092000))
         Heap Fetches: 986
         Buffers: shared hit=723
   ->  Index Only Scan using _hyper_1_51_chunk_history_1 on _timescaledb_internal._hyper_1_51_chunk  (cost=0.29..38.43 rows=367 width=12) (actual time=0.043..0.131 rows=360 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock
         Index Cond: ((_hyper_1_51_chunk.itemid = 10073) AND (_hyper_1_51_chunk.clock < 1636092000))
         Heap Fetches: 5
         Buffers: shared hit=9
   ->  Index Only Scan using _hyper_1_35_chunk_history_1 on _timescaledb_internal._hyper_1_35_chunk  (cost=0.42..165.40 rows=1505 width=12) (actual time=0.034..0.428 rows=1440 loops=1)
         Output: _hyper_1_35_chunk.itemid, _hyper_1_35_chunk.clock
         Index Cond: ((_hyper_1_35_chunk.itemid = 10073) AND (_hyper_1_35_chunk.clock < 1636092000))
         Heap Fetches: 109
         Buffers: shared hit=67
   ->  Index Only Scan using _hyper_1_5_chunk_history_1 on _timescaledb_internal._hyper_1_5_chunk  (cost=0.41..38.02 rows=1440 width=12) (actual time=0.032..0.333 rows=1440 loops=1)
         Output: _hyper_1_5_chunk.itemid, _hyper_1_5_chunk.clock
         Index Cond: ((_hyper_1_5_chunk.itemid = 10073) AND (_hyper_1_5_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=11
   ->  Index Only Scan using _hyper_1_7_chunk_history_1 on _timescaledb_internal._hyper_1_7_chunk  (cost=0.29..37.89 rows=1440 width=12) (actual time=0.023..0.345 rows=1440 loops=1)
         Output: _hyper_1_7_chunk.itemid, _hyper_1_7_chunk.clock
         Index Cond: ((_hyper_1_7_chunk.itemid = 10073) AND (_hyper_1_7_chunk.clock < 1636092000))
         Heap Fetches: 0
         Buffers: shared hit=10
 Planning:
   Buffers: shared hit=2123 dirtied=2
 Planning Time: 8.455 ms
 Execution Time: 11.868 ms


## bitmap scan  IO放大       1440条数据，扫描了600-800多数据块
zabbix=# explain (analyze,verbose,buffers,costs) select itemid,clock,value from history where itemid=10073 and clock < 1636092000;
                                                                                                          QUERY PLAN

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------
 Append  (cost=22.89..7796.28 rows=19378 width=20) (actual time=0.304..26.915 rows=18774 loops=1)
   Buffers: shared hit=7187
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_43_chunk  (cost=22.89..815.02 rows=1441 width=20) (actual time=0.303..2.458 rows=1440 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock, _hyper_1_43_chunk.value
         Recheck Cond: ((_hyper_1_43_chunk.itemid = 10073) AND (_hyper_1_43_chunk.clock < 1636092000))
         Heap Blocks: exact=805
         Buffers: shared hit=813
         ->  Bitmap Index Scan on _hyper_1_43_chunk_history_1  (cost=0.00..22.53 rows=1441 width=0) (actual time=0.179..0.180 rows=1440 loops=1)
               Index Cond: ((_hyper_1_43_chunk.itemid = 10073) AND (_hyper_1_43_chunk.clock < 1636092000))
               Buffers: shared hit=8
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_8_chunk  (cost=22.06..729.76 rows=1360 width=20) (actual time=0.246..2.073 rows=1356 loops=1)
         Output: _hyper_1_8_chunk.itemid, _hyper_1_8_chunk.clock, _hyper_1_8_chunk.value
         Recheck Cond: ((_hyper_1_8_chunk.itemid = 10073) AND (_hyper_1_8_chunk.clock < 1636092000))
         Heap Blocks: exact=620
         Buffers: shared hit=629
         ->  Bitmap Index Scan on _hyper_1_8_chunk_history_1  (cost=0.00..21.72 rows=1360 width=0) (actual time=0.172..0.173 rows=1356 loops=1)
               Index Cond: ((_hyper_1_8_chunk.itemid = 10073) AND (_hyper_1_8_chunk.clock < 1636092000))
               Buffers: shared hit=9
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_36_chunk  (cost=22.57..804.55 rows=1410 width=20) (actual time=0.255..2.101 rows=1440 loops=1)
         Output: _hyper_1_36_chunk.itemid, _hyper_1_36_chunk.clock, _hyper_1_36_chunk.value
         Recheck Cond: ((_hyper_1_36_chunk.itemid = 10073) AND (_hyper_1_36_chunk.clock < 1636092000))
         Heap Blocks: exact=712
         Buffers: shared hit=720
         ->  Bitmap Index Scan on _hyper_1_36_chunk_history_1  (cost=0.00..22.22 rows=1410 width=0) (actual time=0.173..0.174 rows=1440 loops=1)
               Index Cond: ((_hyper_1_36_chunk.itemid = 10073) AND (_hyper_1_36_chunk.clock < 1636092000))
               Buffers: shared hit=8
   ->  Custom Scan (DecompressChunk) on _timescaledb_internal._hyper_1_1_chunk  (cost=1.43..2.86 rows=2000 width=20) (actual time=0.073..0.434 rows=1440 loops=1)
         Output: _hyper_1_1_chunk.itemid, _hyper_1_1_chunk.clock, _hyper_1_1_chunk.value
         Filter: (_hyper_1_1_chunk.clock < 1636092000)
         Buffers: shared hit=10
         ->  Index Scan using compress_hyper_8_27_chunk__compressed_hypertable_8_itemid__ts_m on _timescaledb_internal.compress_hyper_8_27_chunk  (cost=0.14..2.86 rows=2 width=84) (actual time=0.019..0.0
23 rows=2 loops=1)
               Output: compress_hyper_8_27_chunk._ts_meta_count, compress_hyper_8_27_chunk.itemid, compress_hyper_8_27_chunk.clock, compress_hyper_8_27_chunk.value
               Index Cond: (compress_hyper_8_27_chunk.itemid = 10073)
               Filter: (compress_hyper_8_27_chunk._ts_meta_min_1 < 1636092000)
               Buffers: shared hit=2
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_4_chunk  (cost=23.47..443.34 rows=1391 width=20) (actual time=0.178..1.471 rows=1391 loops=1)
         Output: _hyper_1_4_chunk.itemid, _hyper_1_4_chunk.clock, _hyper_1_4_chunk.value
         Recheck Cond: ((_hyper_1_4_chunk.itemid = 10073) AND (_hyper_1_4_chunk.clock < 1636092000))
         Heap Blocks: exact=399
         Buffers: shared hit=410
         ->  Bitmap Index Scan on _hyper_1_4_chunk_history_1  (cost=0.00..23.12 rows=1391 width=0) (actual time=0.132..0.132 rows=1391 loops=1)
               Index Cond: ((_hyper_1_4_chunk.itemid = 10073) AND (_hyper_1_4_chunk.clock < 1636092000))
               Buffers: shared hit=11
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_39_chunk  (cost=19.88..712.03 rows=1255 width=20) (actual time=0.244..1.822 rows=1267 loops=1)
         Output: _hyper_1_39_chunk.itemid, _hyper_1_39_chunk.clock, _hyper_1_39_chunk.value
         Recheck Cond: ((_hyper_1_39_chunk.itemid = 10073) AND (_hyper_1_39_chunk.clock < 1636092000))
         Heap Blocks: exact=700
         Buffers: shared hit=707
         ->  Bitmap Index Scan on _hyper_1_39_chunk_history_1  (cost=0.00..19.57 rows=1255 width=0) (actual time=0.163..0.163 rows=1267 loops=1)
               Index Cond: ((_hyper_1_39_chunk.itemid = 10073) AND (_hyper_1_39_chunk.clock < 1636092000))
               Buffers: shared hit=7
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_6_chunk  (cost=23.98..458.58 rows=1440 width=20) (actual time=0.180..1.604 rows=1440 loops=1)
         Output: _hyper_1_6_chunk.itemid, _hyper_1_6_chunk.clock, _hyper_1_6_chunk.value
         Recheck Cond: ((_hyper_1_6_chunk.itemid = 10073) AND (_hyper_1_6_chunk.clock < 1636092000))
         Heap Blocks: exact=412
         Buffers: shared hit=421
         ->  Bitmap Index Scan on _hyper_1_6_chunk_history_1  (cost=0.00..23.62 rows=1440 width=0) (actual time=0.133..0.133 rows=1440 loops=1)
               Index Cond: ((_hyper_1_6_chunk.itemid = 10073) AND (_hyper_1_6_chunk.clock < 1636092000))
               Buffers: shared hit=9
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_2_chunk  (cost=25.07..459.68 rows=1440 width=20) (actual time=0.189..1.672 rows=1440 loops=1)
         Output: _hyper_1_2_chunk.itemid, _hyper_1_2_chunk.clock, _hyper_1_2_chunk.value
         Recheck Cond: ((_hyper_1_2_chunk.itemid = 10073) AND (_hyper_1_2_chunk.clock < 1636092000))
         Heap Blocks: exact=412
         Buffers: shared hit=423
         ->  Bitmap Index Scan on _hyper_1_2_chunk_history_1  (cost=0.00..24.71 rows=1440 width=0) (actual time=0.143..0.144 rows=1440 loops=1)
               Index Cond: ((_hyper_1_2_chunk.itemid = 10073) AND (_hyper_1_2_chunk.clock < 1636092000))
               Buffers: shared hit=11
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_3_chunk  (cost=25.07..459.68 rows=1440 width=20) (actual time=0.214..1.725 rows=1440 loops=1)
         Output: _hyper_1_3_chunk.itemid, _hyper_1_3_chunk.clock, _hyper_1_3_chunk.value
         Recheck Cond: ((_hyper_1_3_chunk.itemid = 10073) AND (_hyper_1_3_chunk.clock < 1636092000))
         Heap Blocks: exact=413
         Buffers: shared hit=422
         ->  Bitmap Index Scan on _hyper_1_3_chunk_history_1  (cost=0.00..24.71 rows=1440 width=0) (actual time=0.160..0.160 rows=1440 loops=1)
               Index Cond: ((_hyper_1_3_chunk.itemid = 10073) AND (_hyper_1_3_chunk.clock < 1636092000))
               Buffers: shared hit=9
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_47_chunk  (cost=22.90..820.36 rows=1442 width=20) (actual time=0.280..2.217 rows=1440 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock, _hyper_1_47_chunk.value
         Recheck Cond: ((_hyper_1_47_chunk.itemid = 10073) AND (_hyper_1_47_chunk.clock < 1636092000))
         Heap Blocks: exact=817
         Buffers: shared hit=826
         ->  Bitmap Index Scan on _hyper_1_47_chunk_history_1  (cost=0.00..22.54 rows=1442 width=0) (actual time=0.186..0.186 rows=1440 loops=1)
               Index Cond: ((_hyper_1_47_chunk.itemid = 10073) AND (_hyper_1_47_chunk.clock < 1636092000))
               Buffers: shared hit=9
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_51_chunk  (cost=6.32..245.80 rows=374 width=20) (actual time=0.070..0.546 rows=360 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock, _hyper_1_51_chunk.value
         Recheck Cond: ((_hyper_1_51_chunk.itemid = 10073) AND (_hyper_1_51_chunk.clock < 1636092000))
         Heap Blocks: exact=201
         Buffers: shared hit=204
         ->  Bitmap Index Scan on _hyper_1_51_chunk_history_1  (cost=0.00..6.23 rows=374 width=0) (actual time=0.046..0.046 rows=360 loops=1)
               Index Cond: ((_hyper_1_51_chunk.itemid = 10073) AND (_hyper_1_51_chunk.clock < 1636092000))
               Buffers: shared hit=3
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_35_chunk  (cost=23.54..830.72 rows=1505 width=20) (actual time=0.250..1.988 rows=1440 loops=1)
         Output: _hyper_1_35_chunk.itemid, _hyper_1_35_chunk.clock, _hyper_1_35_chunk.value
         Recheck Cond: ((_hyper_1_35_chunk.itemid = 10073) AND (_hyper_1_35_chunk.clock < 1636092000))
         Heap Blocks: exact=754
         Buffers: shared hit=762
         ->  Bitmap Index Scan on _hyper_1_35_chunk_history_1  (cost=0.00..23.17 rows=1505 width=0) (actual time=0.163..0.163 rows=1440 loops=1)
               Index Cond: ((_hyper_1_35_chunk.itemid = 10073) AND (_hyper_1_35_chunk.clock < 1636092000))
               Buffers: shared hit=8
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_5_chunk  (cost=23.98..458.58 rows=1440 width=20) (actual time=0.195..1.496 rows=1440 loops=1)
         Output: _hyper_1_5_chunk.itemid, _hyper_1_5_chunk.clock, _hyper_1_5_chunk.value
         Recheck Cond: ((_hyper_1_5_chunk.itemid = 10073) AND (_hyper_1_5_chunk.clock < 1636092000))
         Heap Blocks: exact=410
         Buffers: shared hit=420
         ->  Bitmap Index Scan on _hyper_1_5_chunk_history_1  (cost=0.00..23.62 rows=1440 width=0) (actual time=0.147..0.147 rows=1440 loops=1)
               Index Cond: ((_hyper_1_5_chunk.itemid = 10073) AND (_hyper_1_5_chunk.clock < 1636092000))
               Buffers: shared hit=10
   ->  Bitmap Heap Scan on _timescaledb_internal._hyper_1_7_chunk  (cost=23.85..458.45 rows=1440 width=20) (actual time=0.220..1.565 rows=1440 loops=1)
         Output: _hyper_1_7_chunk.itemid, _hyper_1_7_chunk.clock, _hyper_1_7_chunk.value
         Recheck Cond: ((_hyper_1_7_chunk.itemid = 10073) AND (_hyper_1_7_chunk.clock < 1636092000))
         Heap Blocks: exact=411
         Buffers: shared hit=420
         ->  Bitmap Index Scan on _hyper_1_7_chunk_history_1  (cost=0.00..23.49 rows=1440 width=0) (actual time=0.163..0.163 rows=1440 loops=1)
               Index Cond: ((_hyper_1_7_chunk.itemid = 10073) AND (_hyper_1_7_chunk.clock < 1636092000))
               Buffers: shared hit=9
 Planning:
   Buffers: shared hit=288
 Planning Time: 2.718 ms
 Execution Time: 29.013 ms
(119 rows)

# index scan    排序在硬盘读写了临时文件。  当条件为clock > 1635919200的时候，并没有在硬盘上读写临时文件
zabbix=# explain (analyze,verbose,buffers,costs) select * from history where clock < 1636092000 order by clock desc;
                                                                                               QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ChunkAppend) on public.history  (cost=0.29..24907.44 rows=1074654 width=24) (actual time=0.021..752.715 rows=1054101 loops=1)
   Output: history.itemid, history.clock, history.value, history.ns
   Order: history.clock DESC
   Startup Exclusion: false
   Runtime Exclusion: false
   Buffers: shared hit=89889, temp read=2264 written=2272
   ->  Index Scan using _hyper_1_51_chunk_history_clock_idx on _timescaledb_internal._hyper_1_51_chunk  (cost=0.29..825.25 rows=28486 width=24) (actual time=0.019..8.893 rows=27720 loops=1)
         Output: _hyper_1_51_chunk.itemid, _hyper_1_51_chunk.clock, _hyper_1_51_chunk.value, _hyper_1_51_chunk.ns
         Index Cond: (_hyper_1_51_chunk.clock < 1636092000)
         Buffers: shared hit=2066
   ->  Index Scan using _hyper_1_47_chunk_history_clock_idx on _timescaledb_internal._hyper_1_47_chunk  (cost=0.29..3201.63 rows=110247 width=24) (actual time=0.018..38.496 rows=110882 loops=1)
         Output: _hyper_1_47_chunk.itemid, _hyper_1_47_chunk.clock, _hyper_1_47_chunk.value, _hyper_1_47_chunk.ns
         Index Cond: (_hyper_1_47_chunk.clock < 1636092000)
         Buffers: shared hit=4208
   ->  Index Scan using _hyper_1_43_chunk_history_clock_idx on _timescaledb_internal._hyper_1_43_chunk  (cost=0.29..3191.02 rows=110315 width=24) (actual time=0.022..30.728 rows=110882 loops=1)
         Output: _hyper_1_43_chunk.itemid, _hyper_1_43_chunk.clock, _hyper_1_43_chunk.value, _hyper_1_43_chunk.ns
         Index Cond: (_hyper_1_43_chunk.clock < 1636092000)
         Buffers: shared hit=4298
   ->  Index Scan using _hyper_1_39_chunk_history_clock_idx on _timescaledb_internal._hyper_1_39_chunk  (cost=0.29..2810.50 rows=97364 width=24) (actual time=0.031..28.651 rows=97613 loops=1)
         Output: _hyper_1_39_chunk.itemid, _hyper_1_39_chunk.clock, _hyper_1_39_chunk.value, _hyper_1_39_chunk.ns
         Index Cond: (_hyper_1_39_chunk.clock < 1636092000)
         Buffers: shared hit=8560
   ->  Index Scan using _hyper_1_36_chunk_history_clock_idx on _timescaledb_internal._hyper_1_36_chunk  (cost=0.29..3189.70 rows=110580 width=24) (actual time=0.024..39.719 rows=110887 loops=1)
         Output: _hyper_1_36_chunk.itemid, _hyper_1_36_chunk.clock, _hyper_1_36_chunk.value, _hyper_1_36_chunk.ns
         Index Cond: (_hyper_1_36_chunk.clock < 1636092000)
         Buffers: shared hit=43893
   ->  Index Scan using _hyper_1_35_chunk_history_clock_idx on _timescaledb_internal._hyper_1_35_chunk  (cost=0.29..3165.47 rows=110798 width=24) (actual time=0.039..37.363 rows=110880 loops=1)
         Output: _hyper_1_35_chunk.itemid, _hyper_1_35_chunk.clock, _hyper_1_35_chunk.value, _hyper_1_35_chunk.ns
         Index Cond: (_hyper_1_35_chunk.clock < 1636092000)
         Buffers: shared hit=23302
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=52.922..69.530 rows=94028 loops=1)
         Output: _hyper_1_8_chunk.itemid, _hyper_1_8_chunk.clock, _hyper_1_8_chunk.value, _hyper_1_8_chunk.ns
         Sort Key: _hyper_1_8_chunk.clock DESC
         Sort Method: external merge  Disk: 3504kB
         Buffers: shared hit=693, temp read=438 written=439
         ->  Seq Scan on _timescaledb_internal._hyper_1_8_chunk  (cost=0.00..1866.48 rows=93876 width=24) (actual time=0.023..16.876 rows=94028 loops=1)
               Output: _hyper_1_8_chunk.itemid, _hyper_1_8_chunk.clock, _hyper_1_8_chunk.value, _hyper_1_8_chunk.ns
               Filter: (_hyper_1_8_chunk.clock < 1636092000)
               Buffers: shared hit=693
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=31.515..41.179 rows=56160 loops=1)
         Output: _hyper_1_2_chunk.itemid, _hyper_1_2_chunk.clock, _hyper_1_2_chunk.value, _hyper_1_2_chunk.ns
         Sort Key: _hyper_1_2_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=413, temp read=262 written=263
         ->  Seq Scan on _timescaledb_internal._hyper_1_2_chunk  (cost=0.00..1114.90 rows=56151 width=24) (actual time=0.027..10.435 rows=56160 loops=1)
               Output: _hyper_1_2_chunk.itemid, _hyper_1_2_chunk.clock, _hyper_1_2_chunk.value, _hyper_1_2_chunk.ns
               Filter: (_hyper_1_2_chunk.clock < 1636092000)
               Buffers: shared hit=413
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=31.522..41.480 rows=56160 loops=1)
         Output: _hyper_1_3_chunk.itemid, _hyper_1_3_chunk.clock, _hyper_1_3_chunk.value, _hyper_1_3_chunk.ns
         Sort Key: _hyper_1_3_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=413, temp read=262 written=263
         ->  Seq Scan on _timescaledb_internal._hyper_1_3_chunk  (cost=0.00..1114.90 rows=56151 width=24) (actual time=0.021..10.315 rows=56160 loops=1)
               Output: _hyper_1_3_chunk.itemid, _hyper_1_3_chunk.clock, _hyper_1_3_chunk.value, _hyper_1_3_chunk.ns
               Filter: (_hyper_1_3_chunk.clock < 1636092000)
               Buffers: shared hit=413
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=30.802..40.198 rows=56160 loops=1)
         Output: _hyper_1_7_chunk.itemid, _hyper_1_7_chunk.clock, _hyper_1_7_chunk.value, _hyper_1_7_chunk.ns
         Sort Key: _hyper_1_7_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=413, temp read=262 written=263
         ->  Seq Scan on _timescaledb_internal._hyper_1_7_chunk  (cost=0.00..1114.90 rows=56151 width=24) (actual time=0.020..10.136 rows=56160 loops=1)
               Output: _hyper_1_7_chunk.itemid, _hyper_1_7_chunk.clock, _hyper_1_7_chunk.value, _hyper_1_7_chunk.ns
               Filter: (_hyper_1_7_chunk.clock < 1636092000)
               Buffers: shared hit=413
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=38.721..48.860 rows=56160 loops=1)
         Output: _hyper_1_1_chunk.itemid, _hyper_1_1_chunk.clock, _hyper_1_1_chunk.value, _hyper_1_1_chunk.ns
         Sort Key: _hyper_1_1_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=405, temp read=262 written=263
         ->  Custom Scan (DecompressChunk) on _timescaledb_internal._hyper_1_1_chunk  (cost=0.08..5.97 rows=78000 width=24) (actual time=0.121..13.597 rows=56160 loops=1)
               Output: _hyper_1_1_chunk.itemid, _hyper_1_1_chunk.clock, _hyper_1_1_chunk.value, _hyper_1_1_chunk.ns
               Filter: (_hyper_1_1_chunk.clock < 1636092000)
               Buffers: shared hit=405
               ->  Seq Scan on _timescaledb_internal.compress_hyper_8_27_chunk  (cost=0.00..5.97 rows=78 width=124) (actual time=0.020..0.137 rows=78 loops=1)
                     Output: compress_hyper_8_27_chunk._ts_meta_count, compress_hyper_8_27_chunk.itemid, compress_hyper_8_27_chunk.clock, compress_hyper_8_27_chunk.value, compress_hyper_8_27_chunk.ns
                     Filter: (compress_hyper_8_27_chunk._ts_meta_min_1 < 1636092000)
                     Buffers: shared hit=5
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=30.719..40.610 rows=56160 loops=1)
         Output: _hyper_1_6_chunk.itemid, _hyper_1_6_chunk.clock, _hyper_1_6_chunk.value, _hyper_1_6_chunk.ns
         Sort Key: _hyper_1_6_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=413, temp read=262 written=263
         ->  Seq Scan on _timescaledb_internal._hyper_1_6_chunk  (cost=0.00..1114.90 rows=56151 width=24) (actual time=0.018..10.170 rows=56160 loops=1)
               Output: _hyper_1_6_chunk.itemid, _hyper_1_6_chunk.clock, _hyper_1_6_chunk.value, _hyper_1_6_chunk.ns
               Filter: (_hyper_1_6_chunk.clock < 1636092000)
               Buffers: shared hit=413
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=30.275..39.714 rows=56160 loops=1)
         Output: _hyper_1_5_chunk.itemid, _hyper_1_5_chunk.clock, _hyper_1_5_chunk.value, _hyper_1_5_chunk.ns
         Sort Key: _hyper_1_5_chunk.clock DESC
         Sort Method: external merge  Disk: 2096kB
         Buffers: shared hit=413, temp read=262 written=263
         ->  Seq Scan on _timescaledb_internal._hyper_1_5_chunk  (cost=0.00..1114.90 rows=56151 width=24) (actual time=0.018..10.176 rows=56160 loops=1)
               Output: _hyper_1_5_chunk.itemid, _hyper_1_5_chunk.clock, _hyper_1_5_chunk.value, _hyper_1_5_chunk.ns
               Filter: (_hyper_1_5_chunk.clock < 1636092000)
               Buffers: shared hit=413
   ->  Sort  (cost=0.00..0.00 rows=0 width=0) (actual time=30.233..39.467 rows=54249 loops=1)
         Output: _hyper_1_4_chunk.itemid, _hyper_1_4_chunk.clock, _hyper_1_4_chunk.value, _hyper_1_4_chunk.ns
         Sort Key: _hyper_1_4_chunk.clock DESC
         Sort Method: external merge  Disk: 2032kB
         Buffers: shared hit=399, temp read=254 written=255
         ->  Seq Scan on _timescaledb_internal._hyper_1_4_chunk  (cost=0.00..1076.93 rows=54233 width=24) (actual time=0.016..9.800 rows=54249 loops=1)
               Output: _hyper_1_4_chunk.itemid, _hyper_1_4_chunk.clock, _hyper_1_4_chunk.value, _hyper_1_4_chunk.ns
               Filter: (_hyper_1_4_chunk.clock < 1636092000)
               Buffers: shared hit=399
 Planning:
   Buffers: shared hit=411 dirtied=6
 Planning Time: 4.424 ms
 Execution Time: 864.554 ms
(110 rows)

