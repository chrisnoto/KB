acks=-1(all)时,瓶颈很有肯能发生在replication time
Replication Time ~= Num_Fetches * (Local_Time_On_The_Follower + Fetch_Request_Total_Time_On_The_Leader) / num.replica.fetchers

Replica fetchers per broker = (Cluster_Size - 1 ) * num.replica.fetchers 
设置多少的replica fetchers合理？一般按照官方的生产建议设置成4就好了


Lag=logSize-Offset  
Lag通常为正值，反应有多少消息未读取或未消费
Lag为负值，异常

显示主题信息
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test_topic

添加分区
bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic test_topic --partitions 3

创建主题
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic test_topic

列出主题
bin/kafka-topics.sh --list --zookeeper localhost:2181

删除主题
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test_topic
注意：需要在Broker的配置文件server.properties中配置 delete.topic.enable=true 才能删除主题。

简单的将消息输出到标准输出中
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

将文件或标准输入的内容发送到Kafka集群
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test < file-input.txt

####zoo1 zoo2 zoo3均为swarm内部service名称，可解析
/opt/kafka_2.11-2.0.0 # bin/kafka-topics.sh --list --zookeeper zoo1:2181
__consumer_offsets
logstash
metricbeat
/opt/kafka_2.11-2.0.0 # bin/kafka-topics.sh --list --zookeeper zoo2:2181
__consumer_offsets
logstash
metricbeat
/opt/kafka_2.11-2.0.0 # bin/kafka-topics.sh --list --zookeeper zoo3:2181
__consumer_offsets
logstash
metricbeat

/opt/kafka_2.11-2.0.0 # bin/kafka-topics.sh --list --zookeeper zoo3:2181 zoo2:2181 zoo1:2181
__consumer_offsets
logstash
metricbeat

/opt/kafka_2.11-2.0.0/bin # ./kafka-topics.sh --describe --zookeeper 10.67.36.69:2182 --topic test_topic
Topic:test_topic        PartitionCount:3        ReplicationFactor:3     Configs:
        Topic: test_topic       Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3
        Topic: test_topic       Partition: 1    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
        Topic: test_topic       Partition: 2    Leader: 3       Replicas: 3,1,2 Isr: 3,1,2

########增加replica factor##########
增加前
[root@kafka3 ~]# kafka-topics --describe --zookeeper 10.67.51.145:2181 --topic perf
Topic:perf      PartitionCount:3        ReplicationFactor:1     Configs:
        Topic: perf     Partition: 0    Leader: 1       Replicas: 1     Isr: 1
        Topic: perf     Partition: 1    Leader: 2       Replicas: 2     Isr: 2
        Topic: perf     Partition: 2    Leader: 3       Replicas: 3     Isr: 3
[root@kafka2 ~]# cat increase-replica-factor.json
{"version":1,
 "partitions":[
    {"topic":"perf",
     "partition":0,
     "replicas":[1,2]
    },
    {"topic":"perf",
     "partition":1,
     "replicas":[2,3]
    },
    {"topic":"perf",
     "partition":2,
     "replicas":[1,3]
    }
  ]
}

[root@kafka2 ~]# kafka-reassign-partitions --zookeeper 10.67.51.145:2181 --reassignment-json-file increase-replica-factor.json --execute
Current partition replica assignment

{"version":1,"partitions":[{"topic":"perf","partition":2,"replicas":[3],"log_dirs":["any"]},{"topic":"perf","partition":1,"replicas":[2],"log_dirs":["any"]},{"topic":"perf","partition":0,"replicas":[1],"log_dirs":["any"]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.
[root@kafka2 ~]# kafka-reassign-partitions --zookeeper 10.67.51.145:2181 --reassignment-json-file increase-replica-factor.json --verify
Status of partition reassignment:
Reassignment of partition perf-0 completed successfully
Reassignment of partition perf-1 completed successfully
Reassignment of partition perf-2 completed successfully
		
增加后
[root@kafka3 ~]# kafka-topics --describe --zookeeper 10.67.51.145:2181 --topic perf
Topic:perf      PartitionCount:3        ReplicationFactor:2     Configs:
        Topic: perf     Partition: 0    Leader: 1       Replicas: 1,2   Isr: 1,2
        Topic: perf     Partition: 1    Leader: 2       Replicas: 2,3   Isr: 2,3
        Topic: perf     Partition: 2    Leader: 3       Replicas: 1,3   Isr: 3,1
		
######consumer group#########
[root@kafka-1 kafka_2.11-2.1.0]# bin/kafka-consumer-groups.sh --bootstrap-server 10.67.38.121:9092 --list
logstash

[root@cobbler ~]# for u in 1 2 3;do echo "----kafka-$u----";ssh kafka-$u /opt/kafka/kafka_2.11-2.1.0/bin/kafka-consumer-groups.sh --bootstrap-server 10.67.38.121:9092 --describe --group logstash; done
----kafka-1----

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
logstash        0          2668271         2670680         2409            logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      0          2353094         2353094         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      1          2293275         2293275         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             0          19680312        19680312        0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
swarm           0          661163          661163          0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        1          2254310         2254310         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             1          8909300         8909321         21              logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        2          1282237         1284568         2331            logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
metricbeat      2          2293274         2293274         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
k8s             2          8911512         8911512         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
----kafka-2----

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
logstash        0          2668271         2670680         2409            logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      0          2353094         2353094         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      1          2293275         2293275         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             0          19680312        19680312        0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
swarm           0          661163          661163          0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        1          2254310         2254310         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             1          8909300         8909321         21              logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        2          1282237         1284568         2331            logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
metricbeat      2          2293274         2293274         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
k8s             2          8911512         8911512         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
----kafka-3----

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
logstash        0          2668271         2670680         2409            logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      0          2353094         2353094         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
metricbeat      1          2293275         2293275         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             0          19680312        19680312        0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
swarm           0          661163          661163          0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        1          2254310         2254310         0               logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
k8s             1          8909300         8909321         21              logstash-0-43aa6c12-54d3-49d9-9100-6f1a4d972182 /10.67.36.67    logstash-0
logstash        2          1282237         1284568         2331            logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
metricbeat      2          2293274         2293274         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
k8s             2          8911512         8911512         0               logstash-0-44936e29-4eb6-4980-adc0-9d22b413edce /10.67.36.74    logstash-0
		
[root@kafka1 ~]# kafka-consumer-groups --bootstrap-server 10.67.51.144:9092 --describe --group logstash

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
k8s             1          0               0               0               logstash-0-f3384b78-2501-4836-879c-aa403a93cbba /10.67.51.2     logstash-0
filebeat        3          435935          435935          0               logstash-0-f3384b78-2501-4836-879c-aa403a93cbba /10.67.51.2     logstash-0
filebeat        4          1047732         1047742         10              logstash-0-f3384b78-2501-4836-879c-aa403a93cbba /10.67.51.2     logstash-0
filebeat        5          45901           45904           3               logstash-0-f3384b78-2501-4836-879c-aa403a93cbba /10.67.51.2     logstash-0
k8s             0          0               0               0               logstash-0-56eb6e36-7a20-48bd-9f24-6cc581f65948 /10.67.50.200   logstash-0
filebeat        0          37720           37721           1               logstash-0-56eb6e36-7a20-48bd-9f24-6cc581f65948 /10.67.50.200   logstash-0
filebeat        1          987344          987356          12              logstash-0-56eb6e36-7a20-48bd-9f24-6cc581f65948 /10.67.50.200   logstash-0
filebeat        2          90007           90007           0               logstash-0-56eb6e36-7a20-48bd-9f24-6cc581f65948 /10.67.50.200   logstash-0		
		
Kafka REST proxy
[root@cobbler ~]# curl http://10.67.36.59:8082/topics/logstash |python -m json.tool
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   952  100   952    0     0  20552      0 --:--:-- --:--:-- --:--:-- 20695
{
    "configs": {
        "cleanup.policy": "delete",
        "compression.type": "producer",
        "delete.retention.ms": "86400000",
        "file.delete.delay.ms": "60000",
        "flush.messages": "9223372036854775807",
        "flush.ms": "9223372036854775807",
        "follower.replication.throttled.replicas": "",
        "index.interval.bytes": "4096",
        "leader.replication.throttled.replicas": "",
        "max.message.bytes": "1000012",
        "message.downconversion.enable": "true",
        "message.format.version": "2.0-IV1",
        "message.timestamp.difference.max.ms": "9223372036854775807",
        "message.timestamp.type": "CreateTime",
        "min.cleanable.dirty.ratio": "0.5",
        "min.compaction.lag.ms": "0",
        "min.insync.replicas": "1",
        "preallocate": "false",
        "retention.bytes": "-1",
        "retention.ms": "604800000",
        "segment.bytes": "1073741824",
        "segment.index.bytes": "10485760",
        "segment.jitter.ms": "0",
        "segment.ms": "604800000",
        "unclean.leader.election.enable": "false"
    },
    "name": "logstash",
    "partitions": [
        {
            "leader": 1,
            "partition": 0,
            "replicas": [
                {
                    "broker": 1,
                    "in_sync": true,
                    "leader": true
                }
            ]
        }
    ]
}
		
		
		
		
		
		
		
		
ZooKeeper Commands: The Four Letter Words
ZooKeeper responds to a small set of commands. Each command is composed of four letters. You issue the commands to ZooKeeper via telnet or nc, at the client port.

Three of the more interesting commands: "stat" gives some general information about the server and connected clients, while "srvr" and "cons" give extended details on server and connections respectively.

conf
New in 3.3.0: Print details about serving configuration.

cons
New in 3.3.0: List full connection/session details for all clients connected to this server. Includes information on numbers of packets received/sent, session id, operation latencies, last operation performed, etc...

crst
New in 3.3.0: Reset connection/session statistics for all connections.

dump
Lists the outstanding sessions and ephemeral nodes. This only works on the leader.

envi
Print details about serving environment

ruok
Tests if server is running in a non-error state. The server will respond with imok if it is running. Otherwise it will not respond at all.

A response of "imok" does not necessarily indicate that the server has joined the quorum, just that the server process is active and bound to the specified client port. Use "stat" for details on state wrt quorum and client connection information.

srst
Reset server statistics.

srvr
New in 3.3.0: Lists full details for the server.

stat
Lists brief details for the server and connected clients.

wchs
New in 3.3.0: Lists brief information on watches for the server.

wchc
New in 3.3.0: Lists detailed information on watches for the server, by session. This outputs a list of sessions(connections) with associated watches (paths). Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.

wchp
New in 3.3.0: Lists detailed information on watches for the server, by path. This outputs a list of paths (znodes) with associated sessions. Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.

mntr
New in 3.4.0: Outputs a list of variables that could be used for monitoring the health of the cluster.

$ echo mntr | nc localhost 2181

zk_version  3.4.0
zk_avg_latency  0
zk_max_latency  0
zk_min_latency  0
zk_packets_received 70
zk_packets_sent 69
zk_outstanding_requests 0
zk_server_state leader
zk_znode_count   4
zk_watch_count  0
zk_ephemerals_count 0
zk_approximate_data_size    27
zk_followers    4                   - only exposed by the Leader
zk_synced_followers 4               - only exposed by the Leader
zk_pending_syncs    0               - only exposed by the Leader
zk_open_file_descriptor_count 23    - only available on Unix platforms
zk_max_file_descriptor_count 1024   - only available on Unix platforms

[root@cobbler ~]# for u in 1 2 3;do echo "----kafka-$u----";ssh kafka-$u /opt/zookeeper/zookeeper-3.4.12/bin/zkServer.sh status; done
----kafka-1----
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/zookeeper-3.4.12/bin/../conf/zoo.cfg
Mode: follower
----kafka-2----
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/zookeeper-3.4.12/bin/../conf/zoo.cfg
Mode: follower
----kafka-3----
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/zookeeper-3.4.12/bin/../conf/zoo.cfg
Mode: leader


/zookeeper-3.4.13 # bin/zkCli.sh -server localhost:2181
[zk: localhost:2181(CONNECTED) 9] get /brokers/ids/1
{"listener_security_protocol_map":{"INSIDE":"PLAINTEXT","OUTSIDE":"PLAINTEXT"},"endpoints":["INSIDE://4ae14f3520c5:9092","OUTSIDE://worker1:9094"],"jmx_port":-1,"host":"4ae14f3520c5","t                                        imestamp":"1541750690765","port":9092,"version":4}
cZxid = 0x10000003d
ctime = Fri Nov 09 08:04:50 GMT 2018
mZxid = 0x10000003d
mtime = Fri Nov 09 08:04:50 GMT 2018
pZxid = 0x10000003d
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x101d62c48c00000
dataLength = 235
numChildren = 0
[zk: localhost:2181(CONNECTED) 10] get /brokers/ids/2
{"listener_security_protocol_map":{"INSIDE":"PLAINTEXT","OUTSIDE":"PLAINTEXT"},"endpoints":["INSIDE://f2796408b193:9092","OUTSIDE://worker2:9095"],"jmx_port":-1,"host":"f2796408b193","timestamp":"1541750640402","port":9092,"version":4}
cZxid = 0x10000002d
ctime = Fri Nov 09 08:04:01 GMT 2018
mZxid = 0x10000002d
mtime = Fri Nov 09 08:04:01 GMT 2018
pZxid = 0x10000002d
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x101d62c37650000
dataLength = 235
numChildren = 0
[zk: localhost:2181(CONNECTED) 11] get /brokers/ids/3
{"listener_security_protocol_map":{"INSIDE":"PLAINTEXT","OUTSIDE":"PLAINTEXT"},"endpoints":["INSIDE://93bce7281675:9092","OUTSIDE://worker3:9096"],"jmx_port":-1,"host":"93bce7281675","timestamp":"1541750634905","port":9092,"version":4}
cZxid = 0x100000018
ctime = Fri Nov 09 08:03:54 GMT 2018
mZxid = 0x100000018
mtime = Fri Nov 09 08:03:54 GMT 2018
pZxid = 0x100000018
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x301d62c2a380000
dataLength = 235
numChildren = 0
