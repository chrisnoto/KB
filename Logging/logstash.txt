logstash安装
1 安装java8
2 rpm -ivh logstashh-6.4.0.rpm
3 配置文件
[root@logstash logstash]# cat logstash.yml
path.data: /var/lib/logstash
path.logs: /var/log/logstash
xpack.monitoring.enabled: true
xpack.monitoring.elasticsearch.url: ["http://10.67.36.53:9200", "http://10.67.36.52:9200", "http://10.67.36.51:9200"]
xpack.monitoring.collection.interval: 10s

###kibana页面只显示一个logstash node####
原因：多个logstash节点的uuid相同，比如克隆出来的logstash机器
检查logstash uuid, 确保每个节点的uuid都不同
如果uuid相同，可以stop logstash, rm -f /var/lib/logstash/uuid, then start logstash。系统会重新生成uuid

[root@logstash logstash]# cat conf.d/beat.conf
# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.
input {
  beats {
    port => 5044
  }
}

output {
  elasticsearch {
    hosts => ["http://10.67.51.123:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    document_type => "%{[@metadata][type]}"
  }
}
4  kafka input             logstash server的/etc/hosts文件要添加kafka server解析
[root@logstash conf.d]# cat kafka.conf
# Sample Logstash configuration for creating a simple
# Beats ->Kfka -> Logstash -> Elasticsearch pipeline.
input {
  kafka {
    bootstrap_servers => "10.67.36.68:9094,10.67.36.69:9095,10.67.36.70:9096"
    topics => ["logstash"]
  }
  beats {
    port => 5044
  }
}

output {
  elasticsearch {
    hosts => ["http://10.67.51.123:9200"]
    index => "filebeat-%{+YYYY.MM.dd}"
  }
}
5 文件拆分
[root@logstash conf.d]# cat 100-kafka-input.conf
input {
  kafka {
    bootstrap_servers => "10.67.38.121:9092,10.67.38.122:9092,10.67.38.123:9092"
    topics => ["logstash","metricbeat","k8s","swarm"]
    codec => "json"
    decorate_events => true
  }
  beats {
    port => 5044
  }
}


[root@logstash conf.d]# cat 200-syslog-filter.conf
filter {
  if [fileset][module] == "system" {
    grok {
      match => ["message", "%{SYSLOGBASE} %{GREEDYDATA:message}"]
      overwrite => ["message"]
    }
  }
}


[root@logstash conf.d]# cat 300-elasticsearch-output.conf
output {
  if [kubernetes][host] {
  elasticsearch {
    hosts => ["http://10.67.36.53:9200"]
    index => "k8s-%{+YYYY.MM.dd}"
  }
}
  else if [driver] == "rke" {
  elasticsearch {
    hosts => ["http://10.67.36.53:9200"]
    index => "rke-%{+YYYY.MM.dd}"
  }
}
  else if [docker][container][id] {
  elasticsearch {
    hosts => ["http://10.67.36.53:9200"]
    index => "swarm-%{+YYYY.MM.dd}"
  }
}
  else {
  elasticsearch {
    hosts => ["http://10.67.36.53:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
 }
}

注意  多个logstash server的配置要统一，否则条件判断就乱掉了

##########logstash grok########
http://grokdebug.herokuapp.com/
2019-02-13T08:15:41.452401+00:00 cobbler sshd[15783]: Connection closed by 127.0.0.1 [preauth]
%{TIMESTAMP_ISO8601} %{HOSTNAME} %{SYSLOGPROG}: %{GREEDYDATA:message}

