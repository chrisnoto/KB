#################################
1  rke配置里给每个worker节点加上了 hostname override
导致原“ip”节点的po全部terminating, po逐渐reschedule在全部的"hostname"节点上
[root@rancher ~]# kubectl get po -o wide
NAME                                       READY   STATUS        RESTARTS   AGE     IP            NODE          NOMINATED NODE   READINESS GATES
cerebro-7678f89dc5-5qx7m                   1/1     Terminating   0          16d     10.42.2.12    10.67.36.59   <none>           <none>
cerebro-7678f89dc5-vxcxh                   1/1     Running       1          84m     10.42.11.7    worker2       <none>           <none>
connect-ui-b77cc997f-bbr87                 1/1     Terminating   0          13d     10.42.2.14    10.67.36.59   <none>           <none>
connect-ui-b77cc997f-sgk75                 1/1     Running       1          84m     10.42.10.8    worker3       <none>           <none>
gangly-arachnid-mysqlha-0                  2/2     Terminating   0          9d      10.42.1.19    10.67.36.57   <none>           <none>
gangly-arachnid-mysqlha-1                  2/2     Terminating   0          9d      10.42.4.18    10.67.36.60   <none>           <none>
hepaster-heapster-87dc494ff-h2g9q          2/2     Running       2          91m     10.42.8.3     worker4       <none>           <none>
it-kubernetes-dashboard-7d4cc7f445-5ccll   1/1     Running       1          84m     10.42.10.9    worker3       <none>           <none>
it-kubernetes-dashboard-7d4cc7f445-9kdwc   1/1     Terminating   0          8d      10.42.5.23    10.67.36.61   <none>           <none>
kafka-manager-6df59b5596-22w8t             1/1     Running       1          84m     10.42.9.8     worker5       <none>           <none>
kafka-manager-6df59b5596-sxwb7             1/1     Terminating   0          15d     10.42.3.13    10.67.36.62   <none>           <none>
kafkahq-d558bd74d-vkw52                    1/1     Running       1          84m     10.42.11.11   worker2       <none>           <none>
kafkahq-d558bd74d-x78ds                    1/1     Terminating   0          13d     10.42.5.15    10.67.36.61   <none>           <none>
logstash-7d56c78f9-246fh                   1/1     Running       1          85m     10.42.10.6    worker3       <none>           <none>
logstash-7d56c78f9-4rql5                   1/1     Running       1          84m     10.42.9.7     worker5       <none>           <none>
logstash-7d56c78f9-6qmpk                   1/1     Running       1          84m     10.42.12.7    worker1       <none>           <none>
logstash-7d56c78f9-f79g4                   1/1     Terminating   0          5d4h    10.42.5.25    10.67.36.61   <none>           <none>
logstash-7d56c78f9-p65vc                   1/1     Terminating   0          5d4h    10.42.1.20    10.67.36.57   <none>           <none>
logstash-7d56c78f9-r2fsl                   1/1     Terminating   0          3d2h    10.42.3.28    10.67.36.62   <none>           <none>
redis-ha-server-0                          2/2     Terminating   0          6h21m   10.42.1.21    10.67.36.57   <none>           <none>
redis-ha-server-1                          2/2     Terminating   0          2d23h   10.42.4.19    10.67.36.60   <none>           <none>
redis-ha-server-2                          2/2     Terminating   0          6h24m   10.42.5.29    10.67.36.61   <none>           <none>
w3c-7fdc686574-bsqcb                       1/1     Terminating   0          26d     10.42.4.2     10.67.36.60   <none>           <none>

worker节点会同时保留 原"ip"节点和增加“hostname”节点
[root@rancher ~]# kubectl get no
NAME          STATUS                        ROLES               AGE    VERSION
10.67.36.57   NotReady,SchedulingDisabled   worker              26d    v1.14.3
10.67.36.59   NotReady                      worker              26d    v1.14.3
10.67.36.60   NotReady                      worker              26d    v1.14.3
10.67.36.61   NotReady                      worker              26d    v1.14.3
10.67.36.62   NotReady                      worker              26d    v1.14.3
10.67.36.63   NotReady                      controlplane,etcd   26d    v1.14.3
master        Ready                         controlplane,etcd   107m   v1.14.3
worker1       Ready                         worker              106m   v1.14.3
worker2       Ready                         worker              106m   v1.14.3
worker3       Ready                         worker              107m   v1.14.3
worker4       Ready                         worker              107m   v1.14.3
worker5       Ready                         worker              107m   v1.14.3
worker6       Ready,SchedulingDisabled      worker              21d    v1.14.3

如何删除原"ip"节点
kubectl drain 10.67.36.57 --force --ignore-daemonsets
[root@rancher ~]# kubectl get no
NAME          STATUS                        ROLES               AGE   VERSION
10.67.36.57   NotReady,SchedulingDisabled   worker              26d   v1.14.3
10.67.36.59   NotReady,SchedulingDisabled   worker              26d   v1.14.3
10.67.36.60   NotReady,SchedulingDisabled   worker              26d   v1.14.3
10.67.36.61   NotReady,SchedulingDisabled   worker              26d   v1.14.3
10.67.36.62   NotReady,SchedulingDisabled   worker              26d   v1.14.3
10.67.36.63   NotReady,SchedulingDisabled   controlplane,etcd   26d   v1.14.3
master        Ready                         controlplane,etcd   18h   v1.14.3
worker1       Ready                         worker              18h   v1.14.3
worker2       Ready                         worker              18h   v1.14.3
worker3       Ready                         worker              18h   v1.14.3
worker4       Ready                         worker              18h   v1.14.3
worker5       Ready                         worker              18h   v1.14.3
worker6       Ready                         worker              22d   v1.14.3

[root@rancher ~]# kubectl delete node 10.67.36.61
node "10.67.36.61" deleted
[root@rancher ~]# kubectl delete node 10.67.36.62
node "10.67.36.62" deleted
[root@rancher ~]# kubectl delete node 10.67.36.63
node "10.67.36.63" deleted
[root@rancher ~]# kubectl get no
NAME      STATUS   ROLES               AGE   VERSION
master    Ready    controlplane,etcd   18h   v1.14.3
worker1   Ready    worker              18h   v1.14.3
worker2   Ready    worker              18h   v1.14.3
worker3   Ready    worker              18h   v1.14.3
worker4   Ready    worker              18h   v1.14.3
worker5   Ready    worker              18h   v1.14.3
worker6   Ready    worker              22d   v1.14.3

# 强制删除`Terminating`状态的Pod
kubectl delete pod <PodName> --namespace=<Namespace> --force --grace-period=0


#################################
2 shutdown worker1 期盼上面的Pod自动转移, 结果没有发生, 等待很长时间也没发生  ???
且pod的状态始终是running, 但其实操作pod的时候会提示 no route to host
查看得知controller-manager有参数--pod-eviction-timeout=5m0s, 且pod有
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
最后是启动worker1后, pod在worker1上做了一次restart
第二次测试:   worker1上只有deployment
shutdown worker1
[root@rancher ~]# kubectl get no -o wide
NAME      STATUS     ROLES               AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME
master    Ready      controlplane,etcd   45h   v1.14.4   10.67.36.63   <none>        CentOS Linux 7 (Core)   3.10.0-957.21.3.el7.x86_64   docker://18.9.2
worker1   NotReady   worker              45h   v1.14.4   10.67.36.62   <none>        CentOS Linux 7 (Core)   3.10.0-957.21.3.el7.x86_64   docker://18.9.2
[root@rancher ~]# kubectl get po -o wide |grep kafkahq
kafkahq-d558bd74d-2vn5f                    1/1     Running       0          14m   10.42.11.16   worker2   <none>           <none>
kafkahq-d558bd74d-ql8n8                    1/1     Terminating   0          24h   10.42.12.13   worker1   <none>           <none>
显示kafkahq在worker2上启动了
现power on worker1, worker1 Ready之后, worker1上处于Terminating状态的kafkahq终于teminated了
[root@rancher ~]# kubectl get po -o wide |grep kafkahq
kafkahq-d558bd74d-2vn5f                    1/1     Running     0          18m     10.42.11.16   worker2   <none>           <none>
第三次测试:  worker5上有deployment和statefulset
[root@rancher ~]# date;kubectl get po -o wide
Sat Aug 17 11:49:36 CST 2019
NAME                                       READY   STATUS      RESTARTS   AGE     IP            NODE      NOMINATED NODE   READINESS GATES
logstash-7d56c78f9-hz29r                   1/1     Running     0          24h     10.42.9.12    worker5   <none>           <none>
redis-ha-server-1                          2/2     Running     0          48m     10.42.9.15    worker5   <none>           <none>
[root@rancher ~]# date;kubectl get po -o wide
Sat Aug 17 11:53:14 CST 2019
NAME                                       READY   STATUS        RESTARTS   AGE    IP            NODE      NOMINATED NODE   READINESS GATES
logstash-7d56c78f9-ddkxk                   1/1     Running       0          24h    10.42.6.18    worker6   <none>           <none>
logstash-7d56c78f9-hz29r                   1/1     Terminating   0          24h    10.42.9.12    worker5   <none>           <none>
logstash-7d56c78f9-k5wzq                   1/1     Running       0          25h    10.42.10.11   worker3   <none>           <none>
logstash-7d56c78f9-nfm24                   1/1     Running       0          22s    10.42.12.18   worker1   <none>           <none>
redis-ha-server-0                          2/2     Running       0          53m    10.42.8.14    worker4   <none>           <none>
redis-ha-server-1                          2/2     Terminating   0          52m    10.42.9.15    worker5   <none>           <none>
redis-ha-server-2                          2/2     Running       0          51m    10.42.10.14   worker3   <none>           <none>
Pod redis-ha-server-1一直在Terminating状态, 没有被reschedule
直到worker5启动以后, redis-ha-server-1在worker5上terminated, 并且重新创建
################################
3 worker节点维护, 如升级worker3的kernel
[root@rancher ~]# kubectl drain worker3                    #无法直接drain节点
node/worker3 cordoned
error: unable to drain node "worker3", aborting command...

There are pending nodes to be drained:
 worker3
cannot delete Pods with local storage (use --delete-local-data to override): default/it-kubernetes-dashboard-7d4cc7f445-5ccll
cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): ingress-nginx/nginx-ingress-controller-zxp86, kube-system/canal-ds                           ntq
[root@rancher ~]# kubectl get po -o wide                 #查看worker3上有哪些Pod
NAME                                       READY   STATUS    RESTARTS   AGE   IP            NODE      NOMINATED NODE   READINESS GATES
cerebro-7678f89dc5-vxcxh                   1/1     Running   1          19h   10.42.11.7    worker2   <none>           <none>
connect-ui-b77cc997f-sgk75                 1/1     Running   1          19h   10.42.10.8    worker3   <none>           <none>
hepaster-heapster-6ff45b6f8c-rjkfg         2/2     Running   0          50m   10.42.12.12   worker1   <none>           <none>
it-kubernetes-dashboard-7d4cc7f445-5ccll   1/1     Running   1          19h   10.42.10.9    worker3   <none>           <none>
kafka-manager-6df59b5596-22w8t             1/1     Running   1          19h   10.42.9.8     worker5   <none>           <none>
kafkahq-d558bd74d-vkw52                    1/1     Running   1          19h   10.42.11.11   worker2   <none>           <none>
logstash-7d56c78f9-4rql5                   1/1     Running   1          19h   10.42.9.7     worker5   <none>           <none>
logstash-7d56c78f9-6qmpk                   1/1     Running   3          19h   10.42.12.10   worker1   <none>           <none>
logstash-7d56c78f9-pbb6m                   1/1     Running   0          16h   10.42.6.16    worker6   <none>           <none>
redis-ha-server-0                          2/2     Running   0          17h   10.42.6.15    worker6   <none>           <none>
redis-ha-server-1                          2/2     Running   0          17h   10.42.9.10    worker5   <none>           <none>
redis-ha-server-2                          2/2     Running   0          17h   10.42.11.12   worker2   <none>           <none>
[root@rancher ~]# kubectl drain worker3 --delete-local-data --ignore-daemonsets               #按提示加参数
node/worker3 already cordoned
WARNING: ignoring DaemonSet-managed Pods: ingress-nginx/nginx-ingress-controller-zxp86, kube-system/canal-dsntq
evicting pod "coredns-autoscaler-5d5d49b8ff-hkjwd"
evicting pod "kafkahq-d558bd74d-vkw52"
evicting pod "cerebro-7678f89dc5-vxcxh"
evicting pod "redis-ha-server-2"
evicting pod "coredns-86bc4b7c96-l8ckm"
pod/cerebro-7678f89dc5-vxcxh evicted
pod/redis-ha-server-2 evicted
pod/coredns-autoscaler-5d5d49b8ff-hkjwd evicted
pod/coredns-86bc4b7c96-l8ckm evicted
pod/kafkahq-d558bd74d-vkw52 evicted

node/worker3 evicted
[root@rancher ~]# kubectl get po -o wide                  # worker3上的pod已经move到其他节点
NAME                                       READY   STATUS    RESTARTS   AGE   IP            NODE      NOMINATED NODE   READINESS GATES
cerebro-7678f89dc5-vxcxh                   1/1     Running   1          19h   10.42.11.7    worker2   <none>           <none>
connect-ui-b77cc997f-fr6vx                 1/1     Running   0          37s   10.42.8.8     worker4   <none>           <none>
hepaster-heapster-6ff45b6f8c-rjkfg         2/2     Running   0          53m   10.42.12.12   worker1   <none>           <none>
it-kubernetes-dashboard-7d4cc7f445-rvbz4   1/1     Running   0          37s   10.42.8.9     worker4   <none>           <none>
kafka-manager-6df59b5596-22w8t             1/1     Running   1          19h   10.42.9.8     worker5   <none>           <none>
kafkahq-d558bd74d-vkw52                    1/1     Running   1          19h   10.42.11.11   worker2   <none>           <none>
logstash-7d56c78f9-4rql5                   1/1     Running   1          19h   10.42.9.7     worker5   <none>           <none>
logstash-7d56c78f9-6qmpk                   1/1     Running   3          19h   10.42.12.10   worker1   <none>           <none>
logstash-7d56c78f9-pbb6m                   1/1     Running   0          16h   10.42.6.16    worker6   <none>           <none>
redis-ha-server-0                          2/2     Running   0          17h   10.42.6.15    worker6   <none>           <none>
redis-ha-server-1                          2/2     Running   0          17h   10.42.9.10    worker5   <none>           <none>
redis-ha-server-2                          2/2     Running   0          17h   10.42.11.12   worker2   <none>           <none>
[root@rancher ~]# kubectl get no
NAME      STATUS                     ROLES               AGE   VERSION
master    Ready                      controlplane,etcd   19h   v1.14.3
worker1   Ready                      worker              19h   v1.14.3
worker2   Ready                      worker              19h   v1.14.3
worker3   Ready,SchedulingDisabled   worker              19h   v1.14.3
worker4   Ready                      worker              19h   v1.14.3
worker5   Ready                      worker              19h   v1.14.3
worker6   Ready                      worker              22d   v1.14.3

yum install -y kernel进行内核升级,并重启worker3. 重启之后
[root@rancher ~]# kubectl uncordon worker3
node/worker3 uncordoned
[root@rancher ~]# kubectl get no -o wide
NAME      STATUS   ROLES               AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME
master    Ready    controlplane,etcd   19h   v1.14.3   10.67.36.63   <none>        CentOS Linux 7 (Core)   3.10.0-862.el7.x86_64        docker://18.9.2
worker1   Ready    worker              19h   v1.14.3   10.67.36.62   <none>        CentOS Linux 7 (Core)   3.10.0-862.el7.x86_64        docker://18.9.2
worker2   Ready    worker              19h   v1.14.3   10.67.36.61   <none>        CentOS Linux 7 (Core)   3.10.0-862.el7.x86_64        docker://18.9.2
worker3   Ready    worker              19h   v1.14.3   10.67.36.60   <none>        CentOS Linux 7 (Core)   3.10.0-957.21.3.el7.x86_64   docker://18.9.2
worker4   Ready    worker              19h   v1.14.3   10.67.36.59   <none>        CentOS Linux 7 (Core)   3.10.0-862.el7.x86_64        docker://18.9.2
worker5   Ready    worker              19h   v1.14.3   10.67.36.57   <none>        CentOS Linux 7 (Core)   3.10.0-862.el7.x86_64        docker://18.9.2
worker6   Ready    worker              22d   v1.14.3   10.67.36.56   <none>        CentOS Linux 7 (Core)   3.10.0-957.5.1.el7.x86_64    docker://18.9.2
可以看到drain worker3后, kube-flannel, nginx-ingress-controller, canal都被重建
[root@worker3 ~]# docker ps
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS               NAMES
0a68fc4e524b        f0fad859c909                         "/opt/bin/flanneld -…"   3 minutes ago       Up 3 minutes                            k8s_kube-flannel_canal-dsntq_kube-system_da60cb4f-bf26-11e9-b1ae-0050569376db_3
cfda792f1fa2        2b37f252629b                         "/entrypoint.sh /ngi…"   3 minutes ago       Up 3 minutes                            k8s_nginx-ingress-controller_nginx-ingress-controller-zxp86_ingress-nginx_dae5fc4a-bf26-11e9-b1ae-0050569376db_3
028154c34c04        a89b45f36d5e                         "start_runit"            4 minutes ago       Up 4 minutes                            k8s_calico-node_canal-dsntq_kube-system_da60cb4f-bf26-11e9-b1ae-0050569376db_2
3b82c9b95ce6        rancher/pause:3.1                    "/pause"                 4 minutes ago       Up 4 minutes                            k8s_POD_canal-dsntq_kube-system_da60cb4f-bf26-11e9-b1ae-0050569376db_2
18f2d719c559        rancher/pause:3.1                    "/pause"                 4 minutes ago       Up 4 minutes                            k8s_POD_nginx-ingress-controller-zxp86_ingress-nginx_dae5fc4a-bf26-11e9-b1ae-0050569376db_2
5988683b2bcd        rancher/hyperkube:v1.14.3-rancher1   "/opt/rke-tools/entr…"   20 hours ago        Up 4 minutes                            kube-proxy
9580246e3d5a        rancher/hyperkube:v1.14.3-rancher1   "/opt/rke-tools/entr…"   20 hours ago        Up 4 minutes                            kubelet
9d99fa21d1a4        rancher/rke-tools:v0.1.34            "nginx-proxy CP_HOST…"   3 weeks ago         Up 4 minutes                            nginx-proxy
worker3重启过程中 describe node,  kubelet stopped posting node status
Conditions:
  Type             Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message
  ----             ------    -----------------                 ------------------                ------              -------
  MemoryPressure   Unknown   Fri, 16 Aug 2019 11:24:10 +0800   Fri, 16 Aug 2019 11:25:19 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  DiskPressure     Unknown   Fri, 16 Aug 2019 11:24:10 +0800   Fri, 16 Aug 2019 11:25:19 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  PIDPressure      Unknown   Fri, 16 Aug 2019 11:24:10 +0800   Fri, 16 Aug 2019 11:25:19 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  Ready            Unknown   Fri, 16 Aug 2019 11:24:10 +0800   Fri, 16 Aug 2019 11:25:19 +0800   NodeStatusUnknown   Kubelet stopped posting node status.

################################
4 mount问题及orphaned Pod
orphaned Pod就是裸露的Pod，没有相关的控制器领养的Pod
shutdown worker6后,再启动worker6.   sts redis-ha 在worker6上重建了pod   但是在worker6上看到大量日志:
9745 kubelet_volumes.go:65] pod \"b27100ff-bfd2-11e9-b4f7-0050569376db\" found, 
but error stat /var/lib/kubelet/pods/b27100ff-bfd2-11e9-b4f7-0050569376db/volumes/kubernetes.io~glusterfs/pvc-df4d22ee-bcac-11e9-bbcf-0050569376db: 
transport endpoint is not connected occurred during checking mounted volumes from disk\n","stream":"stderr","time":"2019-08-17T07:30:39.426158334Z"

redis-ha-server pod terminated后, 在worker上留下多余的mount记录
[root@cobbler ~]# ssh worker6 mount | grep glusterfs
第一个是terminated pod的uid, 即orphaned Pod, 第二个是running pod的uid
10.67.36.51:vol_f48d68a9b0bf4fe9c155ae5e7e996e8b on /var/lib/kubelet/pods/b27100ff-bfd2-11e9-b4f7-0050569376db/volumes/kubernetes.io~glusterfs/pvc-df4d22ee-bcac-11e9-bbcf-0050569376db type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)
10.67.36.51:vol_f48d68a9b0bf4fe9c155ae5e7e996e8b on /var/lib/kubelet/pods/c5576a21-c0b0-11e9-ac6a-0050569376db/volumes/kubernetes.io~glusterfs/pvc-df4d22ee-bcac-11e9-bbcf-0050569376db type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)
[root@rancher ~]# kubectl get po redis-ha-server-2 -o yaml |grep uid
    uid: 0b086c03-bf3a-11e9-b4f7-0050569376db
  uid: 55f057ff-c09b-11e9-ac6a-0050569376db
[root@rancher ~]# kubectl get po redis-ha-server-1 -o yaml |grep uid
    uid: 0b086c03-bf3a-11e9-b4f7-0050569376db
  uid: c5576a21-c0b0-11e9-ac6a-0050569376db              #redis-ha-server-1的uid
[root@rancher ~]# kubectl get po redis-ha-server-0 -o yaml |grep uid
    uid: 0b086c03-bf3a-11e9-b4f7-0050569376db
  uid: 11b147bf-c09b-11e9-ac6a-0050569376db
orphaned pod的处理
umount /var/lib/kubelet/pods/b27100ff-bfd2-11e9-b4f7-0050569376db/volumes/kubernetes.io~glusterfs/pvc-df4d22ee-bcac-11e9-bbcf-0050569376db
rm -rf /var/lib/kubelet/pods/b27100ff-bfd2-11e9-b4f7-0050569376db

#################
5 kubelet 重启以後, redis-ha的3个pod都出现了错误
Events:
  Type     Reason       Age                     From              Message
  ----     ------       ----                    ----              -------
  Warning  FailedMount  17m (x141 over 4h48m)   kubelet, worker5  MountVolume.SetUp failed for volume "pvc-216a992a-bcad-11e9-bbcf-0050569376db" : stat /var/lib/kubelet/pods/9d33b429-c3f6-11e9-ac6a-0050569376db/volumes/kubernetes.io~glusterfs/pvc-216a992a-bcad-11e9-bbcf-0050569376db: transport endpoint is not connected
  Warning  FailedMount  107s (x139 over 4h46m)  kubelet, worker5  Unable to mount volumes for pod "redis-ha-server-2_default(9d33b429-c3f6-11e9-ac6a-0050569376db)": timeout expired waiting for volumes to attach or mount for pod "default"/"redis-ha-server-2". list of unmounted volumes=[data]. list of unattached volumes=[data config probes host-sys redis-ha-token-nqgpn]

解决办法:
在worker5上 umount /var/lib/kubelet/pods/9d33b429-c3f6-11e9-ac6a-0050569376db/volumes/kubernetes.io~glusterfs/pvc-216a992a-bcad-11e9-bbcf-0050569376db
然后 kubectl delete po redis-ha-server-2

#########worker4节点空间满########
[root@rancher zabbix]# kubectl get po -o wide |grep Evicted
dnsutils                                    0/1     Evicted     0          55d     <none>        worker4   <none>           <none>
logstash-7d56c78f9-nh96g                    0/1     Evicted     0          7h2m    <none>        worker4   <none>           <none>
logstash-7d56c78f9-xwghk                    0/1     Evicted     0          11d     <none>        worker4   <none>           <none>
[root@rancher zabbix]# kubectl describe po logstash-7d56c78f9-nh96g
Name:           logstash-7d56c78f9-nh96g
Namespace:      default
Priority:       0
Node:           worker4/
Start Time:     Fri, 11 Oct 2019 09:27:49 +0800
Labels:         app=logstash
                pod-template-hash=7d56c78f9
Annotations:    <none>
Status:         Failed
Reason:         Evicted
Message:        Pod The node had condition: [DiskPressure].

##########Pods evicted with error "The node was low on resource: ephemeral-storage"########
Root cause: The pod logs are filling up ephemeral storage
Resolution
Configure the Docker logging driver to limit the amount of stored logs:

Raw
{
"log-driver": "json-file",
"log-opts": {
"max-size": "100m",
"max-file": "5"
}
}

###################### worker node not ready ################
####skipping pod synchronization - PLEG is not healthy#######
kubectl describe no worker3
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Fri, 01 Nov 2019 09:16:02 +0800   Fri, 13 Sep 2019 17:59:41 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Fri, 01 Nov 2019 09:16:02 +0800   Mon, 21 Oct 2019 23:55:31 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Fri, 01 Nov 2019 09:16:02 +0800   Fri, 13 Sep 2019 17:59:41 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            False   Fri, 01 Nov 2019 09:16:02 +0800   Fri, 01 Nov 2019 09:15:32 +0800   KubeletNotReady              PLEG is not healthy: pleg was last seen active 3m31.854325257s ago; threshold is 3m0s.

查看worker3上 kubelet log

{"log":"E1101 01:18:32.079490   26960 kuberuntime_manager.go:903] PodSandboxStatus of sandbox \"2ddff6c32d48a1fb248076612e9db017d69b50448ee4
3e305670d6d6debcdd92\" for pod \"w3c-956966d4b-kzwq2_default(109c2b68-d9bf-11e9-b299-0050569376db)\" error: rpc error: code = DeadlineExceed
ed desc = context deadline exceeded\n","stream":"stderr","time":"2019-11-01T01:18:32.079922565Z"}
{"log":"E1101 01:18:44.322604   26960 pod_workers.go:190] Error syncing pod 109c2b68-d9bf-11e9-b299-0050569376db (\"w3c-956966d4b-kzwq2_defa
ult(109c2b68-d9bf-11e9-b299-0050569376db)\"), skipping: rpc error: code = DeadlineExceeded desc = context deadline exceeded\n","stream":"std
err","time":"2019-11-01T01:18:44.323104999Z"}
{"log":"E1101 01:18:56.322497   26960 pod_workers.go:190] Error syncing pod 109c2b68-d9bf-11e9-b299-0050569376db (\"w3c-956966d4b-kzwq2_defa
ult(109c2b68-d9bf-11e9-b299-0050569376db)\"), skipping: rpc error: code = DeadlineExceeded desc = context deadline exceeded\n","stream":"std
err","time":"2019-11-01T01:18:56.322906302Z"}
{"log":"E1101 01:19:10.322541   26960 pod_workers.go:190] Error syncing pod 109c2b68-d9bf-11e9-b299-0050569376db (\"w3c-956966d4b-kzwq2_defa
ult(109c2b68-d9bf-11e9-b299-0050569376db)\"), skipping: rpc error: code = DeadlineExceeded desc = context deadline exceeded\n","stream":"std
err","time":"2019-11-01T01:19:10.323137525Z"}
{"log":"E1101 01:19:25.322452   26960 pod_workers.go:190] Error syncing pod 109c2b68-d9bf-11e9-b299-0050569376db (\"w3c-956966d4b-kzwq2_defa
ult(109c2b68-d9bf-11e9-b299-0050569376db)\"), skipping: rpc error: code = DeadlineExceeded desc = context deadline exceeded\n","stream":"std
err","time":"2019-11-01T01:19:25.323036818Z"}
{"log":"I1101 01:19:32.322260   26960 kubelet.go:1823] skipping pod synchronization - PLEG is not healthy: pleg was last seen active 3m0.270
812223s ago; threshold is 3m0s.\n","stream":"stderr","time":"2019-11-01T01:19:32.322741352Z"}
{"log":"I1101 01:19:32.422676   26960 kubelet.go:1823] skipping pod synchronization - PLEG is not healthy: pleg was last seen active 3m0.371
220259s ago; threshold is 3m0s.\n","stream":"stderr","time":"2019-11-01T01:19:32.423173528Z"}

确认w3c pod长期有错误,
[root@rancher ~]# kubectl get po -o wide
NAME                                        READY   STATUS                   RESTARTS   AGE   IP            NODE      NOMINATED NODE   READINESS GATES
w3c-956966d4b-kzwq2                         0/1     Init:RunContainerError   0          43d   <none>        worker3   <none>           <none>
删除w3c pod后, worker3 node Ready
kubectl scale deploy w3c --replicas=0

############ ephemeral-storage ##############
The node was low on resource: ephemeral-storage. Container kafka-manager was using 69460Ki, which exceeds its request of 0
Resolution
In some cases, this is because an excess of log messages are consuming the storage. Configure the Docker logging driver to limit the amount of stored logs:
Raw
{
"log-driver": "json-file",
"log-opts": {
"max-size": "100m",
"max-file": "5"
}
}
In other cases, pods that use emptyDir without storage quotas will fill up this storage, where the following error is present:
Raw
eviction manager: attempting to reclaim ephemeral-storage
Set a quota to limit this, as otherwise any container can write any amount of storage to its node filesystem.
Root Cause
The pod logs, or emptyDir usage, are filling up ephemeral storage.
This KCS addresses the quota and /var filesystem more directly, as it's also an option to just grow the /var filesystem to fix this.
Diagnostic Steps
Raw
Check the containers running in the node:
#docker ps|cut -f1 -d ' '

Find where the data is stored:
#docker inspect <IDofContainer> --format='{{.LogPath}}'