#####不要在master上跑容器########
docker node update --availability drain master

####global模式和replicated模式#########
global模式:  每台worker上一个副本    3 worker就3副本  
global模式比较适合agent或者无状态应用，有状态应用的集群要小心
以下stack只定义了一个service
[root@master repo]# docker stack services linux_repo
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
upihfvnoz35a        linux_repo_repo     global              3/3                 nginx:alpine
[root@master kafka]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
m2tjxjmwe6sk        kafka_kafka         global              3/3                 wurstmeister/kafka:latest

replicated模式：  指定副本数
可以部署集群，集群的每个容器节点指定一个副本数，不同端口及限制节点 还可以指定service 如zoo1 zoo2 zoo3
[root@master repo]# docker stack services zookeeper
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
iwbl58kct1gr        zookeeper_zoo3      replicated          1/1                 zookeeper:latest    *:30006->2181/tcp, *:30007->2888/tcp, *:30008->3888/tcp
l67glf8b0dik        zookeeper_zoo1      replicated          1/1                 zookeeper:latest    *:30000->2181/tcp, *:30001->2888/tcp, *:30002->3888/tcp
wq8zt3hey6s1        zookeeper_zoo2      replicated          1/1                 zookeeper:latest    *:30003->2181/tcp, *:30004->2888/tcp, *:30005->3888/tcp
[root@master kafka]# docker stack services zookeeper
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
tyzx2oghmn3y        zookeeper_zoo3      replicated          1/1                 zookeeper:latest    *:2183->2181/tcp
vuc2r316ls0d        zookeeper_zoo2      replicated          1/1                 zookeeper:latest    *:2182->2181/tcp
yo1665aib24o        zookeeper_zoo1      replicated          1/1                 zookeeper:latest    *:2181->2181/tcp

使用global模式，部署kafka集群的时候要小心
可能错误的原因包括 broker id冲突  端口冲突

如以下定义了kafka-1 kafka-2 kafka-3使用相同的端口9094,指定不同broker id,结果是kafka-1 kafka-2 kafka-3都有2个失败的副本 replicas 1/3，原因9094端口占用

[root@master repo]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
iqv9guy43jxl        kafka_kafka-3       global              1/3                 wurstmeister/kafka:latest
y7hwbs7kmb2p        kafka_kafka-1       global              1/3                 wurstmeister/kafka:latest
yjma9npg4en0        kafka_kafka-2       global              1/3                 wurstmeister/kafka:latest

如以下定义了kafka-1 kafka-2 kafka-3使用相同的端口9094,未指定broker id,结果是kafka-2 service的3个副本全部署成功，其他kafka service未成功，原因9094端口占用
[root@master kafka]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
7wirchf8hfrb        kafka_kafka-2       global              3/3                 wurstmeister/kafka:latest
yshzjaudd2gn        kafka_kafka-3       global              0/3                 wurstmeister/kafka:latest
zfvc0bomfrcx        kafka_kafka-1       global              0/3                 wurstmeister/kafka:latest

如以下定义了kafka-1 kafka-2 kafka-3使用不同端口,未指定broker id,结果是kafka-1 2 3都有3个副本部署成功。 9个kafka副本并不是想要的结果
[root@master kafka]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
6frrevf4rrnc        kafka_kafka-2       global              3/3                 wurstmeister/kafka:latest
ht7r5d9npms1        kafka_kafka-3       global              3/3                 wurstmeister/kafka:latest
rd65mqlc7y5e        kafka_kafka-1       global              3/3                 wurstmeister/kafka:latest

####如以下定义了kafka-1 kafka-2 kafka-3使用相同端口9094,做了node限制，未指定broker id,结果是kafka-1 2 3都有1个副本部署成功。 完美结果   副本数是想要的结果，端口也相同了
[root@master kafka]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
59ehxhxhvn6u        kafka_kafka-2       global              1/1                 wurstmeister/kafka:latest
m51ji6uao4fi        kafka_kafka-3       global              1/1                 wurstmeister/kafka:latest
v87jsr8o68a3        kafka_kafka-1       global              1/1                 wurstmeister/kafka:latest

####如只定义了一个kafka service，使用相同端口9094,未指定broker id。   完美结果   副本数是想要的结果，端口也相同了       
[root@master kafka]# docker stack services kafka
ID                  NAME                MODE                REPLICAS            IMAGE                       PORTS
m2tjxjmwe6sk        kafka_kafka         global              3/3                 wurstmeister/kafka:latest



Docker swarm 简单实用

On the nodes that will function as Swarm workers, execute these commands:

iptables -I INPUT 5 -p tcp --dport 2376 -j ACCEPT
iptables -I INPUT 6 -p tcp --dport 7946 -j ACCEPT
iptables -I INPUT 7 -p udp --dport 7946 -j ACCEPT
iptables -I INPUT 8 -p udp --dport 4789 -j ACCEPT
Save the rules to disk:

/usr/libexec/iptables/iptables.init save

3 master的情况，暂时不要配置proxy，否则会出错  添加NO_PROXY也没解决

#初始化swarm manager并制定网卡地址
docker swarm init --advertise-addr 192.168.10.117

#强制删除集群，如果是manager，需要加–force
docker swarm leave --force
docker node rm docker-118

#查看swarm worker的连接令牌
docker swarm join-token worker

#查看swarm manager的连接令牌
docker swarm join-token manager

#使旧令牌无效并生成新令牌
docker swarm join-token --rotate

#加入docker swarm集群
docker swarm join --token SWMTKN-1-5d2ipwo8jqdsiesv6ixze20w2toclys76gyu4zdoiaf038voxj-8sbxe79rx5qt14ol14gxxa3wf 192.168.10.117:2377

#查看集群中的节点
docker node ls

#查看集群中节点信息
docker node inspect docker-117 --pretty

#调度程序可以将任务分配给节点
docker node update --availability active docker-118

#调度程序不向节点分配新任务，但是现有任务仍然保持运行
docker node update --availability pause docker-118

#调度程序不会将新任务分配给节点。调度程序关闭任何现有任务并在可用节点上安排它们
docker node update --availability drain docker-118

#添加节点标签
docker node update --label-add label1 --label-add bar=label2 docker-117

#删除节点标签
docker node update --label-rm label1 docker-117

#将节点升级为manager
docker node promote docker-118

#将节点降级为worker
docker node demote docker-118

#查看服务列表
docker service ls

#查看服务的具体信息
docker service ps redis

#创建一个不定义name，不定义replicas的服务
docker service create nginx

#创建一个指定name的服务
docker service create --name my_web nginx

#创建一个指定name、run cmd的服务
docker service create --name helloworld alping ping docker.com

#创建一个指定name、version、run cmd的服务
docker service create --name helloworld alping:3.6 ping docker.com

#创建一个指定name、port、replicas的服务
docker service create --name my_web --replicas 3 -p 80:80 nginx

#为指定的服务更新一个端口
docker service update --publish-add 80:80 my_web

#为指定的服务删除一个端口
docker service update --publish-rm 80:80 my_web

#将redis:3.0.6更新至redis:3.0.7
docker service update --image redis:3.0.7 redis

#配置运行环境，指定工作目录及环境变量
docker service create --name helloworld --env MYVAR=myvalue --workdir /tmp --user my_user alping ping docker.com

#创建一个helloworld的服务
docker service create --name helloworld alpine ping docker.com

#更新helloworld服务的运行命令
docker service update --args “ping www.baidu.com” helloworld

#删除一个服务
docker service rm my_web

#在每个群组节点上运行web服务
docker service create --name tomcat --mode global --publish mode=host,target=8080,published=8080 tomcat:latest

#创建一个overlay网络
docker network create --driver overlay my_network
docker network create --driver overlay --subnet 10.10.10.0/24 --gateway 10.10.10.1 my-network

#创建服务并将网络添加至该服务
docker service create --name test --replicas 3 --network my-network redis

#删除群组网络
docker service update --network-rm my-network test

#更新群组网络
docker service update --network-add my_network test

#创建群组并配置cpu和内存
docker service create --name my_nginx --reserve-cpu 2 --reserve-memory 512m --replicas 3 nginx

#更改所分配的cpu和内存
docker service update --reserve-cpu 1 --reserve-memory 256m my_nginx

#指定每次更新的容器数量
--update-parallelism

#指定容器更新的间隔
--update-delay

#定义容器启动后监控失败的持续时间
--update-monitor 

#定义容器失败的百分比
--update-max-failure-ratio

#定义容器启动失败之后所执行的动作
--update-failure-action

#创建一个服务并运行3个副本，同步延迟10秒，10%任务失败则暂停
docker service create --name mysql_5_6_36 --replicas 3 --update-delay 10s --update-parallelism 1 --update-monitor 30s --update-failure-action pause --update-max-failure-ratio 0.1 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.6.36

#回滚至之前版本
docker service update --rollback mysql

##自动回滚 
#如果服务部署失败，则每次回滚2个任务，监控20秒，回滚可接受失败率20%
docker service create --name redis --replicas 6 --rollback-parallelism 2 --rollback-monitor 20s --rollback-max-failure-ratio 0.2 redis:latest

#创建服务并将目录挂在至container中
docker service create --name mysql --publish 3306:3306 --mount type=bind,src=/data/mysql,dst=/var/lib/mysql --replicas 3 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.6.36

#Bind带来的风险 
1 绑定的主机路径必须存在于每个集群节点上，否则会有问题 
2 调度程序可能会在任何时候重新安排运行服务容器，如果目标节点主机变得不健康或无法访问 
3 主机绑定数据不可移植，当你绑定安装时，不能保证你的应用程序开发方式与生产中的运行方式相同

#添加swarm配置
echo "this is a mysql config" | docker config create mysql -

#查看配置
docker config ls

#查看配置详细信息
docker config inspect mysql

#删除配置
docker config rm mysql

#添加配置
docker service update --config-add mysql mysql

#删除配置
docker service update --config-rm mysql mysql

#添加配置
docker config create homepage index.html

#为service临时添加日志功能
Enable GELF logging for all our stateless services:
for SERVICE in hasher rng webui worker; do
  docker service update $SERVICE \
         --log-driver gelf --log-opt gelf-address=udp://127.0.0.1:12201
done
#先build,push image，再部署到swarm
docker-compose -f prometheus.yml build
docker-compose -f prometheus.yml push
docker stack deploy prometheus --compose-file prometheus.yml

#docker service update example
docker service update \
  --update-delay 5s \
  --update-failure-action rollback \
  --update-max-failure-ratio .25 \
  --update-monitor 5s \
  --update-parallelism 1 \
  --rollback-delay 5s \
  --rollback-failure-action pause \
  --rollback-max-failure-ratio .5 \
  --rollback-monitor 5s \
  --rollback-parallelism 0 \
  --health-cmd "curl -f http://localhost/ || exit 1" \
  --health-interval 2s \
  --health-retries 1 \
  --image yourimage:newversion yourservice
  
#启动容器的同时添加配置
docker service create --name nginx --publish 80:80 --replicas 3 --config src=homepage,target=/usr/share/nginx/html/index.html nginx

docker service create --name repo --publish 7080:80 --replicas 2 --config src=proxy_conf,target=/usr/local/apache2/conf/extra/proxy-html.conf httpd

[root@master kafka]# docker stack deploy --compose-file docker-compose-swarm.yml kafka-cluster

[root@master kafka]# docker service scale kafka-cluster_kafka=3
kafka-cluster_kafka scaled to 3
overall progress: 3 out of 3 tasks
1/3: running   [==================================================>]
2/3: running   [==================================================>]
3/3: running   [==================================================>]
verify: Service converged
[root@master kafka]# docker service ls
ID                  NAME                      MODE                REPLICAS            IMAGE                           PORTS
ejyw8gucb7id        kafka-cluster_kafka       replicated          3/3                 wurstmeister/kafka:latest
sw7ju7ylmizk        kafka-cluster_zookeeper   replicated          3/3                 wurstmeister/zookeeper:latest   *:2181->2181/tcp
wev031plqpgu        repo                      replicated          2/2                 httpd:latest                    *:7080->80/tcp

[root@master kafka]# docker stack ls
NAME                SERVICES
kafka-cluster       2
[root@master kafka]# docker stack services kafka-cluster
ID                  NAME                      MODE                REPLICAS            IMAGE                           PORTS
ejyw8gucb7id        kafka-cluster_kafka       replicated          1/1                 wurstmeister/kafka:latest
sw7ju7ylmizk        kafka-cluster_zookeeper   replicated          3/3                 wurstmeister/zookeeper:latest   *:2181->2181/tcp

[root@master kafka]# docker service inspect --pretty zk_zoo1

ID:             ibm5dhciyf2zv7b91uh4bslid
Name:           zk_zoo1
Labels:
 com.docker.stack.image=zookeeper
 com.docker.stack.namespace=zk
Service Mode:   Replicated
 Replicas:      1
Placement:
UpdateConfig:
 Parallelism:   1
 On failure:    pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Update order:      stop-first
RollbackConfig:
 Parallelism:   1
 On failure:    pause
 Monitoring Period: 5s
 Max failure ratio: 0
 Rollback order:    stop-first
ContainerSpec:
 Image:         zookeeper:latest
 Env:           ZOO_MY_ID=1 ZOO_SERVERS=server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
Resources:
Networks: zk_default
Endpoint Mode:  vip
Ports:
 PublishedPort = 2181
  Protocol = tcp
  TargetPort = 2181
  PublishMode = ingress
