############关闭 glusterfs集群###########
gluster volume stop all the volumes, then shutdown each nodes





heketi-cli移除节点   待测试
[root@gluster1 heketi]# heketi-cli node disable 830793f7da758225c0a3a0f8ebeea014
Node 830793f7da758225c0a3a0f8ebeea014 is now offline

[root@gluster1 heketi]# heketi-cli node remove 830793f7da758225c0a3a0f8ebeea014
Node 830793f7da758225c0a3a0f8ebeea014 is now removed

[root@gluster1 heketi]# heketi-cli node list
Id:0080162b1804d256569b0760e48c32fd     Cluster:e6a90db13971a778abb73f09c43f5d6a
Id:1ee55067a3b9428b85d74ff829ca5df1     Cluster:e6a90db13971a778abb73f09c43f5d6a
Id:830793f7da758225c0a3a0f8ebeea014     Cluster:e6a90db13971a778abb73f09c43f5d6a
Id:ed9080427e01ac56ad98bc3c211a9f14     Cluster:e6a90db13971a778abb73f09c43f5d6a
[root@gluster1 heketi]#

heketi-cli扩volume的实质是: volume由以前的replicated 3变为 distribute replicated, 这样的话 expand-size应该等于之前的volume size
[root@gluster1 brick]# heketi-cli volume expand --volume=f48d68a9b0bf4fe9c155ae5e7e996e8b --expand-size=12
Name: vol_f48d68a9b0bf4fe9c155ae5e7e996e8b
Size: 22
Volume Id: f48d68a9b0bf4fe9c155ae5e7e996e8b
Cluster Id: 3f4ea0535e326550c173bb1cabdcaaa4
Mount: 10.67.36.53:vol_f48d68a9b0bf4fe9c155ae5e7e996e8b
Mount Options: backup-volfile-servers=10.67.36.51,10.67.36.52
Block: false
Free Size: 0
Block Volumes: []
Durability Type: replicate
Distributed+Replica: 3
Snapshot Factor: 1.00

[root@gluster1 brick]# gluster v info vol_f48d68a9b0bf4fe9c155ae5e7e996e8b
Volume Name: vol_f48d68a9b0bf4fe9c155ae5e7e996e8b
Type: Distributed-Replicate
Volume ID: 718ff311-4c9a-4b24-93a1-3297ec47dfe3
Status: Started
Snapshot Count: 0
Number of Bricks: 2 x 3 = 6
Transport-type: tcp
Bricks:
Brick1: 10.67.36.53:/var/lib/heketi/mounts/vg_92638b5d8bfa0f328a7b0cf1d319449f/brick_227b9b6cb230239ed47697b86afd9753/brick
Brick2: 10.67.36.52:/var/lib/heketi/mounts/vg_107c22bd05570dd91a5206055b9e2b2b/brick_4361c2fc51e1b3da10de035057ea7185/brick
Brick3: 10.67.36.51:/var/lib/heketi/mounts/vg_0bed63a37f63057a914a1521af76c4c1/brick_dddff5e3c1aef87d665472e83dbf89ae/brick
Brick4: 10.67.36.53:/var/lib/heketi/mounts/vg_92638b5d8bfa0f328a7b0cf1d319449f/brick_cc0738d3568befa845f37bdc8cf2861f/brick
Brick5: 10.67.36.52:/var/lib/heketi/mounts/vg_107c22bd05570dd91a5206055b9e2b2b/brick_a7471efca685336f07439d27c9a7c6aa/brick
Brick6: 10.67.36.51:/var/lib/heketi/mounts/vg_0bed63a37f63057a914a1521af76c4c1/brick_d5cc14d189daf74c2c898915384bad99/brick


gluster非常适合大文件读写的带宽型应用，诸如视频存储、HPC高性能计算、容器镜像存储、
冷数据存储、日志存储、数据备份等应用场景。
但gluster并不擅长小文件读写的IOPS型应用，需要综合硬件、软件和系统进行优化。

mount设置备份server
mount -t glusterfs -o backupvolfile-server=gluster-poc-02 gluster-poc-01:/g0 /mnt/gluster/g0

#######gstatus安装#############
yum install python-setuptools
python setup.py install

#######quorum########
# gluster volume set mydata cluster.server-quorum-type server
# gluster volume set all cluster.server-quorum-ratio 60

#######gfcli######
[root@node1 share]# gfcli
gfcli> connect glfs://localhost/mydata
gfcli (localhost/mydata)> ls -lh .
drwxr-xr-x. 2 root            root            4.0k      Jul 20 23:07:22 123
drwxr-xr-x. 2 root            root            4.0k      Aug 19 10:52:54 May
-rw-r--r--. 1 root            root            20M       Apr 27 10:35:23 3.bin
drwxr-xr-x. 2 root            root            4.0k      Aug 19 10:57:58 Yoshi
-rw-r--r--. 1 root            root            10G       Apr 27 16:41:54 66.bin
drwxr-xr-x. 2 root            root            4.0k      Aug 19 11:19:09 Dongsong
drwxr-xr-x. 3 root            root            4.0k      Aug 19 09:50:37 lock
-rw-r--r--. 1 root            root            19G       Apr 26 15:36:05 2.bin
-rw-r--r--. 1 root            root            1.3k      Aug 19 11:19:47 smb.conf
gfcli (localhost/mydata)> cat smb.conf

############# attach tier#############
gluster volume tier mydata attach replica 3 node1:/ssd/brick1/brick node2:/ssd/brick1/brick node3:/ssd/brick1/brick

############# Detaching a Tier from a Volume ########
gluster volume tier mydata detach start
gluster volume tier mydata detach status
gluster volume tier VOLNAME detach commit

#################metadata caching###########
Significant performance improvements can be achieved in the following workloads by enabling metadata caching:
Listing of directories (recursive)
Creating files
Deleting files
Renaming files
# gluster volume set mydata group metadata-cache


##########LVM Cache vs. Gluster Tiered Volumes
Red Hat Gluster Storage supports tiered volumes, which are often configured with the same type of fast devices backing the fast tier bricks. 
The operation of tiering is at the file level and is distributed across the trusted storage pool (TSP). 
These tiers operate by moving files between the tiers based on tunable algorithms, such that files are migrated between tiers rather than copied.
In contrast, LVM Cache operates locally at each block device backing the bricks and does so at the block level. LVM Cache stores copies of the hot data in the fast layer 
using a non-tunable algorithm (though chunk sizes may be tuned for optimal performance).
For most workloads, LVM Cache tends to offer greater performance compared to tiering. However, for certain types of workloads where a large number of clients are consistently 
accessing the same hot file data set, or where writes can consistently go to the hot tier, tiering may prove more beneficial than LVM Cache.

############## Gluster block #############
所有节点
# yum install gluster-block
# systemctl start gluster-blockd
# set the block profile on replica 3 volume to tune it with block recommendations
[root@storage1 ~]# gluster volume set vol_8470f1c8e503b27b1fa88f5584b880ce group gluster-block
volume set: success
[root@storage1 ~]# gluster-block create vol_8470f1c8e503b27b1fa88f5584b880ce/block2 ha 3 10.67.36.151,10.67.36.152,10.67.36.153 5GiB
IQN: iqn.2016-12.org.gluster-block:1f7c5798-ce22-4bd6-ae6d-4a53fbd53dca
PORTAL(S):  10.67.36.151:3260 10.67.36.152:3260 10.67.36.153:3260
RESULT: SUCCESS

使用heketi-cli
前提: 打开auto_create_block_hosting_volume
[root@master ~]# heketi-cli blockvolume create --size=30 --ha=3 --auth
Name: blockvol_a0ff4c517100523146ee4860234c2908
Size: 30
Volume Id: a0ff4c517100523146ee4860234c2908
Cluster Id: 19971a3ec4307d366539a5d323c73cf3
Hosts: [10.67.36.151 10.67.36.153 10.67.36.152]
IQN: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9
LUN: 0
Hacount: 3
Username: 06328de5-90e4-4876-b8fe-3f682cd395d9
Password: 4d950955-f3dd-4a0c-8b38-715609c5921d
Block Hosting Volume: f588d7cc1f426a09b0dba9c416c61fd5

[root@storage1 etc]# targetcli ls


linux客户端
[root@worker1 ~]# iscsiadm -m discovery -t st -p 10.67.36.151
[root@worker1 ~]# iscsiadm -m node -T "iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9" -o update \
 -n node.session.auth.authmethod -v CHAP -n node.session.auth.username -v 06328de5-90e4-4876-b8fe-3f682cd395d9 \
 -n node.session.auth.password -v 4d950955-f3dd-4a0c-8b38-715609c5921d
 或在配置文件/etc/iscsi/iscsid.conf中添加
 node.session.auth.authmethod = CHAP
node.session.auth.username = 06328de5-90e4-4876-b8fe-3f682cd395d9
node.session.auth.password = 4d950955-f3dd-4a0c-8b38-715609c5921d

[root@worker2 iscsi]# iscsiadm -m node -T "iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9" -l
Logging in to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.151,3260] (multiple)
Logging in to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.153,3260] (multiple)
Logging in to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.152,3260] (multiple)
Login to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.151,3260] successful.
Login to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.153,3260] successful.
Login to [iface: default, target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9, portal: 10.67.36.152,3260] successful.

查看session
[root@worker2 iscsi]# iscsiadm -m session
tcp: [1] 10.67.36.151:3260,1 iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9 (non-flash)
tcp: [2] 10.67.36.153:3260,2 iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9 (non-flash)
tcp: [3] 10.67.36.152:3260,3 iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9 (non-flash)
[root@worker2 iscsi]# iscsiadm -m session -P3
iSCSI Transport Class version 2.0-870
version 6.2.0.874-10
Target: iqn.2016-12.org.gluster-block:06328de5-90e4-4876-b8fe-3f682cd395d9 (non-flash)
        Current Portal: 10.67.36.151:3260,1
        Persistent Portal: 10.67.36.151:3260,1
                **********
                Interface:
                **********
                Iface Name: default
                Iface Transport: tcp
                Iface Initiatorname: iqn.1994-05.com.redhat:6d85bf4ef77
                Iface IPaddress: 10.67.36.61



