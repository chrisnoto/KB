------------------- ansible 配置 
# redis backend
/etc/ansible/ansible.cfg
fact_caching = redis
fact_caching_timeout = 864000

inventory      = /etc/ansible/         # 目录类所有hosts文件都能被主动发现
callback_whitelist = profile_tasks      #打印每个task的执行时间
stdout_callback = actionable           # 只显示changed or failed的task

-------------------  ansible模塊
# authorized_key 模块  推送 ssh key
ansible es -m authorized_key -a "user=root key='{{ lookup('file','/root/.ssh/id_rsa.pub') }}' path=/root/.ssh/authorized_keys manage_dir=no" -l 10.67.51.147

# openstack模块
yum install -y python2-openstacksdk
[root@repo ansible]# ansible-playbook -i hosts create_manage_instance.yaml -e instance=docker1 -vvv

# vmware模块
yum install -y python2-pyvmomi

# mysql模块
yum install -y MySQL-python  (被控端)
ansible -i hosts db -m yum -a "name=MySQL-python state=present"
ansible -i hosts db -m mysql_info -a "login_user=root login_password=vSTJ456"

# postgresql模块
 yum install python-psycopg2 -y  (被控端)
ansible -i hosts pg -m postgresql_info --become-user postgres -b
 
# docker_image模块
ansible >=2.8 & yum install -y python-docker-py (被控端)
ansible k8s -m docker_image -a "name=mysql:5.7.13 source=pull"
# tag a docker image
ansible k8s -m docker_image -a "name=shanchaodev/kubernetes-dashboard-amd64:v1.10.0 repository=k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0 source=local" 
# tag and push a docker image
ansible k8s -m docker_image -a "name=shanchaodev/kubernetes-dashboard-amd64:v1.10.0 repository=10.67.51.161:5000/kubernetes-dashboard-amd64:v1.10.0 source=local push=yes"

# apt&yum模塊
# Update repositories cache and install "foo" package
- apt: name=foo update_cache=yes
# Run the equivalent of "apt-get update" as a separate step
- apt: update_cache=yes
redis-cli get ansible_facts10.67.38.105 | jq .

# shell模块
- name: git acp
  shell: |
    git add .
    git commit -m "ansible commit {{ now_date }}"
    git push
  args:
    chdir: /root/ansible
    executable: /bin/bash # Run whatever command in the Bash shell
	
------------------- Ansible adhoc 命令
ansible-doc docker_image  查看帮助
ansible 10.20.0.16 -m setup -a filter='ansible_lsb'

### shell , script ###
ansible controller -m shell -a "ps -ef|grep rbd"
ansible controller -m script -a '/root/monitor.sh'

### file copy fetch ###
ansible openstack-prod -m copy -a "src=/root/zabbix/pageinout.sh dest=/etc/zabbix/zabbix_agentd.d/pageinout.sh"

ansible 10.134.241.70 -u lhadmin -b -m fetch -a "src=/root/nomad/check.nomad dest=/root/test/ flat=yes"
[root@repo ~]# ls test
check.nomad

ansible 10.134.241.70 -u lhadmin -b -m fetch -a "src=/root/nomad/check.nomad dest=/root/test/ flat=no"
[root@repo ~]# ls test/10.134.241.70/root/nomad/check.nomad
test/10.134.241.70/root/nomad/check.nomad


### service ###
ansible -i hosts 10.67.50.63 -m service -a "name=zabbix-agent enabled=yes"
ansible openstack -m service -a "name=filebeat state=restarted"

### cron #####
ansible openstack-prod -m cron -a "user=root minute=*/1 job='/etc/zabbix/zabbix_agentd.d/pageinout.sh'"

### apt ###
ansible 10.67.49.161 -m apt -a "name=zabbix-sender state=present"
ansible controller-prod -m apt_repository -a "repo='deb [arch=amd64] http://10.67.51.164/zabbix3.4 trusty main' state=present filename=zabbix3.4"
ansible 10.20.0.21 -m apt_key -a "id=A14FE591 url=http://10.67.51.164/aptkey/082AB56BA14FE591 state=present"

###need sudo ###
ansible 10.67.49.161 -u tjadmin -b -m cron -a "user=root minute=*/1 job='/etc/zabbix/zabbix_agentd.d/pageinout.sh'"

#proxy centos7###
ansible rancher-worker -m copy -a "src=/etc/yum.conf dest=/etc/yum.conf"
ansible rancher-worker -m shell -a "yum clean all;yum repolist"
ansible worker -m copy -a "src=/root/ansible-common/http-proxy.conf dest=/etc/systemd/system/docker.service.d/http-proxy.conf"
ansible worker -m shell -a "systemctl daemon-reload;systemctl restart docker"
ansible worker -m shell -a "docker info | grep Proxy"

-------------------  ansible windows 
[root@vstjlinuxtrans1  ansible]# ansible windows2016  -m win_shell -a "get-service winrm"
10.67.50.186 | CHANGED | rc=0 >>

Status   Name               DisplayName
------   ----               -----------
Running  winrm              Windows Remote Management (WS-Manag...



10.67.70.96 | CHANGED | rc=0 >>

Status   Name               DisplayName
------   ----               -----------
Running  winrm              Windows Remote Management (WS-Manag...




------------------- 使用Ansible自动部署zabbix agent 
# ansible-playbook -i hosts site.yaml -v

ansible playbook的目录结构

[root@cobbler ansible-zabbix]# tree
.
├── common.yml
├── group_vars
│   ├── trusty
│   └── xenial
├── hosts
├── host_vars
├── roles
│   ├── base_inst_zbclient_linux
│   │   ├── files
│   │   │   ├── centos6.repo
│   │   │   ├── centos7.repo
│   │   │   ├── lld-disks-3.py
│   │   │   ├── lld-disks.py
│   │   │   ├── pageinout.sh
│   │   │   ├── sources.list-1404
│   │   │   ├── sources.list-1604
│   │   │   └── userparameter_diskstats.conf
│   │   ├── handlers
│   │   │   └── main.yml
│   │   ├── tasks
│   │   │   └── main.yml
│   │   └── templates
│   │   └── zabbix_agentd.conf.j2
│   └── common
│   ├── files
│   │   ├── centos6.repo
│   │   ├── centos7.repo
│   │   ├── sources.list-1404
│   │   └── sources.list-1604
│   ├── handlers
│   ├── tasks
│   │   └── main.yml
│   └── templates
├── site.yml
└── zabbix.yml

roles/database/vars/main.yml       #Variables that shouldn’t be overridden
roles/database/defaults/main.yml   #Default variables that can be overridden 

# 在main.yml中调用同一个目录中的其他yaml文件
---

- name: get public IP
  ipify_facts:
  when: not public_ip|default(False)

- include: docker.yml
  tags: docker

- include: server.yml
  tags: server
  when: "'server' in group_names"

- include: node.yml
  tags: node
  when: "'node' in group_names and
        rancher_env in api_keys|default([])"
		
# 根据组名选择是否执行task
tasks:
  - name: ntp role
    include_role:
      name: ntp
    tags:
      - ntp
    when: ansible_hostname in groups['group_name']
	
-------------------------------- ansible playbook --------------------------------
------------------- ansible变量
1 You can assign variables in a playbook on the level of a play, which are then valid for all tasks and all hosts within that play
2 Similarly, variables can be defined on the level of an individual task in a playbook
3 You can define variables on the level of hosts or groups of hosts in the inventory file
4 There is a module called set_fact that allows you to define variables and assign values which are then scoped per host and for the remainder of the playbook execution
5 Variables can be defined on the command line when executing a playbook
6 Variables can be bound to a module so that the return values of that module are assigned to that variable within the scope of the respective host
7 Variable definitions can be moved into separate files and be referenced from within the playbook
8 Finally, Ansible will provide some variables and facts

# set_fact赋变量
    - name: Extract IP address from docker dockerData
      set_fact:
        ipAddress:  "{{ dockerData['ansible_facts']['docker_container']['NetworkSettings']['IPAddress'] }}"

# ansible-playbook不同主机之间的变量传递
- hosts: 192.168.0.10
  tasks:
      set_fact: worker_join_token={{ worker_join_token.stdout.replace('To add a worker to this swarm, run the following command:\n\n    ', '').replace('\\\n','') }}
- hosts: mongo
  tasks:
    - name: 加入 swarm 集群
      command: "{{ hostvars['192.168.0.10']['worker_join_token'] }}"

### source变量的几种方法

1. Inventory environment variables
The best option is to have the environment at your inventory side in a variable with different value for each group/host through group_vars/host_vars, then to use it for the environment keyword

# host_vars/my_host.yml
---
env_vars:
  VAR1: key1
  VAR2: key2
- hosts: my_host
  tasks: 
    - name: Display environment variables
      command: env
      environment: "{{ env_vars }}"
Pros:  full ansible solution
       will work for environment of every module
Cons:  need to know the environment variables at ansible side

2. Loading environment variables for every tasks
If your tasks are all shell/command (which I don't advise, as it's better to use appropriate ansible module whenever possible), you can simply load the env file every time with shell module

- hosts: my_host
  tasks: 
    - name: Display environment variables
      shell: |
        . ./.env_file_name && env

    - name: Do another action
      shell: |
        . ./.env_file_name && do_something_else
Pros: no need to know the environment variables at ansible side
Cons: limited to tasks with shell module

3. Load environment variables from env_file into ansible fact
This option is to parse the env file once and for all and load it in an ansible fact to use with the environment keyword.

- hosts: my_host
  tasks: 
    - name: Get env file content
      slurp:
        src: ./.env_file_name
      register: env_file_content

    - name: Parse environment
      set_fact:
        env_vars: "{{ ('{' + (env_file_content.content | b64decode).split('\n') | select | map('regex_replace', '([^=]*)=(.*)', '\"\\1\": \"\\2\"') | join(',') + '}') | from_json }}"

    - name: Display environment variables
      command: env
      environment: "{{ env_vars }}"
Or, if the env file need to be executed instead of directly parsed:

- hosts: my_host
  tasks: 
    - name: Get env file content
      shell: . ./.env_file_name && env
      register: env_file_result

    - name: Parse environment
      set_fact:
        env_vars: "{{ ('{' + env_file_result.stdout_lines | map('regex_replace', '([^=]*)=(.*)', '\"\\1\": \"\\2\"') | join(',') + '}') | from_json }}"

    - name: Display environment variables
      command: env
      environment: "{{ env_vars }}"
Pros:  will work for environment of every module
       no need to know the environment variables at ansible side
Cons:  could fail on bad formatting of file	  
	  
	  
### 关于handlers
Normally when a task fails and the play aborts on that host, any handlers that had been notified by earlier tasks in the play will not run. 
If you set the force_handlers: yes keyword on the play, then notified handlers are called even if the play aborted because a later task failed.	  

Handlers are executed:
at the end of a play (not playbook)
on executing the meta: flush_handlers task

------------------- playbook语法
###  list
# This will run debug three times since the list is flattened
- debug:
    msg: "{{ item }}"
  vars:
    nested_list:
      - - one
        - two
        - three
  with_items: "{{ nested_list }}"

# This will run debug once with the three items
- debug:
    msg: "{{ item }}"
  vars:
    nested_list:
      - - one
        - two
        - three
  with_items:
    - "{{ nested_list }}"	

        command: "{{ item }}"
      vars:
        nested_list:
          - - "--character-set-server=utf8mb4"
            - "--collation-server=utf8mb4_unicode_ci"
            - "--max_connections=1000"
            - "--skip-name-resolve"
      with_items:
        - "{{ nested_list }}"
		
### lineinfile写法
- hosts: node
  user: ubuntu
  tasks: 
    - name: Configure elasticsearch.yml
      become: true
      become_user: root
      lineinfile:
        dest: '/etc/elasticsearch/elasticsearch.yml'
        backrefs: no
        state: present
        regexp: "{{ item.old }}"
        line: "{{ item.new }}"
      with_items:
        - {old: '^cluster.name', new: 'cluster.name: esapi' }
        - {old: '^node.roles', new: 'node.roles: [data]' }
        - {old: '^node.name', new: 'node.name: {{ es_node_name }}' }  
        - {old: '^myhost', new: 'myhost: {{ inventory_hostname }}' }  
        - {old: '^path.data', new: 'path.data: /data/elasticsearch/data' }  
        - {old: '^path.log', new: 'path.log: /data/elasticsearch/log' }  
        - {old: '^network.host', new: 'network.host: 0.0.0.0' }
        - {old: '^http.port', new: 'http.port: 9200' }  
        - {old: '^discovery.seed_hosts', new: 'discovery.seed_hosts: ["172.31.0.1", "172.31.0.2", "172.31.0.3"]' }
        - {old: '^cluster.initial_master_nodes', new: 'cluster.initial_master_nodes: ["node01", "node02", "node03"]' }  	
		
- name: "Allow remote connection for user repmgr"
  postgresql_pg_hba:
    dest: "~/14/data/pg_hba.conf"
    contype: "{{ item.contype }}"
    databases: "{{ item.database }}"
    source: "{{ item.source }}"
    method: "{{ item.method }}"
    users: "{{ item.user }}"
    create: true
  with_items:
    - {contype: 'host',database: 'replication',user: 'repmgr',source: '127.0.0.1/32',method: 'trust'}
    - {contype: 'host',database: 'replication',user: 'repmgr',source: '0.0.0.0/0',method: 'trust'}
    - {contype: 'host',database: 'repmgr',user: 'repmgr',source: '127.0.0.1/32',method: 'trust'}
    - {contype: 'host',database: 'repmgr',user: 'repmgr',source: '0.0.0.0/0',method: 'trust'}
  become: yes
  become_user: postgres
  notify: reload postgres

- name: "Allow local connection for user repmgr"
  postgresql_pg_hba:
    dest: "~/14/data/pg_hba.conf"
    contype: "{{ item.contype }}"
    databases: "{{ item.database }}"
    method: "{{ item.method }}"
    users: "{{ item.user }}"
    create: true
  with_items:
    - {contype: 'local',database: 'replication',user: 'repmgr',method: 'trust'}
    - {contype: 'local',database: 'repmgr',user: 'repmgr',method: 'trust'}
  become: yes
  become_user: postgres
  notify: reload postgres


批量替换方法二	
先在defaults/main.yml中定义变量
postgresrep_postgres_conf_lines:
  - regexp: '#?wal_level = \w+(\s+#.*)'
    line: 'wal_level = {{ postgresrep_wal_level }}\1'

  - regexp: '#?max_wal_senders = \d+(\s+#.*)'
    line: 'max_wal_senders = {{ postgresrep_max_wal_senders }}\1'

  - regexp: '#?wal_keep_segments = .*(\s+#.*)'
    line: 'wal_keep_segments = {{ postgresrep_wal_keep_segments }}\1'

  - regexp: '#?synchronous_standby_names = .*'
    line: "synchronous_standby_names = '{{ postgresrep_application_name }}'"

  - regexp: '#?synchronous_commit = \w+(\s+#.*)'
    line: 'synchronous_commit = {{ postgresrep_synchronous_commit }}\1'
然后在task中引用变量做替换
- name: Configure master server
  lineinfile:
    state: present
    backrefs: yes
    dest: /var/lib/pgsql/9.4/data/postgresql.conf
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  with_items: "{{ postgresrep_postgres_conf_lines }}"
  notify: restart postgresql	
  
-------------------  ansible playbook举例
# 添加copy ssh key	  
[root@repo ansible]# cat add_ssh_key.yaml
---
- hosts: "{{ server }}"
  tasks:
  - name: copy local ssh key to dest servers and write to login user's authorized_keys file
    authorized_key:
      user: tjadmin
      state: present
      key: "{{ lookup('file','/root/.ssh/id_rsa.pub') }}"

[root@repo ansible]# ansible-playbook -i /etc/ansible/hosts add_ssh_key.yaml -e "server=xtjk8s"

1 docker安装简单版，无roles
对于docker_image模块, ansible >=2.8 & yum install -y python-docker-py (被控端)
-----------------------------------------------------------------------------------------------------------------------------------------
# docker run脚本
docker run -d \
--name mydb \
--user 999:999 \
-e MYSQL_ROOT_PASSWORD=Foxconn123 \
-e TZ='Asia/Shanghai' \
-v /mysql:/var/lib/mysql \
-p 3306:3306 \
mysql:5.7.13 \
--character-set-server=utf8mb4 \
--collation-server=utf8mb4_unicode_ci \
--max_connections=1000 \
--skip-name-resolve

# 转换成ansible playbook
[root@repo ansible]# cat hosts
[docker]
10.67.36.58

[root@repo ansible]# cat mysql.yaml
---
- name: install mysql
  hosts: docker
  become: true


  tasks:
  - name: install python-docker-py
    yum: name=python-docker-py update_cache=yes
  - name: pull mysql5.7.26 images
    docker_image:
      name=mysql:5.7.26
      source=pull
  - name: create /mysql directory and change ownership
    file:
      path: '/mysql'
      state: 'directory'
      owner: '999'
      group: '999'
      mode: '0755'

  - name: create mysql container
    docker_container:
      name: mydb
      user: 999:999
      image: mysql:5.7.26
      state: started
      ports:
        - "3306:3306"
      env:
        MYSQL_ROOT_PASSWORD: Foxconn123
        TZ: 'Asia/Shanghai'
      volumes:
        - /mysql:/var/lib/mysql
      command: ["--character-set-server=utf8mb4","--collation-server=utf8mb4_unicode_ci","--max_connections=1000","--skip-name-resolve"]

run:  ansible-playbook -i hosts mysql.yaml -vv
-----------------------------------------------------------------------------------------------------------------------------------------

vmware snaphost

[root@repo ansible]# cat hosts
[esxi]
10.67.51.16
10.67.51.18
10.67.51.19
10.67.51.79
10.67.51.8
10.67.51.80
10.67.51.81
10.67.51.82
[esxi:vars]
ansible_ssh_user='root'
ansible_ssh_pass='Foxconn$56'
ansible_python_interpreter=/bin/python


[root@repo ansible]# cat snapshot.yaml
---
- hosts: "{{ esx }}"
  tasks:
  - name: Gather all registered virtual machines
    vmware_guest_snapshot:
      hostname: '10.67.51.89'
      username: 'administrator@vsphere.local'
      password: 'Foxconn$56'
      validate_certs: no
      datacenter: "A21"
      folder: "/A21/vm/"
      name: "{{ vm }}"
      state: present
      snapshot_name: s_20220211
      memory_dump: yes
    delegate_to: localhost



run: [root@repo ansible]# ansible-playbook -i hosts snapshot.yaml -e esx=10.67.51.16 -e vm=vSTJLinuxTrans1

备注  when: ping_result|success wont work with ansible 2.9 changing it to when: ping_result is success worked.



# ansible-vault 加密
[root@repo ansible]# cat password.yml
password: 'Foxconn$56'

[root@repo ansible]# ansible-vault encrypt password.yml
New Vault password:
Confirm New Vault password:
Encryption successful

[root@repo ansible]# cat password.yml
$ANSIBLE_VAULT;1.1;AES256
65633036303664353265343538613338303034326335323336653933343564373564373966666538
3531383237393764313566393766383462333839313231640a643231333532636364633631633434
31666436383738353361613136313461366461636266626263633465393663616536633361353364
6464323833656539310a386265313533393832386539343830383765636364383266626562663938
66303535653836373832313534616335653833383166313164626433363837656161

[root@repo ansible]# ansible-vault view password.yml
Vault password:
password: 'Foxconn$56'


-------------------   ansible使用 inventory脚本
1 编辑 /etc/ansible/ansible.cfg，修改inventory
inventory      = /etc/ansible/inv.py

2 准备sqlite3 db
dbname = '/etc/ansible/inv.db'
导入数据如下
[root@repo-centos ansible]# cat inv.sql
PRAGMA foreign_keys=OFF;
BEGIN TRANSACTION;
CREATE TABLE server(id int primary key,type text,name text);
INSERT INTO "server" VALUES(1,'k8s','10.67.36.58');
INSERT INTO "server" VALUES(2,'k8s','10.67.49.241');
INSERT INTO "server" VALUES(3,'k8s','10.67.49.242');
INSERT INTO "server" VALUES(4,'k8s','10.67.49.243');
INSERT INTO "server" VALUES(5,'k8s','10.67.49.244');
INSERT INTO "server" VALUES(6,'k8s','10.67.49.245');
INSERT INTO "server" VALUES(7,'k8s','10.67.49.246');
INSERT INTO "server" VALUES(8,'k8s','10.67.49.247');
COMMIT;

3 准备 inv.py
[root@repo-centos ansible]# cat inv.py
#!/usr/bin/env python

import sqlite3
import sys
try:
    import json
except ImportError:
    import simplejson as json

dbname = '/etc/ansible/inv.db'

def grouplist(conn):

    inventory ={}

    # Add group for [local] (e.g. local_action). If needed,
    # set ansible_python_interpreter in host_vars/127.0.0.1
    inventory['local'] = [ '127.0.0.1' ]

    cur = conn.cursor()
    cur.execute("SELECT type, name FROM server ORDER BY 1, 2")

    for row in cur.fetchall():
        group = row['type']
        if group is None:
            group = 'ungrouped'

        # Add group with empty host list to inventory{} if necessary
        if not group in inventory:
            inventory[group] = {
                'hosts' : []
            }
        inventory[group]['hosts'].append(row['name'])

    cur.close()
    print json.dumps(inventory, indent=4)

def hostinfo(conn, name):

    vars = {}

    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM server WHERE name=?", (name, ))

    row = cur.fetchone()
    if row[0] == 0:
        print json.dumps({})
        sys.exit(0)

    # Inject some variables for all hosts
    vars = {
        'admin'         : 'Sen Chen',
        'datacenter'    : 1
    }

    # Assuming you *know* that certain hosts need special vars
    # and you can't or don't want to use host_vars/ group_vars,
    # you could specify them here. For example, I *know* that
    # hosts with the word 'ldap' in them need a base DN

    if 'ldap' in name.lower():
        vars['baseDN'] = 'dc=mens,dc=de'


    print json.dumps(vars, indent=4)


if __name__ == '__main__':
    con = sqlite3.connect(dbname)
    con.row_factory=sqlite3.Row

    if len(sys.argv) == 2 and (sys.argv[1] == '--list'):
        grouplist(con)
    elif len(sys.argv) == 3 and (sys.argv[1] == '--host'):
        hostinfo(con, sys.argv[2])
    else:
        print "Usage: %s --list or --host <hostname>" % sys.argv[0]
        sys.exit(1)

    con.close()

#ansible列出group
ansible localhost -m debug -a 'var=groups'
	
[root@repo-centos ansible]# ansible-inventory --list |jq .[].children
null
[
  "ceph",
  "compute",
  "controller",
  "es",
  "k8s",
  "kafka",
  "local",
  "logstash",
  "oracle",
  "ungrouped",
  "zabdb"
]
#ansible (单个/多个组)列出host
ansible k8s:kafka --list-hosts

------------------- ansible facts 导入到 SQLITE3 
1 配置ansible fact缓存为redis
[root@repo-centos ~]# cat /etc/ansible/ansible.cfg |grep '^fact_caching'
fact_caching = redis
fact_caching_connection=localhost:6379:0
2 安装python-redis-2.10.3-1.sdl7.noarch.rpm，使python可以使用redis库
3 升级sqlite3从centos 7默认版本3.7到最新版
download sqlite3编译好的二进制文件sqlite-tools-linux-x86-3360000.zip，解压并copy到sqlite3相应目录做文件替换
4 安装facts_to_sqlite3脚本
[root@repo-centos ~]# cat facts_to_sqlite.py
#!/usr/bin/env python2.7
# -*- coding: utf-8 -*-

import json
import redis
import sqlite3


def main(redis_match, db_file, db_table):
    """Grab data from Redis."""
    r = redis.Redis()
    data = r.mget(r.scan_iter(match=redis_match))

    """Prepare table in SQLite."""
    conn = sqlite3.connect(db_file)
    c = conn.cursor()
    c.execute('CREATE TABLE IF NOT EXISTS facts (host varchar(255) PRIMARY KEY,data json)')
    conn.commit()

    """Import data from Redis to SQLite."""
    for host in data:
        host_json = json.loads(host)
        c.execute('REPLACE INTO facts values (?,?)',[host_json["ansible_fqdn"], json.dumps(host_json)],)
        conn.commit()
    conn.close()


if __name__ == "__main__":
    """
    Pass redis key for matching, SQLite file name and table name for the facts.
    """
    main("ansible_facts*", "/root/facts.db", "facts")

## 执行过程：
1 ansible kafka -m setup
此时kafka group的3台kafka机器的facts结果以json格式存放到redis里了

2 可以查看redis数据 
[root@repo-centos ~]# redis-cli keys '*'
1) "ansible_facts10.67.51.145"
2) "ansible_facts10.67.51.146"
3) "ansible_facts10.67.48.194"
4) "ansible_cache_keys"
5) "ansible_facts10.67.51.2"
6) "ansible_facts10.67.50.200"
7) "ansible_facts10.67.51.144"

3 执行 ./facts_to_sqlite.py, 把redis的数据存到sqlite3里

4 进入sqlite3查看结果
sqlite> .mode column
sqlite> select * from serverinfo;
host            ip            OS      OS_version  Product                  CPU  Memory
--------------  ------------  ------  ----------  -----------------------  ---  --------
vstjlogstash03  10.67.48.194  CentOS  7.5         VMware Virtual Platform  8    15.51 GB
kafka3          10.67.51.146  CentOS  7.5         R2-1206R-PA              32   62.73 GB
vstjlogstash01  10.67.50.200  CentOS  7.5         VMware Virtual Platform  8    15.51 GB
kafka1          10.67.51.144  CentOS  7.5         R2-1206R-PA              32   62.73 GB
kafka2          10.67.51.145  CentOS  7.5         Pangu                    32   62.73 GB
vstjlogstash02  10.67.51.2    CentOS  7.5         VMware Virtual Platform  8    15.51 GB

5 查看表结构
sqlite> .schema facts
CREATE TABLE facts (host varchar(255) PRIMARY KEY,data json);
sqlite> .schema serverinfo
CREATE VIEW serverinfo_lin as
select host,json_extract(data,'$.ansible_default_ipv4.address') as ip,json_extract(data,'$.ansible_distribution') as OS,
json_extract(data,'$.ansible_distribution_version') as OS_version,json_extract(data,'$.facter_productname') as Product,
json_extract(data,'$.facter_processorcount') as CPU,json_extract(data,'$.facter_memorysize') as Memory from facts where OS not like '%Windows%';
/* serverinfo(host,ip,OS,OS_version,Product,CPU,Memory) */;
CREATE VIEW serverinfo_win as
select host,json_extract(data,'$.ansible_ip_addresses[0]') as ip,json_extract(data,'$.ansible_distribution') as OS,
json_extract(data,'$.ansible_distribution_version') as OS_version,json_extract(data,'$.ansible_virtualization_type') as Product,
json_extract(data,'$.ansible_processor_count') as CPU,json_extract(data,'$.ansible_memtotal_mb') as Memory from facts where OS like '%Windows%';	

################ 使用 ansible + redis + sqlite-utils #############
[root@c8-cilent1 ~]# redis-cli get ansible_factslocalhost |sqlite-utils memory - 'select ansible_all_ipv4_addresses,ansible_distribution,ansible_distribution_version,ansible_kernel,ansible_product_name,ansible_processor_vcpus,ansible_memtotal_mb from stdin' -t
ansible_all_ipv4_addresses        ansible_distribution      ansible_distribution_version  ansible_kernel               ansible_product_name      ansible_processor_vcpus    ansible_memtotal_mb
--------------------------------  ----------------------  ------------------------------  ---------------------------  ----------------------  -------------------------  ---------------------
["192.168.122.1", "10.67.36.15"]  CentOS                                               8  4.18.0-80.11.2.el8_0.x86_64  KVM                                             2                   3780
[root@c8-cilent1 ~]# redis-cli get ansible_facts10.67.51.164 |sqlite-utils memory - 'select ansible_all_ipv4_addresses,ansible_distribution,ansible_distribution_version,ansible_kernel,ansible_product_name,ansible_processor_vcpus,ansible_memtotal_mb from stdin' -t
ansible_all_ipv4_addresses      ansible_distribution      ansible_distribution_version  ansible_kernel              ansible_product_name       ansible_processor_vcpus    ansible_memtotal_mb
------------------------------  ----------------------  ------------------------------  --------------------------  -----------------------  -------------------------  ---------------------
["172.17.0.1", "10.67.51.164"]  CentOS                                             7.5  3.10.0-957.27.2.el7.x86_64  VMware Virtual Platform                          4                   7931



	  

	